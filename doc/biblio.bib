% This file was created with JabRef 2.7b.
% Encoding: ISO8859_1

@STRING{amdo = {Conference on Articulated Motion and Deformable Objects}}

@STRING{apsipa = {Annual Summit and Conference of the Asia-Pacific Signal and Information
	Processing Association}}

@STRING{asru = {IEEE Workshop on Automatic Speech Recognition \& Understanding}}

@STRING{avbpa = {International Conference of Audio and Video-Based Person Authentication,
	AVBPA}}

@STRING{avsp = {International Conference on Audio-Visual Speech Processing, AVSP}}

@STRING{csl = {Computer Speech and Language}}

@STRING{cv = {IEEE International Conference on Computer Vision}}

@STRING{cvpr = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition}}

@STRING{dsp = {Digital Signal Processing}}

@STRING{eurasip = {EURASIP Journal on Applied Signal Processing}}

@STRING{eurospeech = {European Conference on Speech Communication and Technology (Eurospeech)}}

@STRING{eusipco = {European Signal and Image Processing Conference (EUSIPCO)}}

@STRING{icassp = {IEEE International Conference on Acoustics, Speech, and Signal Processing,
	ICASSP}}

@STRING{icb = {IEEE IAPR International Conference on Biometrics (ICB)}}

@STRING{icct = {IEEE International Conference on Communication Technology}}

@STRING{icdsp = {International Conference on Digital Signal Processing}}

@STRING{icip = {IEEE International Conference on Image Processing}}

@STRING{icphs = {International Congress of Phonetic Sciences (ICPhS)}}

@STRING{icpr = {International Conference on Pattern Recognition (ICPR)}}

@STRING{icslp = {Proceedings International Conference on Spoken Language Processing,
	ICSLP}}

@STRING{icsmc = {IEEE International Conference on Systems, Man, and Cybernetics, 'Computational
	Cybernetics and Simulation'}}

@STRING{ieee = {Proceedings of the IEEE}}

@STRING{interspeech = {International Conference on Speech Communication and Technology}}

@STRING{iscis = {International Symposium on Computer and Information Sciences}}

@STRING{isoe = {Proceedings of SPIE - The International Society for Optical Engineering}}

@STRING{ivc = {Image and Vision Computing}}

@STRING{jasa = {Journal of Acoustic Society of America}}

@STRING{jep = {Proceedings of journees d'etudes sur le parole, JEP}}

@STRING{lncs = {Lecture Notes in Computer Science}}

@STRING{mmsp = {IEEE International workshop on Multimedia Signal Processing}}

@STRING{mmua = {International Workshop on Multimodal User Authentication}}

@STRING{nist = {NIST Speaker Recognition Evaluation Workshop}}

@STRING{odyssey = {Speaker and Language Recognition Workshop (IEEE Odyssey)}}

@STRING{pami = {IEEE transactions on Pattern Analysis and Machine intelligence}}

@STRING{rfia = {Reconnaissance des Formes et Intelligence Artificielle, RFIA}}

@STRING{sac = {ACM Symposium On Applied Computing}}

@STRING{specom = {International Conference on Speech and Computer SPECOM}}

@STRING{tal = {Traitement Automatique des langues}}

@STRING{taslp = {IEEE Transactions on Audio, Speech, and Language Processing}}

@STRING{tassp = {IEEE Transactions on Acoustics, Speech and Signal Processing}}

@STRING{tcsvt = {IEEE Transactions on Circuits and Systems for Video Technology}}

@STRING{tip = {IEEE Transactions on Image Processing}}

@STRING{tit = {IEEE Transactions on Information Theory}}

@STRING{tm = {IEEE Transactions on Multimedia}}

@STRING{tnn = {IEEE Transactions on Neural Networks}}

@STRING{tsap = {IEEE Transactions on Speech and Audio Processing}}

@INPROCEEDINGS{Abry91,
  author = {Abry, C. and Lallouache,M. T.},
  title = {{Audibility and stability of articulatory movements: Deciphering
	two experiments on anticipatory rounding in French}},
  booktitle = icphs,
  year = {1991},
  volume = {1},
  pages = {220--225},
  owner = {antho},
  timestamp = {2009.10.05}
}

@PHDTHESIS{Acero90,
  author = {Alejandro Acero},
  title = {{Acoustical and Environmental Robustness in Automatic Speech Recognition}},
  school = {Department of Electrical and Computer Engineering Carnegie Mellon
	University},
  year = {1990},
  address = {Pittsburgh, Pennsylvania (USA)},
  month = {September},
  file = {Acero90.pdf:Speech_reco/Acero90.pdf:PDF},
  owner = {antho},
  pages = {849--852},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2009.10.05}
}

@TECHREPORT{Achermann96,
  author = {Bernard Achermann and Horst Bunke},
  title = {{Combination of classifiers on the decision level for face recognition}},
  institution = {{Institut d'Informatique et de Math\'ematiques Appliqu\'es de l'Universit\'e
	de Bern}},
  year = {1996},
  file = {Achermann96.pdf:Video/Achermann96.pdf:PDF},
  journal = {University of Bern, IAM-96-002},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Acheroy96,
  author = {Marc Acheroy and Cathy Meunier and Josef Big\"un and G\'erard Chollet
	and Beno\^it Duc and Stefan Fischer and Dominique Genoud and Philip
	Lockwood and Gilbert Maitre and St\'ephane Pigeon and Ionnais Pitas
	and K. Sobottka and Luc Vandendorpe},
  title = {{Multi-Modal Person Verification Tools Using Speech and Images}},
  booktitle = {{Proceedings of the European Conference on Multimedia Applications,
	Services and Techniques}},
  year = {1996},
  pages = {747-761},
  address = {Madrid (Spain)},
  abstract = {We propose multi-modal person verification using voice and images
	as a solution to the secured access problem. The necessary i/o devices
	are now standard, cheaply available and, most importantly, constitute
	the two most important human communication modalities. The visual
	part currently involves i) matching of a coarse grid containing Gabor
	phase information from face images, ii) facial feature localization
	and extraction iii) 3D biometrical feature extraction by structured
	light. The acoustic part usesthree methods (DTW, SOSM and HMM) to
	compare voice references extracted from the speech
	
	signal. In acoustic part LPC coefficients are extracted and three
	different classifiers are used in parallel. The global decision is
	taken by applying a Furui treshold to the individual methods
	
	and in combining the individual results according to a majority law.},
  citeseerurl = {citeseer.csail.mit.edu/acheroy96multimodal.html},
  file = {Acheroy96.pdf:Audio-Video/Acheroy96.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.12}
}

@ARTICLE{Adami07,
  author = {Andre Gostavo Adami},
  title = {{Modeling prosodic differences for speaker recognition}},
  journal = {Speech Communication},
  year = {2007},
  volume = {49},
  pages = {277-291},
  number = {4},
  file = {Adami07.pdf:Speaker_reco/Prosodic/Adami07.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.08.23}
}

@INPROCEEDINGS{Adjoudani95,
  author = {Adjoudani, A. and Beno{\^i}t, C.},
  title = {{Audio-Visual Speech Recognition Compared Across Two Architectures}},
  booktitle = eurospeech,
  year = {1995},
  organization = {ISCA},
  file = {Adjoudani95.pdf:Audio-Video/Adjoudani95.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{ABC2010,
  author = {Agnitio and BUT and CRIM},
  title = {{ABC System description for NIST SRE 2010}},
  booktitle = nist,
  year = {2010},
  pages = {1--20},
  file = {ABC2010.pdf:Speaker_reco/NIST/ABC2010.pdf:PDF},
  owner = {antho},
  timestamp = {2011.02.01}
}

@INPROCEEDINGS{Ahn00,
  author = {Sungjoo Ahn and Sunmee Kang and Hanseok Ko},
  title = {{Effective speaker adaptations for speaker verification}},
  booktitle = icassp,
  year = {2000},
  volume = {2},
  pages = {1081--1084},
  organization = {IEEE; 1999},
  file = {Ahn00.pdf:Speaker_reco/Adaptation/Ahn00.pdf:PDF}
}

@INPROCEEDINGS{Ajmera03,
  author = {Ajmera, J. and Wooters, C.},
  title = {{A robust speaker clustering algorithm}},
  booktitle = asru,
  year = {2003},
  pages = {411--416},
  organization = {IEEE},
  file = {Ajmera03.pdf:Speaker_Diarization/Ajmera03.pdf:PDF}
}

@ARTICLE{Alam11,
  author = {Md Jahangir Alam and Pierre Ouellet and Patrick Kenny and Douglas
	O'Shaughnessy},
  title = {{Comparative Evaluation of Feature Normalization Techniques for Speaker
	Verification}},
  journal = {Advances in Nonlinear Speech Processing},
  year = {2011},
  volume = {1},
  pages = {246--253},
  file = {Alam11.pdf:Parametrisation/Alam11.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Amino06,
  author = {Amino, K. and Sugawara, T. and Arai, T.},
  title = {{Idiosyncrasy of nasal sounds in human speaker identification and
	their acoustic properties}},
  journal = {Acoustical science and technology},
  year = {2006},
  volume = {27},
  pages = {233--235},
  number = {4},
  owner = {antho},
  publisher = {J-STAGE},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Anastasakos96,
  author = {Anastasakos, T. and McDonough, J. and Schwartz, R. and Makhoul, J.},
  title = {{A compact model for speaker-adaptive training}},
  booktitle = icslp,
  year = {1996},
  organization = {ISCA},
  file = {Anastasakos96.pdf:Speaker_reco/Adaptation/SAT/Anastasakos96.pdf:PDF}
}

@INPROCEEDINGS{Andre-Obrecht97,
  author = {Regine Andre-Obrecht and Bruno Jacob},
  title = {{Direct identification vs. correlated models to process acoustic
	and articulatory informations in automatic speech recognition}},
  booktitle = icassp,
  year = {1997},
  volume = {2},
  pages = {999-1002},
  address = {Munich (Germany)},
  abstract = {Our work deals with the classical problem of merging heterogenous
	and asynchronous parameters. It is well known that lip reading improves
	the speech recognition score, especially in noise conditions; so
	we study more precisely the modeling of the acoustic and labial parameters
	to propose two automatic speech recognition systems: a direct identification
	is performed by using a classical HMM approach, no correlation between
	visual and acoustic parameters is assumed; and two correlated models,
	a master HMM and a slave HMM, process respectively the labial observations
	and the acoustic ones. To assess each approach, we use a segmental
	pre-processing method. Our task is the recognition of spelled French
	letters, in clear and noisy (cocktail party) environments. Whatever
	the approach and conditions, the introduction of labial features
	improves the performance, but the difference between the two models
	is not enough sufficient to provide any priority},
  doi = {10.1109/ICASSP.1997.596108},
  file = {Andre-Obrecht97.pdf:Audio-Video/Andre-Obrecht97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Andrews01,
  author = {Walter D. Andrews and Mary A. kohler and Joseph P. Campbell and John
	J. Godfrey},
  title = {{Phonetic, Idiolectal and Acoustic Speaker Recognition}},
  booktitle = odyssey,
  year = {2001},
  address = {Chania (Greece)},
  abstract = {This paper describes a text-independent speaker recognition system
	that achieves an equal error rate of less than 1% by combining phonetic,
	idiolect, and acoustic features. The phonetic system is a novel language-independent
	speaker-recognition system based on differences among speakers in
	dynamic realization of phonetic features (i.e., pronunciation), rather
	than spectral differences in voice quality. The system exploits phonetic
	information from six languages to perform text-independent speaker
	recognition. The idiolectal system models speaker idiosyncrasies
	with word n-gram frequency counts computed from the output of an
	automatic speech recognition system. The acoustic system is a Gaussian
	Mixture Model-Universal Background Model that exploits the spectral
	differences in voice quality. All experiments were performed on the
	NIST 2001 Speaker Recognition Evaluation Extended Data Task.},
  owner = {larcher},
  timestamp = {2006.06.21}
}

@INPROCEEDINGS{Andrews01_b,
  author = {Walter D. Andrews and Mary A. Kohler and Joseph P. Campbell},
  title = {{Phonetic speaker recognition}},
  booktitle = eurospeech,
  year = {2001},
  file = {Andrews01_b.pdf:Speaker_reco/Phonetic/Andrews01_b.pdf:PDF}
}

@INPROCEEDINGS{Ariki96,
  author = {Ariki, Y. and Tagashira, S. and Nishijima, M.},
  title = {{Speaker recognition and speaker normalization by projection to speaker
	subspace}},
  booktitle = icassp,
  year = {1996},
  volume = {1},
  pages = {319--322},
  file = {Ariki96.pdf:Speaker_reco/Divers/Ariki96.pdf:PDF}
}

@ARTICLE{Ariyaeeinia08,
  author = {Alladin Ariyaeeinia and Christopher Morrison and Amit Malegaonkar
	and Sue Black},
  title = {{A test of the effectiveness of speaker verification for differentiating
	between identical twins}},
  journal = {Science \& Justice},
  year = {2008},
  volume = {48},
  pages = {182--186},
  number = {4},
  file = {Ariyaeeinia08.pdf:Speaker_reco/Divers/Ariyaeeinia08.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Ariyaeeinia97,
  author = {Ariyaeeinia, AM and Sivakumaran, P.},
  title = {{Analysis and comparison of score normalisation methods for text-dependent
	speaker verification}},
  booktitle = eurospeech,
  year = {1997},
  pages = {1379-1382},
  file = {Ariyaeeinia97.pdf:Speaker_reco/Text_dependent/Ariyaeeinia97.pdf:PDF}
}

@ARTICLE{Atreas03,
  author = {Nikolaos Atreas and Costas Karanikas and Alexander O. Tarakanov},
  title = {{Signal processing by an immune type tree transform}},
  journal = lncs,
  year = {2003},
  volume = {2787},
  pages = {111--119},
  file = {Atreas03.pdf:Artificial_Immune_System/Atreas03.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Atreas04,
  author = {Nikolaos D. Atreas and Costas Karanikas and Persefoni Polychronidou},
  title = {{Signal analysis on strings for immune-type pattern recognition}},
  journal = {Comparative and functional genomics},
  year = {2004},
  volume = {5},
  pages = {69--74},
  number = {1},
  file = {Atreas04.pdf:Artificial_Immune_System/Atreas04.pdf:PDF},
  publisher = {John Wiley \& Sons}
}

@ARTICLE{Aubert02,
  author = {Xavier L. Aubert},
  title = {{An overview of decoding techniques for large vocabulary continuous
	speech recognition}},
  journal = {Computer speech \& language},
  year = {2002},
  volume = {16},
  pages = {89--114},
  number = {1},
  file = {Aubert02.pdf:Speech_reco/Aubert02.pdf:PDF},
  publisher = {Elsevier}
}

@PHDTHESIS{Auckenthaler01,
  author = {Roland Auckenthaler},
  title = {{Text-Independent Speaker verification with Limited Resources}},
  school = {University of Wales},
  year = {2001},
  month = {may},
  owner = {larcher},
  timestamp = {2007.07.30}
}

@ARTICLE{Auckenthaler00,
  author = {Roland Auckenthaler and Michael Carey and Harvey Lloyd-Thomas},
  title = {{Score Normalization for Text-Independent Speaker Verification System}},
  journal = dsp,
  year = {2000},
  volume = {1},
  pages = {42-54},
  number = {10},
  abstract = {This paper discusses several aspects of score normalization for text-independent
	speaker verification. The theory of score normalization is explained
	using Bayes' theorem and detection error trade-off plots. Based on
	the theory, the world, cohort, and zero normalization techniques
	are explained. A novel normalization technique, test normalization,
	is introduced. Experiments showed significant improvements for this
	new technique compared to the standard techniques. Finally, there
	is a discussion of the use of additional knowledge to further improve
	the normalization methods. Here, the test normalization method is
	extended to use knowledge of the handset type.},
  doi = {10.1006/dspr.1999.0360},
  file = {Auckenthaler00.pdf:Speaker_reco/Normalisation/Auckenthaler00.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@INPROCEEDINGS{Auckenthaler01-b,
  author = {Roland Auckenthaler and John S. Mason},
  title = {{Gaussian selection applied to text-independent speaker verification}},
  booktitle = odyssey,
  year = {2001},
  pages = {83-86},
  address = {Crete},
  file = {Auckenthaler01-b.pdf:Speaker_reco/Divers/Auckenthaler01-b.pdf:PDF},
  owner = {antho},
  timestamp = {2008.02.06}
}

@INPROCEEDINGS{Auckenthaler99,
  author = {Roland Auckenthaler and Eluned S. Parris and Michael J. Carey},
  title = {{Improving a GMM speaker verification system by phonetic weighting}},
  booktitle = icassp,
  year = {1999},
  volume = {1},
  pages = {313--316},
  organization = {IEEE},
  file = {Auckenthaler99.pdf:Speaker_reco/Phonetic/Auckenthaler99.pdf:PDF}
}

@INPROCEEDINGS{Audibert_HASR10,
  author = {Nicolas Audibert and Anthony Larcher and Christophe L \'e vy and
	Juliette Kahn and Solange Rossato and Driss Matrouf and Jean-Francois
	Bonastre},
  title = {{LIA human-based system description for NIST HASR 2010}},
  booktitle = {{NIST Speaker Recognition Evaluation Workshop}},
  year = {2010},
  file = {Audibert_HASR10.pdf:Speaker_reco/NIST/Audibert_HASR10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.10.11}
}

@INPROCEEDINGS{Avinash10,
  author = {Avinash B. and Guruprasad S. and Ygnannarayana B.},
  title = {{Exploring subsegmental and suprasegmental features for a text-dependent
	speaker verification in distant speech signals}},
  booktitle = interspeech,
  year = {2010},
  pages = {1073--1076},
  file = {Avinash10.pdf:Parametrisation/Avinash10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.10.04}
}

@TECHREPORT{Bach05,
  author = {Francis R. Bach and Michael I. Jordan},
  title = {{A probabilistic interpretation of canonical correlation analysis}},
  institution = {Department of Statistics, University of California, Berkeley},
  year = {2005},
  file = {Bach05.pdf:Outils/PLDA/Bach05.pdf:PDF}
}

@INPROCEEDINGS{Bahl86,
  author = {Bahl, L. and Brown, P. and De Souza, P. and Mercer, R.},
  title = {{Maximum mutual information estimation of hidden Markov model parameters
	for speech recognition}},
  booktitle = icassp,
  year = {1986},
  volume = {11},
  file = {Bahl86.pdf:Speech_reco/Bahl86.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Bailly03,
  author = {Bailly-Bailliere, E. and Bengio, S. and Bimbot, F. and Hamouz, M.
	and Kittler, J. and Mariethoz, J. and Matas, J. and Messer, K. and
	Popovici, V. and Poree, F. and others},
  title = {{The BANCA database and evaluation protocol}},
  journal = {Lecture Notes in Computer Science (LNCS)},
  year = {2003},
  volume = {2688},
  pages = {625--638},
  file = {Bailly03.pdf:Base_de_donnees/Bailly03.pdf:PDF},
  owner = {antho},
  publisher = {Springer-Verlag; 1999},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Baker06,
  author = {Brendan Baker and Sridha Sridharan},
  title = {{Speaker Verification Using Hidden Markov Models in a Multilingual
	Text-Constrained Framework}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--6},
  organization = {IEEE},
  file = {Baker06.pdf:Speaker_reco/Text_dependent/Baker06.pdf:PDF}
}

@INPROCEEDINGS{Baker04,
  author = {Brendan Baker and Robbie Vogt and Mickael Mason and Shrida Sridharan},
  title = {{Improved phonetic and lexical speaker recognition through MAP adaptation}},
  booktitle = odyssey,
  year = {2004},
  file = {Baker04.pdf:Speaker_reco/Phonetic/Baker04.pdf:PDF}
}

@CONFERENCE{Baker05,
  author = {Brendan J. Baker and Robbie J. Vogt and Shrida Sridharan},
  title = {{Gaussian mixture modelling of broad phonetic and syllabic events
	for text-independent speaker verification}},
  booktitle = interspeech,
  year = {2005},
  publisher = {International Speech Communication Association (ISCA)},
  file = {Baker05.pdf:Speaker_reco/Phonetic/Baker05.pdf:PDF}
}

@INPROCEEDINGS{Baldwin10,
  author = {Timothy Baldwin and Marco Lui},
  title = {{Language identification: the long and the short of the matter}},
  booktitle = {Annual Conference of the North American Chapter of the Association
	for Computational Linguistics},
  year = {2010},
  pages = {229--237},
  organization = {Association for Computational Linguistics},
  file = {Baldwin10.pdf:Language_reco/Baldwin10.pdf:PDF},
  isbn = {1932432655}
}

@INPROCEEDINGS{Barker99,
  author = {Jon P. Barker and Frédéric Berthommier},
  title = {{Estimation of Speech Acoustics from Visual Speech Features: A Comparison
	of Linear and Non-Linear Models}},
  booktitle = avsp,
  year = {1999},
  pages = {112--117},
  address = {Santa Cruz (USA)},
  organization = {ISCA},
  file = {Barker99.pdf:Audio-Video/Barker99.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Barras94,
  author = {Claude Barras and Marie-José Caraty and Claude Montaci\'e},
  title = {{Contr\^ole temporel et s\'election de l'apprentissage appliqu\'es
	aux mod\`eles de Markov cach\'es}},
  booktitle = rfia,
  year = {1994},
  pages = {391-396},
  file = {Barras94.pdf:Speech_reco/Barras94.pdf:PDF},
  owner = {antho},
  timestamp = {2008.11.18}
}

@INPROCEEDINGS{Barras04,
  author = {Claude Barras and Sylvain Meigner and Jean-Luc Gauvain},
  title = {{Unsupervised online adaptation for speaker verification over the
	telephone}},
  booktitle = odyssey,
  year = {2004},
  pages = {1--4},
  file = {Barras04.pdf:Speaker_reco/Unsupervised/Barras04.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.08}
}

@ARTICLE{Baum70,
  author = {Leonard E. Baum and Ted Petrie and George Soules and Norman Weiss},
  title = {{A maximization technique occurring in the statistical analysis of
	probabilistic functions of Markov chains}},
  journal = {The Annals of Mathematical Statistics},
  year = {1970},
  volume = {41},
  pages = {164--171},
  number = {1},
  file = {Baum70.pdf:Outils/Baum-Welch/Baum70.pdf:PDF},
  owner = {antho},
  publisher = {Institute of Mathematical Statistics},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Beigi98,
  author = {Homayoon Beigi and Stephane H. Maes and Jeffrey S. Sorensen},
  title = {{A distance measure between collections of distributions and its
	application to speaker recognition}},
  booktitle = icassp,
  year = {1998},
  volume = {2},
  pages = {753--756},
  organization = {IEEE},
  file = {Beigi98.pdf:Speaker_reco/Scoring/Beigi98.pdf:PDF}
}

@ARTICLE{Belhumeur97,
  author = {Peter N. Belhumeur and Joao P. Hespanha and David J. Kriegman},
  title = {{Eigenfaces vs. Fisherfaces : recognition using class specific linear
	projection}},
  journal = pami,
  year = {1997},
  volume = {19},
  pages = {711-720},
  number = {7},
  month = {july},
  abstract = {We develop a face recognition algorithm which is insensitive to large
	variation in lighting direction and facial expression.
	
	Taking a pattern classification approach, we consider each pixel in
	an image as a coordinate in a high-dimensional space. We take
	
	advantage of the observation that the images of a particular face,
	under varying illumination but fixed pose, lie in a 3D linear
	
	subspace of the high dimensional image space-if the face is a Lambertian
	surface without shadowing. However, since faces are
	
	not truly Lambertian surfaces and do indeed produce self-shadowing,
	images will deviate from this linear subspace. Rather than
	
	explicitly modeling this deviation, we linearly project the image
	into a subspace in a manner which discounts those regions of the
	
	face with large deviation. Our projection method is based on Fisher's
	Linear Discriminant and produces well separated classes in a
	
	low-dimensional subspace, even under severe variation in lighting
	and facial expressions. The Eigenface technique, another method
	
	based on linearly projecting the image space to a low dimensional
	subspace, has similar computational requirements. Yet, extensive
	
	experimental results demonstrate that the proposed "Fisherface" method
	has error rates that are lower than those of the Eigenface
	
	technique for tests on the Harvard and Yale Face Databases.},
  file = {Belhumeur97.pdf:Image/Belhumeur97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@ARTICLE{Benyacoub99,
  author = {Souheil Ben-Yacoub and Yousri Abdeljaoued and Eddy Mayoraz},
  title = {{Fusion of face and speech data for person identity verification}},
  journal = {IEEE Transactions on Neural Networks},
  year = {1999},
  volume = {10},
  pages = {1065--1074},
  number = {5},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Bengio03,
  author = {Samy Bengio},
  title = {{Multimodal authentication using asynchronous HMMs}},
  booktitle = avbpa,
  year = {2003},
  editor = {Springer-Verlag},
  pages = {770-777},
  address = {Guildford (UK)},
  month = {June},
  owner = {larcher},
  timestamp = {2006.06.20}
}

@ARTICLE{Bengio04,
  author = {Samy Bengio},
  title = {{Multimodal speech processing using asynchronous Hidden Markov Models}},
  journal = {Information Fusion},
  year = {2004},
  volume = {5},
  pages = {81-89},
  number = {2},
  month = {June},
  abstract = {This paper advocates that for some multimodal tasks involving more
	than one stream of data representing the same sequence of events,
	it might sometimes be a good idea to be able to desynchronize the
	streams in order to maximize their joint likelihood. We thus present
	a novel Hidden Markov Model architecture to model the joint probability
	of pairs of asynchronous sequences describing the same sequence of
	events. An Expectation-Maximization algorithm to train the model
	is presented, as well as a Viterbi decoding algorithm, which can
	be used to obtain the optimal state sequence as well as the alignment
	between the two sequences. The model was tested on two audio-visual
	speech processing tasks, namely speech recognition and text-dependent
	speaker verification, both using the M2VTS database. Robust performances
	under various noise conditions were obtained in both cases.},
  doi = {10.1016/j.inffus.2003.04.001},
  keywords = {Speech recognition; Speaker verification; Multimodal fusion; Asynchronous
	fusion; Joint EM estimation; HMM},
  owner = {larcher},
  timestamp = {2006.06.20}
}

@INBOOK{Bengio03_a,
  chapter = {Multimodal Authentication Using Asynchronous HMMs},
  pages = {1056},
  title = {{Audio-and Video-Based Biometric Person Authentication}},
  publisher = {Springer},
  year = {2003},
  author = {Samy Bengio},
  volume = {2688/2003},
  abstract = {It has often been shown that using multiple modalities to authenticate
	the identity of a person is more robust than using only one. Various
	combination techniques exist and are often performed at the level
	of the output scores of each modality system. In this paper, we present
	a novel HMM architecture able to model the joint probability distribution
	of pairs of asynchronous sequences (such as speech and video streams)
	describing the same event. We show how this model can be used for
	audio-visual person authentication. Results on the M2VTS database
	show robust performances of the system under various audio noise
	conditions, when compared to other state-of-the-art techniques.},
  doi = {10.1007/3-540-44887-X},
  owner = {antho},
  timestamp = {2008.07.21}
}

@INPROCEEDINGS{Bengio05,
  author = {Sammy Bengio and Johnny Mari{\'e}thoz and Mikaela Keller},
  title = {{The expected performance curve}},
  booktitle = {International Conference on Machine Learning, ICML, Workshop on ROC
	Analysis in Machine Learning},
  year = {2005},
  volume = {136},
  pages = {1963--1966},
  organization = {Citeseer},
  file = {Bengio05.pdf:Outils/DET curve and ROC/Bengio05.pdf:PDF}
}

@INPROCEEDINGS{Bengio03_isomap,
  author = {Yoshua Bengio and Jean-Francois Paiement and Pascal Vincent and Olivier
	Delalleau and Nicolas Le Roux and Marie Ouimet},
  title = {{Out-of-sample extensions for lle, isomap, mds, eigenmaps, and spectral
	clustering}},
  booktitle = {Advances in Neural Information},
  year = {2003},
  pages = {177},
  organization = {The MIT Press},
  file = {Bengio03_isomap.pdf:Outils/Isomap/Bengio03_isomap.pdf:PDF}
}

@ARTICLE{Bennani95,
  author = {Younes Bennani and Patrick Gallinari},
  title = {{Neural networks for discrimination and modelization of speakers}},
  journal = {Speech Communication},
  year = {1995},
  volume = {17},
  pages = {159-175},
  number = {1-2},
  month = {August},
  abstract = {This article reviews current research on previous termneural networknext
	term systems previous termfor speakernext term recognition tasks.
	We consider two main approaches, the first one relies on direct classification
	and the second on previous termspeaker modelization.next term The
	potential of connectionist models previous termfor speakernext term
	recognition is first presented and the main models are briefly introduced.
	We then present different systems which have been recently proposed
	previous termfor speakernext term recognition tasks. We discuss their
	respective performances and potentials and compare these techniques
	to more conventional methods like vector quantization and Hidden
	Markov models. The paper ends with a summary and suggestions previous
	termfornext term further developments.},
  doi = {10.1016/0167-6393(95)00014-F},
  keywords = {Discriminationnext term; Predictive modeling; Modular connectionist
	system; previous termNeuralnext term nets; Hybrid system; previous
	termSpeakernext term recognition; Identification; Verification},
  owner = {larcher},
  timestamp = {2006.05.09}
}

@INPROCEEDINGS{Benouareth06,
  author = {A. Benouareth and A. Ennaji and M. Sellami},
  title = {{Utilisation des {HMM}s de dur\'ee d'\'etat explicite pour la reconnaissance
	des mots arabes manuscrits}},
  booktitle = rfia,
  year = {2006},
  address = {Tours (France)},
  month = {January},
  abstract = {L'écriture arabe étant par nature semi-cursive, la segmentation des
	mots manuscrits en vue de leur reconnaissance n'est pas toujours
	triviale et demande beaucoup de temps de calcul. Pour remédier à
	ces problèmes, nous proposons dans cet article une méthode globale
	(i.e. sans segmentation en caractères) pour la reconnaissance des
	mots arabes manuscrits dans un vocabulaire limité. Notre approche
	est basée sur les modèles de Markov cachés (Hidden Markov Models
	ou HMMs) de durée d'état explicite de différents types (Gaussien,
	Poissonien et Gamma).
	
	Dans la méthode proposée, chaque mot du lexique est modélisé par un
	HMM discret d'ordre 1 de durée explicite. L'image du mot à reconnaître
	est d'abord parcourue de droite à gauche afin d'en générer une séquence
	de vecteurs de paramètres. Après quantification vectorielle, la séquence
	extraite sera soumise à un classifieur de type
	
	HMM pour identifier le mot. La discrimination de ce dernier est effectuée
	à base d'un critère de maximum de vraisemblance en utilisant l'algorithme
	de Viterbi.
	
	Des expérimentations significatives ont été effectuées sur la base
	de données de référence IFN/ENIT, elles ont montré qu'une distribution
	de type Gamma pour la durée d'état donne un meilleur taux de reconnaissance
	(91.23 % en top 2).},
  file = {Benouareth06.pdf:Divers/Writting_reco/Benouareth06.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.04.03},
  url = {http://www.afrif.asso.fr/archive/rfia2006/idx-theme.html}
}

@INPROCEEDINGS{Benoit91,
  author = {Beno{\^\i}t, C. and Lallouache, T. and Mohamedi, T. and Tseva, A.
	and Abry, C.},
  title = {{Nineteen ($\pm$Two) French Visemes for Visual Speech Synthesis}},
  booktitle = {The ESCA Workshop on Speech Synthesis},
  year = {1991},
  organization = {ISCA},
  file = {Benoit91.pdf:Video/Segmentation/Viseme/Benoit91.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{BenZeghiba06,
  author = {Mohamed Faouzi BenZeghiba and Herv\'e Bourlard},
  title = {{User-customized password speaker verification using multiple reference
	and background models}},
  journal = {Speech Communication},
  year = {2006},
  volume = {48},
  pages = {1200-1213},
  number = {9},
  abstract = {This paper discusses and optimizes an HMM/GMM based User-Customized
	Password Speaker Verification (UCP-SV) system. Unlike text-dependent
	speaker verification, in UCP-SV systems, customers can choose their
	own passwords with no lexical constraints. The password has to be
	pronounced a few times during the enrollment step to create a customer
	dependent model. Although potentially more "user-friendly", such
	systems are less understood and actually exhibit several practical
	issues, including automatic HMM inference, speaker adaptation, and
	efficient likelihood normalization. In our case, HMM inference (HMM
	topology) is performed using hybrid HMM/MLP systems, while the parameters
	of the inferred model, as well as their adaptation, will use GMMs.
	However, the evaluation of a UCP-SV baseline system shows that the
	background model used for likelihood normalization is the main difficulty.
	Therefore, to circumvent this problem, the main contribution of the
	paper is to investigate the use of multiple reference models for
	customer acoustic modeling and multiple background models for likelihood
	normalization. In this framework, several scoring techniques are
	investigated, such as Dynamic Model Selection (DMS) and fusion techniques.
	Results on two different experimental protocols show that an appropriate
	selection criteria for customer and background models can improve
	significantly the UCP-SV performance, making the UCP-SV system quite
	competitive with a text-dependent SV system. Finally, as customers'
	passwords are short, a comparative experiment using the conventional
	GMM-UBM text-independent approach is also conducted.},
  file = {BenZeghiba06.pdf:Speaker_reco/Text_dependent/PassWord_based_recognition/BenZeghiba06.pdf:PDF},
  owner = {antho},
  timestamp = {2008.05.27}
}

@INPROCEEDINGS{Benzeghiba09,
  author = {Mohammed F. BenZeghiba and Jean-Luc Gauvain and Lory Lamel},
  title = {{Gaussian Backend design for open-set language detection}},
  booktitle = icassp,
  year = {2009},
  pages = {4349--4352},
  organization = {IEEE},
  file = {Benzeghiba09.pdf:Language_reco/Benzeghiba09.pdf:PDF},
  issn = {1520-6149}
}

@ARTICLE{Bertelson99,
  author = {Bertelson, P.},
  title = {{Ventriloquism: A case of crossmodal perceptual grouping}},
  journal = {Advances in psychology},
  year = {1999},
  volume = {129},
  pages = {347--362},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Besacier01,
  author = {Laurent Besacier and Bergamini, C. and Vaufreydaz, D. and Castelli,
	E.},
  title = {{The effect of speech and audio compression on speech recognition
	performance}},
  booktitle = {Multimedia Signal Processing, 2001 IEEE Fourth Workshop on},
  year = {2001},
  pages = {301--306},
  organization = {IEEE},
  isbn = {0780370252}
}

@ARTICLE{Besacier00,
  author = {Laurent Besacier and Jean-Francois Bonastre and Corinne Fredouille},
  title = {{Localization and selection of speaker-specific information with
	statistical modeling}},
  journal = {Speech Communication},
  year = {2000},
  volume = {31},
  pages = {89--106},
  number = {2-3},
  file = {Besacier00.pdf:VAD/Besacier00.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Bescos02,
  author = {Bescos, J. and Movilla, A. and Menendez, JM and Cisneros, G.},
  title = {{Real time temporal segmentation of MPEG video}},
  booktitle = icip,
  year = {2002},
  volume = {2},
  abstract = {One of the main customers of video annotation applications are TV
	broadcasters, and one of their key requirements is on-line annotation
	of received digital channels in order to offer dynamic value-added
	content-based services. For this purpose, apart from high levels
	of success in video temporal segmentation - a highly resource-consuming
	task previous to video annotation - a faster than real-time performance
	is also crucial. The paper describes a video temporal segmentation
	module able to detect abrupt transitions and all types of gradual
	transitions in real time, with levels of recall and precision not
	previously reached for so large and varied a set of video sequences.},
  doi = {10.1109/ICIP.2002.1039974},
  file = {Bescos02.pdf:Video/Segmentation/Bescos02.pdf:PDF},
  journal = {Image Processing. 2002. Proceedings. 2002 International Conference
	on},
  owner = {antho},
  timestamp = {2007.10.11}
}

@INPROCEEDINGS{Bhargava10,
  author = {Aditya Bhargava and Grzegorz Kondrak},
  title = {{Language identification of names with SVMs}},
  booktitle = {Annual Conference of the North American Chapter of the Association
	for Computational Linguistics},
  year = {2010},
  pages = {693--696},
  organization = {Association for Computational Linguistics},
  file = {Bhargava10.pdf:Language_reco/Bhargava10.pdf:PDF},
  isbn = {1932432655}
}

@INPROCEEDINGS{Biadsy10,
  author = {Fadi Biadsy and Hagen Soltau and Lidia Mangu and Jiri Navratil and
	Julia Hirschberg},
  title = {{Discriminative Phonotactics for Dialect Recognition Using Context-Dependent
	Phone Classifiers}},
  booktitle = odyssey,
  year = {2010},
  publisher = {Citeseer},
  file = {Biadsy10.pdf:Language_reco/Biadsy10.pdf:PDF}
}

@BOOK{Bigun97,
  title = {Multi-modal Person Authentication},
  publisher = {Springer},
  year = {1997},
  editor = {LNCS},
  author = {Josef Bigun and Beno\^it Duc and F. Smerldi and Stefan Fisher and
	Alexander A. Makarov},
  series = {LNCS},
  month = {June},
  booktitle = {Face Recognition : From Theory to Applications},
  file = {Bigun97.ps:Audio-Video/Bigun97.ps:PostScript},
  owner = {larcher},
  timestamp = {2006.05.18}
}

@INPROCEEDINGS{Bimbot99,
  author = {Frederic Bimbot and Mats Blomberg and Louis Boves and Gerard Chollet
	and Cedric Jaboulet and Bruno Jacob and Jamal Kharroubi and Johan
	Koolwaaij and Johan Lindberg and Johnny Mariethoz and Chafic Mokbel
	and Houda Mokbel},
  title = {{An overview of the PICASSO project research activities in speaker
	verification for telephone applications}},
  booktitle = {European Conference on Speech Communication and Technology},
  year = {1999},
  file = {Bimbot99.pdf:Base_de_donnees/Bimbot99.pdf:PDF}
}

@ARTICLE{Bimbot04,
  author = {Frederic Bimbot and Jean-Fran{\c c}ois Bonastre and Corinne Fredouille
	and Guillaume Gravier and Ivan Magrin-Chagnolleau and Sylvain Meigner
	and Teva Merlin and Javier Ortega-Garcia and Dijana Petrovska-Delacretaz
	and Douglas A. Reynolds},
  title = {{A tutorial on text-independent speaker verification}},
  journal = eurasip,
  year = {2004},
  volume = {4},
  pages = {430--451},
  month = {April},
  abstract = {This paper presents an overview of a state-of-the-art text-independent
	speaker verification system. First, an introduction proposes a modular
	scheme of the training and test phases of a speaker verification
	system. Then, the most commonly speech parameterization used in speaker
	verification, namely, cepstral analysis, is detailed. Gaussian mixture
	modeling, which is the speaker modeling technique used in most systems,
	is then explained. A few speaker modeling alternatives, namely, neural
	networks and support vector machines, are mentioned. Normalization
	of scores is then explained, as this is a very important step to
	deal with real-world data. The evaluation of a speaker verification
	system is then detailed, and the detection error trade-off (DET)
	curve is explained. Several extensions of speaker verification are
	then enumerated, including speaker tracking and segmentation by speakers.
	Then, some applications of speaker verification are proposed, including
	on-site applications, remote applications, applications relative
	to structuring audio information, and games. Issues concerning the
	forensic area are then recalled, as we believe it is very important
	to inform people about the actual performance and limitations of
	speaker verification systems. This paper concludes by giving a few
	research trends in speaker verification for the next couple of years.},
  doi = {10.1155/S1110865704310024},
  file = {Bimbot04.pdf:Speaker_reco/GMM-UBM/Bimbot04.pdf:PDF},
  owner = {larcher},
  timestamp = {2009.10.05}
}

@ARTICLE{Bimbot95,
  author = {Frédéric Bimbot and Ivan Magrin-Chagnolleau and Luc Mathan},
  title = {{Second-order statistical measures for text-independent speaker identification}},
  journal = {Speech Communication},
  year = {1995},
  volume = {17},
  pages = {177--192},
  number = {1-2},
  file = {Bimbot95.pdf:Speaker_reco/GMM-UBM/Bimbot95.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@ARTICLE{Binnie74,
  author = {Binnie, C.A. and Montgomery, A.A. and Jackson, P.L.},
  title = {{Auditory and visual contributions to the perception of consonants}},
  journal = {Journal of Speech, Language and Hearing Research},
  year = {1974},
  volume = {17},
  pages = {619},
  number = {4},
  owner = {antho},
  publisher = {ASHA},
  timestamp = {2009.10.05}
}

@BOOK{Bishop06,
  title = {Pattern recognition and machine learning},
  publisher = {Springer},
  year = {2006},
  editor = {Springer},
  author = {Christopher M. Bishopb},
  volume = {4}
}

@ARTICLE{Blatchford06,
  author = {Blatchford, H. and Foulkes, P.},
  title = {{Identification of voices in shouting}},
  journal = {International Journal of Speech Language and the Law},
  year = {2006},
  volume = {13},
  pages = {241},
  number = {2},
  owner = {antho},
  publisher = {University of Birmingham Press},
  timestamp = {2009.10.05}
}

@ARTICLE{Blei03,
  author = {David M. Blei and Andrew Y. Ng and Michael I. Jordan},
  title = {{Latent dirichlet allocation}},
  journal = {The Journal of Machine Learning Research},
  year = {2003},
  volume = {3},
  pages = {993--1022},
  file = {Blei03.pdf:LDA/Blei03.pdf:PDF},
  publisher = {JMLR. org}
}

@ARTICLE{Boehringer06,
  author = {Boehringer, S. and Vollmar, T. and Tasse, C. and Wurtz, R.P. and
	Gillessen-Kaesbach, G. and Horsthemke, B. and Wieczorek, D.},
  title = {{Syndrome identification based on 2D analysis software}},
  journal = {European Journal of Human Genetics},
  year = {2006},
  volume = {14},
  pages = {1082--1089},
  file = {Boehringer06.pdf:Image/EBGM/Boehringer06.pdf:PDF},
  owner = {antho},
  timestamp = {2009.02.09}
}

@ARTICLE{Boersma08,
  author = {Boersma, P. and Weenink, D.},
  title = {{Praat: Doing phonetics by computer (Version 5.0. 38)[Computer program]}},
  journal = {Retrieved November},
  year = {2008},
  volume = {1},
  pages = {2008}
}

@BOOK{Boite00,
  title = {Traitement de la parole},
  publisher = {PPUR presses polytechniques},
  year = {2000},
  author = {René Boite and Hervé Bourlard and Thierry Dutoit},
  owner = {antho},
  timestamp = {2009.06.04}
}

@INPROCEEDINGS{Bonastre11_a,
  author = {Jean-Francois Bonastre and Pierre-Michel Bousquet and Driss Matrouf
	and Xavier Anguera},
  title = {{Discriminant binary data representation for speaker recognition}},
  booktitle = icassp,
  year = {2011},
  pages = {5284--5287},
  file = {Bonastre11_a.pdf:Speaker_reco/Divers/Bonastre11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.05.30}
}

@INPROCEEDINGS{Bonastre00,
  author = {Jean-Fran{\c c}ois Bonastre and Pierre Delacourt and Corinne Fredouille
	and Sylvain Meignier and Teva Merlin and Christian Wellekens},
  title = {{Diff\'erentes Strat\'egies pour le Suivi du Locuteur, Various Strategies
	for Speaker Tracking}},
  booktitle = rfia,
  year = {2000},
  address = {Paris (France)},
  file = {Bonastre00.ps:Divers/Speaker_tracking/Bonastre00.ps:PostScript},
  owner = {larcher},
  timestamp = {2006.05.10}
}

@INPROCEEDINGS{Bonastre03,
  author = {Jean-Francois Bonastre and Philippe Morin and Jean-Claude Junqua},
  title = {{Gaussian dynamic warping (GDW) method applied to text-dependent
	speaker detection and verification}},
  booktitle = eurospeech,
  year = {2003},
  pages = {2013--2016},
  abstract = {This paper introduces a new acoustic modeling method called Gaussian
	Dynamic Warping (GDW). It is targeting real world applications such
	as voice-based entrance door security systems, the example presented
	in this paper. The proposed approach uses a hierarchical statistical
	framework with three levels of specialization for the acoustic modeling.
	The highest level of specialization is in addition responsible for
	the modeling of the temporal constraints via a specific Temporal
	Structure Information (TSI) component. The preliminary results show
	the ability of the GDW method to elegantly take into account the
	acoustic variability of speech while capturing important temporal
	constraints.},
  file = {Bonastre03.pdf:Speaker_reco/Text_dependent/Bonastre03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Bonastre08,
  author = {Jean-Fran{\c c}ois Bonastre and Nicolas Scheffer and Driss Matrouf
	and Corinne Fredouille and Anthony Larcher and Alexandre Preti and
	Gilles Pouchoulin and Nicholas Evans and Beno\^it Fauve and John
	S.D. Mason},
  title = {{ALIZE/SpkDet: a state-of-the-art open source software for speaker
	recognition}},
  booktitle = odyssey,
  year = {2008},
  note = {http://mistral.univ-avignon.fr/},
  owner = {antho},
  timestamp = {2008.01.31}
}

@INPROCEEDINGS{Boreczky98,
  author = {John S. Boreczky and Lynn D. Wilcox},
  title = {{A hidden Markov model framework for video segmentation using audio
	and image features}},
  booktitle = icassp,
  year = {1998},
  volume = {6},
  pages = {3741-3744},
  month = {May},
  abstract = {This paper describes a technique for segmenting video using hidden
	Markov models (HMM). Video is segmented into regions defined by shots,
	shot boundaries, and camera movement within shots. Features for segmentation
	include an image-based distance between adjacent video frames, an
	audio distance based on the acoustic difference in intervals just
	before and after the frames, and an estimate of motion between the
	two frames. Typical video segmentation algorithms classify shot boundaries
	by computing an image-based distance between adjacent frames and
	comparing this distance to fixed, manually determined thresholds.
	Motion and audio information is used separately. In contrast, our
	segmentation technique allows features to be combined within the
	HMM framework. Further, thresholds are not required since automatically
	trained HMMs take their place. This algorithm has been tested on
	a video data base, and has been shown to improve the accuracy of
	video segmentation over standard threshold-based systems},
  doi = {10.1109/ICASSP.1998.679697},
  file = {Boreczky98.pdf:Video/Boreczky98.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.06.01}
}

@INPROCEEDINGS{Bousquet12_a,
  author = {Pierre-Michel Bousquet and Anthony Larcher and Driss Matrouf and
	Jean-Francois Bonastre},
  title = {{Eigen Factor Radial Model and Mahalanobis scoring in i-vector speaker
	verification}},
  booktitle = {submitted to ICASSP 2012},
  year = {2012},
  owner = {antho},
  timestamp = {2011.11.17}
}

@INPROCEEDINGS{Bousquet11_a,
  author = {Pierre-Michel Bousquet and Driss Matrouf and Jean-Francois Bonastre},
  title = {{Intersession compensation and scoring methods in the i-vectors space
	for speaker recognition}},
  booktitle = interspeech,
  year = {2011},
  pages = {485-488},
  file = {Bousquet11_a.pdf:Speaker_reco/FA/I-Vector/Bousquet11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.10}
}

@ARTICLE{Box58,
  author = {George Edward Pelham Box and Mervin Edgar Muller},
  title = {{A note on the generation of random normal deviates}},
  journal = {Annals of Mathematical Statislics},
  year = {1958},
  volume = {1},
  pages = {610--611},
  file = {Box58.pdf:Outils/Box_Muller/Box58.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Brady07,
  author = {Kevin Brady and Michael Brandstein and Thomas Quatieri and Bob Dunn},
  title = {{An evaluation of audio-visual recognition on the XM2VTS corpus using
	the Lausanne protocols}},
  booktitle = icassp,
  year = {2007},
  address = {Hawaï},
  month = {april},
  abstract = {A multimodal person recognition architecture has been developed for
	the purpose of improving overall recognition performance and for
	addressing channel-specific performance shortfalls. This multimodal
	architecture includes the fusion of a face recognition system with
	the MIT/LL GMM/UBM speaker recognition architecture. This architecture
	exploits the complementary and redundant nature of the face and speech
	modalities. The resulting multimodal architecture has been evaluated
	on the XM2VTS corpus using the Lausanne open set verification protocols,
	and demonstrates excellent recognition performance. The multimodal
	architecture also exhibits strong recognition performance gains over
	the performance of the individual modalities.},
  owner = {larcher},
  timestamp = {2007.05.14}
}

@INPROCEEDINGS{Bregler94,
  author = {Christoph Bregler and Yochai Konig},
  title = {{Eigenlips for robust speech recognition}},
  booktitle = icassp,
  year = {1994},
  volume = {2},
  pages = {669-672},
  address = {Adela\"ide (Australia)},
  month = {april},
  abstract = {We improve the performance of a hybrid connectionist speech recognition
	system by incorporating visual information about the corresponding
	lip movements. Specifically, we investigate the benefits of adding
	visual features in the presence of additive noise and crosstalk (cocktail
	party effect). Our study extends our previous experiments by using
	a new visual front end, and an alternative architecture for combining
	the visual and acoustic information. Furthermore, we have extended
	our recognizer to a multi-speaker, connected letters recognizer.
	Our results show a significant improvement for the combined architecture
	(acoustic and visual information) over just the acoustic system in
	the presence of additive noise and crosstalk},
  file = {Bregler94.pdf:Audio-Video/Bregler94.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.20}
}

@ARTICLE{Bricker76,
  author = {Bricker, PD and Pruzansky, S.},
  title = {{Speaker recognition}},
  journal = {{Contemporary issues in experimental phonetics}},
  year = {1976},
  pages = {295--326},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Broun01_b,
  author = {Charles C. Broun and William M. Campbell and David Pearce and Holly
	Kelleher},
  title = {{Distributed speaker recognition using the ETSI distributed speech
	recognition standard}},
  booktitle = odyssey,
  year = {2001},
  pages = {121--124},
  organization = {Citeseer},
  file = {Broun01_b.pdf:Speaker_reco/Compression/Broun01_b.pdf:PDF}
}

@ARTICLE{Broun01,
  author = {Charles C. Broun and XiaoZheng Zhang},
  title = {{Multimodal fusion of polynomial classifiers for automatic person
	recognition}},
  journal = isoe,
  year = {2001},
  volume = {4390},
  pages = {166-174},
  abstract = {With the prevalence of the information age, privacy and personalization
	are forefront in today's society. As such, biometrics are viewed
	as essential components of current and evolving technological systems.
	Consumers demand unobtrusive and noninvasive approaches. In our previous
	work, we have demonstrated a speaker verification system that meets
	these criteria. However, there are additional constraints for fielded
	systems. The required recognition transactions are often performed
	in adverse environments and across diverse populations, necessitating
	robust solutions. There are two significant problem areas in current
	generation speaker verification systems. The first is the difficulty
	in acquiring clean audio signals (in all environments) without encumbering
	the user with a head-mounted close-talking microphone. Second, unimodal
	biometric systems do not work with a significant percentage of the
	population. To combat these issues, multimodal techniques are being
	investigated to improve system robustness to environmental conditions,
	as well as improve overall accuracy across the population. We propose
	a multimodal approach that builds on our current state-of-the-art
	speaker verification technology. In order to maintain the transparent
	nature of the speech interface, we focus on optical sensing technology
	to provide the additional modality-giving us an audio-visual person
	recognition system. For the audio domain, we use our existing speaker
	verification system. For the visual domain, we focus on lip motion.
	This is chosen, rather than static face or iris recognition, because
	it provides dynamic information about the individual. In addition,
	the lip dynamics can aid speech recognition to provide liveness testing.
	The visual processing method makes use of both color and edge information,
	combined within a Markov random field (MRF) framework, to localize
	the lips. Geometric features are extracted and input to a polynomial
	classifier for the person recognition process. A late integration
	approach, based on a probabilistic model, is employed to combine
	the two modalities. The system is tested on the XM2VTS database combined
	with AWGN (in the audio domain) over a range of signal-to-noise ratios.},
  file = {Broun01.pdf:Audio-Video/Broun01.pdf:PDF},
  keywords = {Active shape model; Lip tracking; Markov random field; Multimodal
	fusion; Polynomial classifier; Speaker verification; Speech recognition},
  owner = {larcher},
  timestamp = {2006.04.12}
}

@INPROCEEDINGS{Broun02,
  author = {Charles C. Broun and Xiaozheng Zhang and R.M. Mersereau and M. Clements},
  title = {{Automatic speechreading with application to speaker verification}},
  booktitle = icassp,
  year = {2002},
  volume = {1},
  pages = {685-688},
  address = {Orlando (USA)},
  abstract = {Speech not only conveys linguistic information, but also characterizes
	the talker's identity and therefore can be used in personal authentication.
	While most of the speech information is contained in the acoustic
	channel, the lip movement during speech production also provides
	useful information. We investigate the effectiveness of visual speech
	features in a speaker verification task. We first present the visual
	front-end of the automatic speechreading system. We then develop
	a recognition engine to train and recognize sequences of visual parameters.
	The experimental results based on the XM2VTS database (see http://www.ee.surrey.ac.uk/research/vssp/xm2vtsdb)
	demonstrate that visual information is highly effective in reducing
	both false acceptance and false rejection rates in speaker verification
	tasks.},
  file = {Broun02.pdf:Video/Lip_reading/Broun02.pdf:PDF},
  keywords = {face recognition feature extraction gesture recognition image motion
	analysis speaker recognition XM2VTS database acoustic channel audio-visual
	speaker verification automatic speechreading false acceptance rates
	false rejection rates linguistic information lip feature extraction
	lip movement visual speech features},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Brummer09_b,
  author = {Niko Brummer and Albert Strasheim},
  title = {{Discriminative acoustic language recognition via channel-compensated
	GMM statistics}},
  booktitle = interspeech,
  year = {2009},
  pages = {2187--2190},
  file = {Brummer09_b.pdf:Language_reco/Brummer09_b.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@INPROCEEDINGS{Brummer11,
  author = {Niko Brummer and Jesus Villalba and Eduardo Lleida},
  title = {{Fully Bayesian likelihood ratio vs i-vector length normalization
	in speaker recognition systems}},
  booktitle = {NIST SRE Analysis Workshop},
  year = {2011},
  owner = {antho},
  timestamp = {2012.02.10}
}

@INPROCEEDINGS{Brummer10,
  author = {Niko Brummer and Edward de Villiers},
  title = {{The speaker partitioning problem}},
  booktitle = odyssey,
  year = {2010},
  file = {Brummer10.pdf:Speaker_reco/Divers/Brummer10.pdf:PDF}
}

@ARTICLE{Brunelli95,
  author = {Roberto Brunelli and Daniele Falavigna},
  title = {{Person identification using multiple cues}},
  journal = pami,
  year = {1995},
  volume = {17},
  pages = {955-966},
  number = {10},
  month = {October},
  abstract = {This paper presents a person identification system based on acoustic
	and visual features. The system is organized as a set of non-homogeneous
	classifiers whose outputs are integrated after a normalization step.
	In particular, two classifiers based on acoustic features and three
	based on visual ones provide data for an integration module whose
	performance is evaluated. A novel technique for the integration of
	multiple classifiers at an hybrid rank/measurement level is introduced
	using HyperBF networks. Two different methods for the rejection of
	an unknown person are introduced. The performance of the integrated
	system is shown to be superior to that of the acoustic and visual
	subsystems. The resulting identification system can be used to log
	personal access and, with minor modifications, as an identity verification
	system},
  doi = {10.1109/34.464560},
  file = {Brunelli95.pdf:Audio-Video/Brunelli95.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.13}
}

@TECHREPORT{Brummer10_LR,
  author = {Niko Br{\\"u}mmer},
  title = {{Calculus of Likelihood Ratios}},
  institution = {University of Stellenbosch},
  year = {2010},
  file = {Brummer10_LR.pdf:Outils/Brummer10_LR.pdf:PDF},
  owner = {antho},
  timestamp = {2010.12.20}
}

@TECHREPORT{Brummer10_PLDA,
  author = {Niko Br{\\"u}mmer},
  title = {{Bayesian PLDA}},
  institution = {University of Stellenbosch},
  year = {2010},
  file = {Brummer10_PLDA.pdf:Outils/Brummer10_PLDA.pdf:PDF},
  owner = {antho},
  timestamp = {2010.12.20}
}

@TECHREPORT{Brummer10_stat,
  author = {Niko Br{\\"u}mmer},
  title = {{Notes on computation of first and second order partial derivatives
	for optimization}},
  institution = {University of Stellenbosch},
  year = {2010},
  file = {Brummer10_stat.pdf:Outils/Brummer10_stat.pdf:PDF},
  owner = {antho},
  timestamp = {2010.12.20}
}

@ARTICLE{Brummer07,
  author = {Niko Br{\\"u}mmer and Lukas Burget and Jan Honza Cernocky and Ondrej
	Glembek and Frantisek Grezl and Martin Karafiat and David A. Van
	Leeuwen and Pavel Matejka and Petr Schwarz and Albert Strasheim},
  title = {{Fusion of heterogeneous speaker recognition systems in the STBU
	submission for the NIST speaker recognition evaluation 2006}},
  journal = taslp,
  year = {2007},
  volume = {15},
  pages = {2072--2084},
  number = {7},
  file = {Brummer07.pdf:Speaker_reco/Score_Fusion/Brummer07.pdf:PDF},
  issn = {1558-7916},
  publisher = {IEEE}
}

@INPROCEEDINGS{Brummer09,
  author = {Niko Br{\\"u}mmer and Lukas Burget and Ondrej Glembek and Valiantsina
	Hubeika and Zdenek Janc{\i}k and Martin Karafi{\'a}t and Pavel Matejka
	and Tomas Mikolov and Oldrich Plchot and Albert Strasheim},
  title = {{BUT-AGNITIO System Description for NIST Language Recognition Evaluation
	2009}},
  booktitle = {NIST Language Recognition Evaluation},
  year = {2009},
  file = {Brummer09.pdf:Language_reco/Brummer09.pdf:PDF}
}

@INPROCEEDINGS{Brummer06_b,
  author = {Niko Br{\\"u}mmer and David van Leeuwen},
  title = {{On calibration of language recognition scores}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--8},
  organization = {IEEE},
  file = {Brummer06_b.pdf:Calibration/Brummer06_b.pdf:PDF}
}

@ARTICLE{Brummer06,
  author = {Niko Br{\\"u}mmer and Johan du Preez},
  title = {{Application-independent evaluation of speaker detection}},
  journal = {Computer Speech \& Language},
  year = {2006},
  volume = {20},
  pages = {230--275},
  number = {2-3},
  file = {Brummer06.pdf:Speaker_reco/Score_Fusion/Brummer06.pdf:PDF},
  issn = {0885-2308},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Agnitio-EVALITA,
  author = {Niko Br{\\"u}mmer and Albert Strasheim},
  title = {{AGNITIO's Speaker Recognition System for EVALITA 2009}},
  booktitle = {EVALITA Evaluation},
  year = {2009}
}

@INPROCEEDINGS{Burget09,
  author = {Lukas Burget and Michal Fapso and Valiantsina Hubeika and Ondrej
	Glembek and Martin Karafiat and Marcel Kockmann and Pavel Matejka
	and Petr Schwarz and Jan Honza Cernocky},
  title = {{BUT system for NIST 2008 speaker recognition evaluation}},
  booktitle = interspeech,
  year = {2009},
  pages = {2335--2338},
  organization = {International Speech Communication Association},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/Divers/Burget09.pdf:PDF}
}

@INPROCEEDINGS{Burget06,
  author = {Lukas Burget and Pavel Matejka and Jan Cernocky},
  title = {{Discriminative training techniques for acoustic language identification}},
  booktitle = icassp,
  year = {2006},
  volume = {1},
  file = {:/Volumes/Donnees/LIA/biblio/Language_reco/Burget06.pdf:PDF}
}

@INPROCEEDINGS{Burget09_b,
  author = {Lukas Burget and Pavel Matejka and Valiantsina Hubeika and Jan Honza
	Cernock\^y},
  title = {{Investigation into variants of Joint Factor Analysis for speaker
	recognition}},
  booktitle = interspeech,
  year = {2009},
  pages = {1263--1266},
  file = {Burget09_b.pdf:Speaker_reco/FA/Burget09_b.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.01}
}

@ARTICLE{Burget07,
  author = {Lukas Burget and Pavel Matejka and Petr Schwarz and Ondrej Glembek
	and Jan Cernocky},
  title = {{Analysis of feature extraction and channel compensation in GMM speaker
	recognition system}},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2007},
  volume = {15},
  pages = {1979--1986},
  number = {7},
  file = {Burget07.pdf:Speaker_reco/FA/Burget07.pdf:PDF},
  issn = {1558-7916},
  language = {english},
  owner = {antho},
  timestamp = {2009.10.05},
  url = {http://www.fit.vutbr.cz/research/view_pub.php?id=8267}
}

@INPROCEEDINGS{Burget11,
  author = {Lukas Burget and Oldrich Plchot and Sandro Cumani and Ondrej Glembek
	and Pavel Matejka and Niko Brummer},
  title = {{Discriminatively trained probabilistic linear discriminant analysis
	for speaker verification}},
  booktitle = icassp,
  year = {2011},
  pages = {4832--4835},
  file = {Burget11.pdf:Speaker_reco/FA/I-Vector/Burget11.pdf:PDF},
  owner = {antho},
  timestamp = {2011.11.17}
}

@ARTICLE{Burton87,
  author = {David K. Burton},
  title = {{Text-Dependent Speaker Verification Using Vector Quantization Source
	Coding}},
  journal = tassp,
  year = {1987},
  volume = {35},
  pages = {133--143},
  file = {Burton87.pdf:Speaker_reco/Text_dependent/Burton87.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.17}
}

@ARTICLE{Burki08,
  author = {Audrey B{\"u}rki and C\'{e}dric Gendrot and Guillaume Gravier and
	George Linares and C{\'e}cile Fougeron},
  title = {{Alignement automatique et analyse phon\'etique: comparaison de diff\'erents
	syst\`emes pour l'analyse du schwa}},
  journal = tal,
  year = {2008},
  volume = {49},
  pages = {165--197},
  file = {Burki08.pdf:Divers/Burki08.pdf:PDF},
  owner = {antho},
  timestamp = {2009.04.30}
}

@MISC{Campbell94,
  author = {Joseph Campbell and Alan L. Higgins},
  title = {A. YOHO speaker verification corpus LDC94s16 (available on LCD website:
	http://www.ldc.upenn.edu)},
  year = {1994},
  owner = {antho},
  timestamp = {2012.03.02}
}

@ARTICLE{Campbell97,
  author = {Joseph P. Campbell},
  title = {{Speaker recognition: a tutorial}},
  journal = ieee,
  year = {1997},
  volume = {85},
  pages = {1437-1462},
  number = {9},
  month = {September},
  abstract = {A tutorial on the design and development of automatic speaker-recognition
	systems is presented. Automatic speaker recognition is the use of
	a machine to recognize a person from a spoken phrase. These systems
	can operate in two modes: to identify a particular person or to verify
	a person's claimed identity. Speech processing and the basic components
	of automatic speaker-recognition systems are shown and design tradeoffs
	are discussed. Then, a new automatic speaker-recognition system is
	given. This recognizer performs with 98.9% correct decalcification.
	Last, the performances of various systems are compared},
  doi = {10.1109/5.628714},
  file = {Campbell97.pdf:Speaker_reco/Divers/Campbell97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@INPROCEEDINGS{Campbell95,
  author = {Joseph P. Campbell},
  title = {{Testing with the YOHO CD-ROM voice verification corpus}},
  booktitle = icassp,
  year = {1995},
  pages = {341-344},
  owner = {antho},
  timestamp = {2012.03.02}
}

@INPROCEEDINGS{Campbell99,
  author = {Joseph P. Campbell and Douglas A. Reynolds},
  title = {{Corpora for the evaluation of speaker recognition systems}},
  booktitle = icassp,
  year = {1999},
  volume = {2},
  pages = {829--832},
  organization = {IEEE},
  file = {Campbell99.pdf:Base_de_donnees/Campbell99.pdf:PDF}
}

@INPROCEEDINGS{Campbell06_a,
  author = {Campbell, WM and Campbell, JP and Reynolds, DA and Singer, E. and
	Torres-Carrasquillo, PA},
  title = {{Support vector machines for speaker and language recognition}},
  booktitle = {Computer Speech \& Language},
  year = {2006},
  volume = {20},
  pages = {210--229},
  publisher = {Elsevier},
  journal = {Computer Speech \& Language},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Campbell10,
  author = {William Campbell and Najim Dehak and Zahi Karam and Alan McCree and
	Doug Reynolds and Fred Richardson and Douglas Sturim and Pedro Torres-Carrasquillo},
  title = {{MITLL 2010 Speaker Recognition Evaluation System Description}},
  booktitle = {{NIST Speaker Recognition Evaluation Workshop}},
  year = {2010},
  file = {Campbell10.pdf:Speaker_reco/NIST/Campbell10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.24}
}

@ARTICLE{Campbell06,
  author = {Campbell, W.M. and Sturim, DE and Reynolds, DA},
  title = {{Support Vector Machines Using GMM Supervectors for Speaker Verification}},
  journal = {IEEE Signal Processing Letters},
  year = {2006},
  volume = {13},
  pages = {308},
  number = {5},
  owner = {antho},
  publisher = {Institute of Electrical and Numerics Engineers},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Campbell03,
  author = {William M. Campbell},
  title = {{A SVM/HMM system for speaker recognition}},
  booktitle = icassp,
  year = {2003},
  pages = {209--212},
  file = {Campbell03.pdf:Speaker_reco/SVM/Campbell03.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.08}
}

@INPROCEEDINGS{Campbell05,
  author = {William M. Campbell and Douglas A. Reynolds and Joseph P. Campbell
	and Brady, KJ},
  title = {{Estimating and Evaluating Confidence for Forensic Speaker Recognition}},
  booktitle = icassp,
  year = {2005},
  volume = {1},
  pages = {717--720},
  organization = {IEEE},
  file = {Campbell05.pdf:Speaker_reco/Useful_information/Campbell05.pdf:PDF}
}

@INPROCEEDINGS{Campbell07,
  author = {William M. Campbell and Fred Richardson and Douglas A. Reynolds},
  title = {{Language recognition with word lattices and support vector machines}},
  booktitle = {Acoustics, Speech and Signal Processing, 2007. ICASSP 2007. IEEE
	International Conference on},
  year = {2007},
  volume = {4},
  organization = {IEEE},
  file = {Campbell07.pdf:Language_reco/Campbell07.pdf:PDF},
  isbn = {1424407273},
  issn = {1520-6149}
}

@INPROCEEDINGS{Campbell06_c,
  author = {William M. Campbell and Douglas E. Sturim and Douglas A. Reynolds
	and Alex Solomonoff},
  title = {{SVM based speaker verification using a GMM supervector kernel and
	NAP variability compensation}},
  booktitle = {Proc. ICASSP},
  year = {2006},
  volume = {1},
  pages = {97--100},
  owner = {antho},
  timestamp = {2009.10.05}
}

@CONFERENCE{Campbell08,
  author = {William M. Campbell and Douglas E Sturim and Pedro A. Torres-Carrasquillo
	and Douglas A. Reynolds},
  title = {{A comparison of subspace feature-domain methods for language recognition}},
  booktitle = interspeech,
  year = {2008},
  pages = {309--312},
  file = {Campbell08.pdf:Language_reco/Campbell08.pdf:PDF}
}

@INPROCEEDINGS{Carbonell98,
  author = {Carbonell, J. and Goldstein, J.},
  title = {{The use of MMR, diversity-based reranking for reordering documents
	and producing summaries}},
  booktitle = {Proceedings of the 21st annual international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {1998},
  pages = {335--336},
  organization = {ACM New York, NY, USA},
  file = {Carbonell98.pdf:Speaker_reco/Adaptation/MMR/Carbonell98.pdf:PDF}
}

@ARTICLE{Carey92,
  author = {Carey, MJ and Parris, ES},
  title = {{Speaker verification using connected words}},
  journal = {Proc. Institute of Acoustics},
  year = {1992},
  volume = {14},
  pages = {96--100},
  number = {6},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Carey96,
  author = {Carey, MJ and Parris, ES and Lloyd-Thomas, H. and Bennett, S.},
  title = {{Robust prosodic features for speaker identification}},
  booktitle = icslp,
  year = {1996},
  volume = {3},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Carey91,
  author = {Michael J. Carey and Eluned S. Parris and John S. Bridle},
  title = {{A Speaker Verification System Using Alpha-Nets}},
  booktitle = icassp,
  year = {1991},
  volume = {1},
  pages = {397-400},
  address = {Toronto (Canada)},
  month = {April},
  abstract = {Speaker verification is performed by comparing the output probabilities
	of two Markov models of the same phonetic unit. One of these Markov
	models is speaker-specific, being built from utterances from the
	speaker whose identity is to be verified. The second model is built
	from utterances from a large population of speakers. The performance
	of the system is improved by treating the pair of models as a connectionist
	network, an alpha-net, which then allows discriminative training
	to be carried out. Experimental results show that adapting the spectral
	observation probabilities of each state of the model by the back
	propagation of errors can correct misclassification errors. The real-time
	implementation of the system produced an average digit error rate
	of 4.5% and only one misclassification in 600 trials using a five-digit
	sequence},
  doi = {10.1109/ICASSP.1991.150360},
  file = {Carey91.pdf:Speaker_reco/Normalisation/Carey91.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@INPROCEEDINGS{Carre84,
  author = {R. Carre and R. Descout and M. Eskenazi and J. Mariani and M. Rossi},
  title = {{The French language database: defining, planning, and recording
	a large database}},
  booktitle = icassp,
  year = {1984},
  address = {San Diego (USA)},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@ARTICLE{Casacuberta04,
  author = {Casacuberta, F. and Ney, H. and Och, F.J. and Vidal, E. and Vilar,
	J.M. and Barrachina, S. and Garc{\'\i}a-Varea, I. and Llorens, D.
	and Mart{\'\i}nez, C. and Molau, S. and others},
  title = {{Some approaches to statistical and finite-state speech-to-speech
	translation}},
  journal = {Computer Speech \& Language},
  year = {2004},
  volume = {18},
  pages = {25--47},
  number = {1},
  file = {Casacuberta04.pdf:Machine_Translation/Casacuberta04.pdf:PDF},
  issn = {0885-2308},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Castaldo08,
  author = {Fabio Castaldo and Daniele Colibro and Emmanuele Dalmasso and Pietro
	Laface and Claudio Vair},
  title = {{Stream-based speaker segmentation using speaker factors and eigenvoices}},
  booktitle = icassp,
  year = {2008},
  pages = {4133--4136},
  organization = {IEEE},
  issn = {1520-6149}
}

@ARTICLE{Castaldo07,
  author = {Fabio Castaldo and Daniele Colibro and Emanuele Dalmasso and Pietro
	Laface and Claudio Vair},
  title = {{Compensation of nuisance factors for speaker and language recognition}},
  journal = taslp,
  year = {2007},
  volume = {15},
  pages = {1969--1978},
  number = {7},
  file = {Castaldo07.pdf:Language_reco/Castaldo07.pdf:PDF},
  issn = {1558-7916},
  publisher = {IEEE}
}

@INPROCEEDINGS{Cernocky07,
  author = {Jan Cernocky and Lukas Burget and Petr Schwarz and Pavel Matejka
	and Martin Karafiat and Ondrej Glembek and Jiri Kopecky and Igor
	Szoke and Michal Fapso and Frantisek Grezl and Valiantsina Hubeika
	and Ilya Oparin},
  title = {{Search in speech, language identification and speaker recognition
	in Speech@ FIT}},
  booktitle = {Radioelektronika},
  year = {2007},
  pages = {1--6},
  organization = {IEEE},
  file = {Cernocky07.pdf:Information_Retrieval/Cernocky07.pdf:PDF},
  isbn = {1424408210}
}

@ARTICLE{Cetingul06,
  author = {Hasan Ertan Cetingul and Engin Erzin and Yucel Yemze. and A. Murat
	Tekalp},
  title = {{Multimodal speaker/speech recognition using lip motion, lip texture
	and audio}},
  journal = {Signal processing},
  year = {2006},
  volume = {86},
  pages = {3549-3558},
  number = {12},
  abstract = {We present a new multimodal speaker/speech recognition system that
	integrates audio, lip texture and lip motion modalities. Fusion of
	audio and face texture modalities has been investigated in the literature
	before. The emphasis of this work is to investigate the benefits
	of inclusion of lip motion modality for two distinct cases: speaker
	and speech recognition. The audio modality is represented by the
	well-known met-frequency cepstral coefficients (MFCC) along with
	the first and second derivatives, whereas lip texture modality is
	represented by the 2D-DCT coefficients of the luminance component
	within a bounding box about the lip region. In this paper, we employ
	a new lip motion modality representation based on discriminative
	analysis of the dense motion vectors within the same bounding box
	for speaker/speech recognition. The fusion of audio, lip texture
	and lip motion modalities is performed by the so-called reliability
	weighted sttmmation (RWS) decision rule. Experimental results show
	that inclusion of lip motion modality provides further performance
	gains over those which are obtained by fusion of audio and lip texture
	alone, in both speaker identification and isolated word recognition
	scenarios.},
  owner = {larcher},
  timestamp = {2007.03.26}
}

@ARTICLE{Chakroborty10,
  author = {Sandipan Chakroborty and Goutam Saha},
  title = {{Feature selection using singular value decomposition and QR factorization
	with column pivoting for text-independent speaker identification}},
  journal = {Speech Communication},
  year = {2010},
  volume = {52},
  pages = {693--709},
  number = {9},
  file = {Chakroborty10.pdf:Speaker_reco/Divers/Chakroborty10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.06}
}

@MISC{Chang01,
  author = {Chang, C.C. and Lin, C.J.},
  title = {{LIBSVM: a library for support vector machines}},
  publisher = {Citeseer}
}

@PHDTHESIS{Charlet97b,
  author = {Delphine Charlet},
  title = {{Authentification vocale du locuteur à travers le réseau téléphonique}},
  school = {ENST},
  year = {1997},
  owner = {antho},
  timestamp = {2009.06.06}
}

@ARTICLE{Charlet97,
  author = {Delphine Charlet and Denis Jouvet},
  title = {{Optimizing feature set for speaker verification}},
  journal = {Pattern Recognition Letters},
  year = {1997},
  volume = {18},
  pages = {873--879},
  number = {9},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@ARTICLE{Charlet00,
  author = {Delphine Charlet and Denis Jouvet and Collin, O.},
  title = {{An alternative normalization scheme in HMM-based text-dependent
	speaker verification}},
  journal = {Speech Communication},
  year = {2000},
  volume = {31},
  pages = {113--120},
  number = {2-3},
  file = {Charlet00.pdf:Speaker_reco/Text_dependent/Charlet00.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Charton10,
  author = {Eric Charton and Anthony Larcher and Christophe L\'evy and Jean-Francois
	Bonastre},
  title = {{Mistral: open source biometric platform}},
  booktitle = sac,
  year = {2010},
  address = {Sierre (Switzerland)},
  month = {march}
}

@ARTICLE{Chatzis09,
  author = {Sotirios Chatzis and Theodora Varvarigou},
  title = {{Factor Analysis Latent Subspace Modeling and Robust Fuzzy Clustering
	Using $ t $-Distributions}},
  journal = {IEEE Transactions on Fuzzy Systems},
  year = {2009},
  volume = {17},
  pages = {505--517},
  number = {3},
  file = {Chatzis09.pdf:Outils/StudentT/Chatzis09.pdf:PDF},
  issn = {1063-6706},
  publisher = {IEEE}
}

@INPROCEEDINGS{Chatzis07,
  author = {Sotirios Chatzis and Theodora Varvarigou},
  title = {{A Robust to Outliers Hidden Markov Model with Application in Text-Dependent
	Speaker Identification}},
  booktitle = {International Conference on Signal Processing and Communications},
  year = {2007},
  pages = {804--807},
  file = {Chatzis07.pdf:Speaker_reco/Text_dependent/Chatzis07.pdf:PDF}
}

@INPROCEEDINGS{Che96,
  author = {Chi Wei Che and Qiguang Lin and Dong-Suk Yuk},
  title = {{An HMM approach to text-prompted speaker verification}},
  booktitle = {1996 IEEE International Conference on Acoustics, Speech, and Signal
	Processing, 1996. ICASSP-96. Conference Proceedings.},
  year = {1996},
  volume = {2},
  pages = {673--676},
  file = {Che96.pdf:Speaker_reco/Text_dependent/Che96.pdf:PDF}
}

@ARTICLE{Chelba08,
  author = {Ciprian Chelba and Timothy J. Hazen and Murat Saraclar},
  title = {Retrieval and browsing of spoken content},
  journal = {IEEE Signal Processing Magazine},
  year = {2008},
  volume = {25},
  pages = {39--49},
  number = {3},
  file = {Chelba08.pdf:Spoken_Document_Retrieval/Chelba08.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Chellappa95,
  author = {Rama Chellappa and Charles L. Wilson and Saad Sirohey},
  title = {{Human and machine recognition of faces, a survey}},
  journal = ieee,
  year = {1995},
  volume = {83},
  pages = {705-741},
  number = {5},
  month = {May},
  abstract = {The goal of this paper is to present a critical survey of existing
	literature on human and machine recognition of faces. Machine recognition
	of faces has several applications, ranging from static matching of
	controlled photographs as in mug shots matching and credit card verification
	to surveillance video images. Such applications have different constraints
	in terms of complexity of processing requirements and thus present
	a wide range of different technical challenges. Over the last 20
	years researchers in psychophysics, neural sciences and engineering,
	image processing analysis and computer vision have investigated a
	number of issues related to face recognition by humans and machines.
	Ongoing research activities have been given a renewed emphasis over
	the last five years. Existing techniques and systems have been tested
	on different sets of images of varying complexities. But very little
	synergism exists between studies in psychophysics and the engineering
	literature. Most importantly, there exists no evaluation or benchmarking
	studies using large databases with the image quality that arises
	in commercial and law enforcement applications In this paper, we
	first present different applications of face recognition in commercial
	and law enforcement sectors. This is followed by a brief overview
	of the literature on face recognition in the psychophysics community.
	We then present a detailed overview of move than 20 years of research
	done in the engineering community. Techniques for segmentation/location
	of the face, feature extraction and recognition are reviewed. Global
	transform and feature based methods using statistical, structural
	and neural classifiers are summarized},
  doi = {10.1109/5.381842},
  file = {Human and machine recognition of faces a survey.pdf:/home/larcher/Biblio/Video/Human and machine recognition of faces a survey.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.02}
}

@INPROCEEDINGS{Chen07,
  author = {Chen, B. and Chen, Y.T.},
  title = {{Word topical mixture models for extractive spoken document summarization}},
  booktitle = {IEEE International Conference on Multimedia and Expo},
  year = {2007},
  pages = {52--55},
  file = {Chen07.pdf:Speaker_reco/Adaptation/MMR/Chen07.pdf:PDF}
}

@ARTICLE{Chen96,
  author = {Ke Chen and Dahong Xie and Huisheng Chi},
  title = {{A modified HME architecture for text-dependent speaker identification}},
  journal = tnn,
  year = {1996},
  volume = {7},
  pages = {1309-1313},
  number = {5},
  month = {September},
  abstract = {A modified hierarchical mixtures of experts (HME) architecture is
	presented for text-dependent speaker identification. A new gating
	network is introduced to the original HME architecture for the use
	of instantaneous and transitional spectral information in text-dependent
	speaker identification. The statistical model underlying the proposed
	architecture is presented and learning is treated as a maximum likelihood
	problem; in particular, an expectation-maximization (EM) algorithm
	is also proposed for adjusting the parameters of the proposed architecture.
	An evaluation has been carried out using a database of isolated digit
	utterances by 10 male speakers. Experimental results demonstrate
	that the proposed architecture outperforms the original HME architecture
	in text-dependent speaker identification},
  doi = {10.1109/72.536325},
  file = {Chen96.pdf:Speaker_reco/Text_dependent/Chen96.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@INPROCEEDINGS{Chen01,
  author = {Li-Fen Chen and Hong-Yuan Mark Liao and Ja-Chen Lin},
  title = {Person identification using facial motion},
  booktitle = icip,
  year = {2001},
  volume = {2},
  pages = {677-680},
  address = {Singapore},
  abstract = {A new method for person identification based on facial motion is proposed.
	Facial motion is represented by a high-dimensional feature vector
	which is constructed by concatenating a sequence of motion flow fields.
	Under the proposed representation, each individual can be characterized
	as a feature vector which collects spatial and temporal information
	of a face simultaneously We then make use of this high-dimensional
	spatiotemporal feature vector to perform person identification. The
	experimental results are encouraging and exciting in terms of robustness
	under varying illumination conditions},
  doi = {10.1109/ICIP.2001.958584},
  file = {Chen01.pdf:Video/Chen01.pdf:PDF},
  keywords = {face recognition feature extraction image representation image sequences
	lighting motion estimation video signal processing CCD camera face
	recognition facial motion facial motion representation high-dimensional
	feature vector illumination conditions motion flow estimation motion
	flow fields sequence person identification spatio-temporal feature
	vector},
  owner = {larcher},
  timestamp = {2006.04.19}
}

@INPROCEEDINGS{Chen98,
  author = {Scott Shaobing Chen and Gopalakrishnan, P.S.},
  title = {{Speaker, environment and channel change detection and clustering
	via the bayesian information criterion}},
  booktitle = {Proc. DARPA Broadcast News Transcription and Understanding Workshop},
  year = {1998},
  pages = {127--132},
  file = {Chen98.pdf:Speaker_Diarization/Chen98.pdf:PDF},
  review = {BIC algorithm}
}

@ARTICLE{Chetty06,
  author = {Chetty, G. and Wagner, M.},
  title = {{Face-Voice Authentication Based on 3D Face Models}},
  journal = {Lecture Notes in Computer Science},
  year = {2006},
  volume = {3851},
  pages = {559},
  file = {Chetty06.pdf:Base_de_donnees/Chetty06.pdf:PDF},
  owner = {antho},
  publisher = {Springer},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Chetty06_a,
  author = {Chetty, G. and Wagner, M.},
  title = {{UCBN: A new audio-visual broadcast news corpus for multimodal speaker
	verification studies}},
  booktitle = {Australian International Conference on Speech Science \& Technology},
  year = {2006},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Chetty06_b,
  author = {Chetty, G. and Wagner, M.},
  title = {{Speaking Faces for Face-Voice Speaker Identity Verification}},
  booktitle = {Ninth International Conference on Spoken Language Processing},
  year = {2006},
  organization = {ISCA}
}

@INPROCEEDINGS{Chetty06_c,
  author = {Girija Chetty and Michael Wagner},
  title = {{UCBN: A new audio-visual broadcast news corpus for multimodal speaker
	verification studies}},
  booktitle = {Proceedings of the 11th Australian International Conference on Speech
	Science \& Technology},
  year = {2006},
  address = {Auckland, New Zealand},
  owner = {antho},
  timestamp = {2009.04.29}
}

@INPROCEEDINGS{Chetty05,
  author = {Girija Chetty and Michael Wagner},
  title = {{Liveness detection using cross-modal correlations in face-voice
	person authentication}},
  booktitle = eurospeech,
  year = {2005},
  pages = {2181-2184},
  owner = {antho},
  timestamp = {2008.07.21}
}

@INPROCEEDINGS{Chetty04,
  author = {Girija Chetty and Michael Wagner},
  title = {{"Liveness" verification in Audio-Video Authentication}},
  booktitle = icslp,
  year = {2004},
  address = {Jeju (Korea)},
  file = {Chetty041.pdf:Audio-Video/Chetty041.pdf:PDF;Chetty04.pdf:Audio-Video/Chetty04.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Chetty041,
  author = {Girija Chetty and Michael Wagner},
  title = {{Automated lip feature extraction for liveness verification in audio-video
	authentication}},
  booktitle = icslp,
  year = {2004},
  pages = {17-22},
  address = {Jeju (Korea)},
  file = {Chetty041.pdf:Audio-Video/Chetty041.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Chia07,
  author = {Tee Kiah Chia and Haizhou Li and Hwe Tou Ng},
  title = {{A statistical language modeling approach to lattice-based spoken
	document retrieval}},
  booktitle = {Joint Meeting of the Conference on Empirical Methods in Natural Language
	Processing and the Conference on Natural Language Learning (EMNLP-CoNLL)},
  year = {2007},
  pages = {810--818},
  file = {Chia07.pdf:Spoken_Document_Retrieval/Chia07.pdf:PDF}
}

@ARTICLE{Chia10,
  author = {Tee Kiah Chia and Khe Chai Sim and Haizhou Li and Hwee Tou Ng},
  title = {{Statistical lattice-based spoken document retrieval}},
  journal = {ACM Transactions on Information Systems (TOIS)},
  year = {2010},
  volume = {28},
  pages = {2},
  number = {1},
  file = {Chia10.pdf:Spoken_Document_Retrieval/Chia10.pdf:PDF},
  publisher = {ACM}
}

@INPROCEEDINGS{Chia08,
  author = {Tee Kiah Chia and Khe Chai Sim and Haizhou Li and Hwee Tou Ng},
  title = {{A lattice-based approach to query-by-example spoken document retrieval}},
  booktitle = {ACM SIGIR conference on Research and development in information retrieval},
  year = {2008},
  pages = {363--370},
  organization = {ACM},
  file = {Chia08.pdf:Spoken_Document_Retrieval/Chia08.pdf:PDF}
}

@ARTICLE{Chibelushi02,
  author = {Claude C. Chibelushi and Farzin Deravi and John S. D. Mason},
  title = {{A Review of Speech-Based Bimodal Recognition}},
  journal = tm,
  year = {2002},
  volume = {4},
  pages = {23-37},
  number = {1},
  month = {March},
  abstract = {Speech recognition and speaker recognition by machine are crucial
	ingredients for many important applications such as natural and flexible
	human-machine interfaces. Most developments in speech-based automatic
	recognition have relied on acoustic speech as the sole input signal,
	disregarding its visual counterpart. However, recognition based on
	acoustic speech alone can be afflicted with deficiencies that preclude
	its use in many real-world applications, particularly under adverse
	conditions. The combination of auditory and visual modalities promises
	higher recognition accuracy and robustness than can be obtained with
	a single modality. Multimodal recognition is therefore acknowledged
	as a vital component of the next generation of spoken language systems.
	The paper reviews the components of bimodal recognizers, discusses
	the accuracy of bimodal recognition, and highlights some outstanding
	research issues as well as possible application domains},
  doi = {10.1109/6046.985551},
  file = {Chibelushi02.pdf:Audio-Video/Chibelushi02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@INPROCEEDINGS{Chibelushi97,
  author = {Claude C. Chibelushi and John S. D. Mason and Farzin Deravi},
  title = {{Feature-level data fusion for bimodal person recognition}},
  booktitle = {Sixth International Conference on Image Processing and Its Applications},
  year = {1997},
  owner = {antho},
  timestamp = {2008.07.24}
}

@ARTICLE{Chien03,
  author = {Jen\-Tzung Chien and Chih-Hsien Huang},
  title = {{Bayesian Learning of Speech Duration Models}},
  journal = tsap,
  year = {2003},
  volume = {11},
  pages = {558-567},
  number = {6},
  month = {november},
  abstract = {This paper presents the Bayesian speech duration modeling and learning
	for hidden Markov model (HMM) based speech recognition. We focus
	on the sequential learning of HMM state duration using quasi-Bayes
	(QB) estimate. The adapted duration models are robust to nonstationary
	speaking rates and noise conditions. In this study, the Gaussian,
	Poisson, and gamma distributions are investigated to characterize
	the duration models. The maximum a posteriori (MAP) estimate of gamma
	duration model is developed. To exploit the sequential learning,
	we adopt the Poisson duration model incorporated with gamma prior
	density, which belongs to the conjugate prior family. When the adaptation
	data are sequentially observed, the gamma posterior density is produced
	with twofold advantages. One is to determine the optimal QB duration
	parameter, which can be merged in HMMs for speech recognition. The
	other one is to build the updating mechanism of gamma prior statistics
	for sequential learning. EM algorithm is applied to fulfill QB parameter
	estimation. The adaptation of overall HMM parameters can be performed
	simultaneously. In the experiments, the proposed adaptive duration
	model improves the speech recognition performance of Mandarin broadcast
	news and noisy connected digits. The batch and sequential learning
	are respectively investigated for MAP and QB duration models.},
  doi = {10.1109/TSA.2003.818114},
  file = {Chien03.pdf:Speech_reco/Continuous/Chien03.pdf:PDF},
  keywords = {Bayes methods Gaussian distribution Poisson distribution gamma distribution
	hidden Markov models learning systems maximum likelihood estimation
	speech recognition},
  owner = {larcher},
  timestamp = {2007.04.02},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1255444&isnumber=28079}
}

@TECHREPORT{Cholet96,
  author = {Gerard Chollet and Jean-Luc Cochard and Andrei Constantinescu and
	Cedric Jaboulet and Philippe Langlais},
  title = {{Swiss French PolyPhone and PolyVar: telephone speech databases to
	model inter- and intra-speaker variability}},
  institution = {IDIAP},
  year = {1996},
  file = {Cholet96.pdf:Base_de_donnees/Cholet96.pdf:PDF},
  owner = {antho},
  timestamp = {2012.03.14}
}

@TECHREPORT{Choudhury98,
  author = {Tanzeem Choudhury and Brian Clarkson and Tony Jebara and Alex Pentland
	and Perceptual computing Group},
  title = {{Multimodal Person Recognition using Unconstrained Audio and Video}},
  institution = {MIT Media-Laboratory},
  year = {1998},
  abstract = {We propose a person identification technique that can recognize and
	verify people from unconstrained video and audio. We do not expect
	fully frontal face image or clean speech as our input. Our recognition
	algorithm can detect and compensate for pose variation and changes
	in the auditory background and also select the most reliable video
	frame and audio clip to use for recognition. We also use 3D depth
	information of a human head to detect the presence of an actual person
	as opposed to an image of that person. Our system achieves 100% recognition
	and verification rates on natural real-time input with 26 registered
	clients.},
  file = {Choudhury98.pdf:Audio-Video/Choudhury98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Chowdhury10,
  author = {Md Fozur Rahman Chowdhury and Sid-Ahmed Selouani and Douglas O'Shaughnessy},
  title = {{Text-independent distributed speaker identification and verification
	using GMM-UBM speaker models for mobile communications}},
  booktitle = {International Conference on Information Science, Signal Processing
	and their Application},
  year = {2010},
  file = {Chowdhury10.pdf:Speaker_reco/Divers/Chowdhury10.pdf:PDF},
  owner = {antho},
  timestamp = {2012.01.16}
}

@INPROCEEDINGS{Cieri04,
  author = {Christopher Cieri and David Miller and Kevin Walker},
  title = {{The Fisher Corpus: a Resource for the Next Generations of Speech-to-Text}},
  booktitle = {{Fourth International Conference on Language Resources and Evaluation}},
  year = {2004},
  owner = {antho},
  timestamp = {2010.04.16}
}

@INPROCEEDINGS{Clarkson97,
  author = {Philip Clarkson and Ronald Rosenfeld},
  title = {{Statistical language modeling using the CMU-Cambridge toolkit}},
  booktitle = eurospeech,
  year = {1997},
  pages = {2707--2710},
  file = {Clarkson97.pdf:Language_reco/Clarkson97.pdf:PDF}
}

@ARTICLE{Coello07,
  author = {Coello, C.A.C.},
  title = {{Evolutionary Algorithms: Basic Concepts and Applications in Biometrics}},
  journal = {Image pattern recognition: synthesis and analysis in biometrics},
  year = {2007},
  volume = {12},
  pages = {289},
  file = {Coello07.pdf:Artificial_Immune_System/Coello07.pdf:PDF},
  owner = {antho},
  publisher = {World Scientific Pub Co Inc},
  timestamp = {2010.08.05}
}

@TECHREPORT{Edinburgh00,
  author = {Collectif},
  title = {{Large Scale Evaluation of Automatic Speaker Verification Technology}},
  institution = {The Center for Communication Interface Research, University of Edinburgh},
  year = {2000},
  file = {Edinburgh00.pdf:Speaker_reco/Text_dependent/Edinburgh00.pdf:PDF},
  owner = {antho},
  timestamp = {2011.11.24}
}

@TECHREPORT{Biobimo05,
  author = {{Consortium BIOBIMO}},
  title = {{Projet BIOBIMO, Annexe Technique}},
  institution = {{Universit\'e d'Avignon et des Pays de Vaucluse}},
  year = {2005},
  owner = {antho},
  timestamp = {2009.05.28}
}

@ARTICLE{Cooper95,
  author = {Cooper, W.S.},
  title = {{Some inconsistencies and misidentified modeling assumptions in probabilistic
	information retrieval}},
  journal = {ACM Transactions on Information Systems},
  year = {1995},
  volume = {13},
  pages = {100--111},
  number = {1},
  file = {Cooper95.pdf:Speaker_reco/Adaptation/MMR/Cooper95.pdf:PDF}
}

@ARTICLE{Cornuejols02,
  author = {Antoine Cornu\'ejols},
  title = {{Une nouvelle m\'ethode d'apprentissage : Les SVM S\'eparateurs \`a
	Vaste Marge.}},
  journal = {Bulletin de l'Association Fran{\c c}aise d'Intelligence Artificielle,
	AFIA},
  year = {2002},
  volume = {51},
  pages = {14-23},
  owner = {larcher},
  timestamp = {2006.05.19}
}

@ARTICLE{Cortes04,
  author = {Cortes, C. and Mohri, M.},
  title = {{Confidence intervals for the area under the ROC curve}},
  journal = {Advances in neural information processing systems},
  year = {2004},
  volume = {17},
  pages = {305--312},
  file = {Cortes04.pdf:Outils/interval_confiance/Cortes04.pdf:PDF},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Craw92,
  author = {Ian Craw and David tock and Alan Bennet},
  title = {{Finding Face Features}},
  booktitle = {European Conference in Computer Vision},
  year = {1992},
  pages = {92-96},
  address = {Santa Margherita (Italy)},
  month = {May},
  owner = {larcher},
  timestamp = {2006.05.29}
}

@INPROCEEDINGS{Crowley97,
  author = {James L. Crowley and Francois Berard},
  title = {{Multi-Modal tracking of faces for video communications}},
  booktitle = cvpr,
  year = {1997},
  pages = {640-645},
  address = {Puerto Rico},
  month = {June},
  abstract = {Visual processes to detect and track faces for video compression and
	transmission. The system is based on an architecture in which a supervisor
	selects and activates visual processes in cyclic manner. Control
	of visual processes is made possible by a confidence factor which
	accompanies each observation. Fusion of results into a unified estimation
	for tracking is made possible by estimating a covariance matrix with
	each observation. Visual processes for face tracking are described
	using blink detection, normalised color histogram matching, and cross
	correlation (SSD and NCC). Ensembles of visual processes are organised
	into processing states so as to provide robust tracking. Transition
	between states is determined by events detected by processes. The
	result of face detection is fed into recursive estimator (Kalman
	filter). The output from the estimator drives a PD controller for
	a pan/tilt/zoom camera. The resulting system provides robust and
	precise tracking which operates continuously at approximately 20
	images per second on a 150 megahertz computer workstation},
  doi = {10.1109/CVPR.1997.609393},
  keywords = {Kalman filters covariance matrices data compression face recognition
	image colour analysis image matching tracking video signal processing},
  owner = {larcher},
  timestamp = {2006.05.09}
}

@INPROCEEDINGS{Cumani11,
  author = {Sandro Cumani and Pier Domenico Batzu and Daniele Colibro and Claudio
	Vair and Pietro Laface and Vasileios Vasilakakis},
  title = {{Comparison of Speaker Recognition Approaches for Real Applications}},
  booktitle = interspeech,
  year = {2011},
  pages = {2365--2368},
  file = {Cumani11.PDF:Speaker_reco/Divers/Cumani11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.10}
}

@INPROCEEDINGS{Cumani11_a,
  author = {Sandro Cumani and Niko Brummer and Lukas Burget and Pietro Laface},
  title = {{Fast discriminative speaker verification in the I-Vector space}},
  booktitle = icassp,
  year = {2011},
  pages = {4852--4855},
  file = {Cumani11_a.pdf:Speaker_reco/FA/I-Vector/Cumani11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@INPROCEEDINGS{Cumani12_a,
  author = {Sandro Cumani and Ondrej Glembek and Niko Brummer and Edward de Villiers
	and Pietro Laface},
  title = {{Gender independent discriminative speaker recognition in i-vector
	space}},
  booktitle = icassp,
  year = {2012},
  file = {Cumani12_a.pdf:Speaker_reco/FA/I-Vector/Cumani12_a.pdf:PDF},
  owner = {antho},
  timestamp = {2012.04.03}
}

@INPROCEEDINGS{Cumani12_b,
  author = {Sandro Cumani and Oldrich Plchot Martin Karafit},
  title = {{Independent Component Analysis and MLLR transforms for speaker identification}},
  booktitle = icassp,
  year = {2012},
  file = {Cumani12_b.pdf:Speaker_reco/FA/I-Vector/Cumani12_b.pdf:PDF},
  owner = {antho},
  timestamp = {2012.04.03}
}

@BOOK{Cunado97,
  title = {{Using gait as a biometric, via phase-weighted magnitude spectra}},
  publisher = {Springer},
  year = {1997},
  author = {David Cunado and Mark S. Nixon and John N. Carter},
  booktitle = {Audio-And Video-Based Biometric Person Authentication: First International
	Conference, Avbpa'97, Crans-Montana, Switzerland, March 12-14, 1997:
	Proceedings},
  organization = {Springer},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Dai96,
  author = {Ying Dai and Yasuaki Nakano},
  title = {{Face-texture model based on SGLD and its application in face detection
	in a color scene}},
  journal = {Pattern Recognition},
  year = {1996},
  volume = {29},
  pages = {1007-1017},
  number = {6},
  month = {June},
  abstract = {This paper proposed a new method for the full face detection from
	complex backgrounds. Based on feature parameters of space gray-level
	dependence (SGLD) matrix, the face-texture model composed by a set
	of inequalities was derived. A color information utilization incorporated
	with the face-texture feature was also investigated. Using the face-texture
	model, we designed a kind of scanning scheme for face detection in
	color scenes, in which the orange-like parts including the face areas
	were enhanced by utilizing the I component of the YIQ color system.
	The experiments showed that this method can locate the face position
	in the complex backgrounds effectively.},
  doi = {10.1016/0031-3203(95)00139-5},
  file = {Dai96.pdf:Video/Face_detection/Dai96.pdf:PDF},
  keywords = {Space gray-level dependence matrix; Face detection; Color information;
	Background; Face-texture model},
  owner = {larcher},
  timestamp = {2006.05.30}
}

@INPROCEEDINGS{Dan08,
  author = {Qu Dan and Yan Honggang and Tang Hui and Wang Bingxi},
  title = {{Two Schemes for Automatic Speaker Recognition over VOIP}},
  booktitle = {IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial
	Application},
  year = {2008},
  pages = {695--699},
  organization = {IEEE},
  file = {Dan08.pdf:Speaker_reco/Compression/Dan08.pdf:PDF}
}

@INPROCEEDINGS{Daoudi07,
  author = {Khalid Daoudi and Jerome Louradour},
  title = {{A novel strategy for speaker verification based on SVM classification
	of pairs of speech sequences}},
  booktitle = {{Symposium on Signal Processing and Its Applications}},
  year = {2007},
  pages = {1--4},
  doi = {10.1109/ISSPA.2007.4555546},
  file = {Daoudi07.pdf:Speaker_reco/SVM/Daoudi07.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.24}
}

@INPROCEEDINGS{Das08_a,
  author = {Amitava Das and Gokul Chittaranjan},
  title = {{Text-Dependent Speaker Recognition by Efficient Capture of Speaker
	Dynamics in Compressed Time-Frequency Representations of Speech}},
  booktitle = interspeech,
  year = {2008},
  pages = {1921-192},
  file = {Das08_a.pdf:Speaker_reco/Text_dependent/Das08_a.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.13}
}

@INPROCEEDINGS{Das08_d,
  author = {Amitava Das and Gokul Chittaranjan},
  title = {{Automated speaker recognition using compressed temporal spectral
	dynamic information of password spectrograms}},
  booktitle = {ISCA Tutorial and Research Workshop on Speech Analysis and Processing
	for Knowledge Discovery},
  year = {2008},
  file = {Das08_d.pdf:Speaker_reco/Text_dependent/Das08_d.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.13}
}

@INPROCEEDINGS{Das08_c,
  author = {Amitava Das and Gokul Chittaranjan and Gopala K. Anumanchipalli},
  title = {{Usefulness of Text-Conditioning and A New Database for Text-Dependent
	Speaker Recognition Research}},
  booktitle = interspeech,
  year = {2008},
  pages = {1925--1928},
  file = {Das08_c.PDF:Speaker_reco/Text_dependent/Das08_c.PDF:PDF}
}

@INPROCEEDINGS{Das08_b,
  author = {Amitava Das and Ohil K. Manyam and Makarand Tapaswi and Veeresh Taranalli},
  title = {{Multilingual spoken-password based user authentication in emerging
	economies using cellular phone networks}},
  booktitle = {IEEE Spoken Language Technology Workshop},
  year = {2008},
  pages = {5--8},
  organization = {IEEE},
  file = {Das08_b.pdf:Speaker_reco/Text_dependent/Das08_b.pdf:PDF}
}

@INPROCEEDINGS{Das10,
  author = {Amitava Das and Makarand Tapaswi},
  title = {Direct modeling of spoken passwords for text-dependent speaker recognition
	by compressed time-feature representations},
  booktitle = icassp,
  year = {2010},
  file = {Das10.pdf:Speaker_reco/Text_dependent/Das10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.07.27}
}

@BOOK{Dasarathy94,
  title = {{Decision Fusion}},
  publisher = {IEEE Computer Society Press},
  year = {1994},
  author = {Belur V. Dasarathy},
  journal = {IEEE Computer Society Press},
  owner = {larcher},
  timestamp = {2006.07.03}
}

@ARTICLE{Dasgupta03,
  author = {Dasgupta, D. and Ji, Z. and Gonzalez, F. and others},
  title = {{Artificial immune system (AIS) research in the last five years}},
  journal = {Evolutionary Computation},
  year = {2003},
  volume = {1},
  pages = {123--130},
  file = {Dasgupta03.pdf:Artificial_Immune_System/Dasgupta03.pdf:PDF}
}

@TECHREPORT{Daugman00,
  author = {John Daugman},
  title = {{Biometric decision landscape}},
  institution = {University of Cambridge, Computer Laboratory},
  year = {2000},
  owner = {antho},
  timestamp = {2008.11.21}
}

@ARTICLE{Davis80,
  author = {Steven B. Davis and Paul Mermelstein},
  title = {{Comparison of Parametric Representations for Monosyllabic Word Recognition
	in Continuously Spoken Sentences}},
  journal = taslp,
  year = {1980},
  volume = {28},
  pages = {357--366},
  number = {4},
  file = {Davis80.pdf:Parametrisation/Davis80.pdf:PDF},
  owner = {antho},
  timestamp = {2012.01.26}
}

@INPROCEEDINGS{Dean08_b,
  author = {Dean, D.B. and Lucey, P.J. and Sridharan, S. and Wark, T.J.},
  title = {{Fused-HMM Adaptation of Synchronous HMMs for Audio-Visual Speech
	Recognition}},
  booktitle = interspeech,
  year = {2008},
  volume = {1051-2004},
  file = {Dean08_b.pdf:Audio-Video/Dean08_b.pdf:PDF},
  journal = {Digital Signal Processing},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Dean05,
  author = {David Dean and Patrick Lucey and Sridha Sridharan and Tim Wark},
  title = {{Comparing audio and visual information for speech processing}},
  booktitle = {Proceedings of the Eighth International Symposium on Signal Processing
	and Its Applications},
  year = {2005},
  volume = {1},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Dean07,
  author = {David Dean and Patrick Lucey and Sridha Sridharan and Timothy J.
	Wark},
  title = {{Weighting and normalisation of synchronous HMMs for audio-visual
	speech recognition}},
  booktitle = avsp,
  year = {2007},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Dean08,
  author = {David Dean and Sridha Sridharan and Patrick Lucey},
  title = {{Cascading Appearance-Based Features for Visual Speaker Verification}},
  booktitle = interspeech,
  year = {2008},
  owner = {antho},
  timestamp = {2008.07.25}
}

@INPROCEEDINGS{Dean06,
  author = {David Dean and Sridha Sridharan and Tim Wark},
  title = {{Audio-visual speaker verification using continuous fused HMMs}},
  booktitle = {HCSNet workshop on Use of vision in human-computer interaction},
  year = {2006},
  volume = {56},
  pages = {87--92},
  organization = {Australian Computer Society, Inc. Darlinghurst, Australia},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Dehak10_b,
  author = {Dehak, N. and Dehak, R. and Glass, J. and Reynolds, D. and Kenny,
	P.},
  title = {{Cosine similarity scoring without score normalization techniques}},
  booktitle = odyssey,
  year = {2010},
  organization = {Odyssey},
  file = {Dehak10_b.pdf:Speaker_reco/FA/I-Vector/Dehak10_b.pdf:PDF}
}

@INPROCEEDINGS{Dehak09,
  author = {Najim Dehak and Read Dehak and Patrick Kenny and Niko Brummer and
	Pierre Ouellet and Pierre Dumouchel},
  title = {{Support Vector Machines versus Fast Scoring in the Low-Dimensional
	Total Variability Space for Speaker Verification}},
  booktitle = interspeech,
  year = {2009},
  pages = {1559-1562},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/FA/I-Vector/Dehak09.pdf:PDF}
}

@ARTICLE{Dehak11_a,
  author = {Najim Dehak and Patrick Kenny and Reda Dehak and Pierre Dumouchel
	and Pierre Ouellet},
  title = {{Front-End Factor Analysis for Speaker Verification}},
  journal = taslp,
  year = {2011},
  volume = {19},
  pages = {788--798},
  number = {4},
  file = {Dehak10.pdf:Speaker_reco/FA/I-Vector/Dehak10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.07.02}
}

@INPROCEEDINGS{Dehak11,
  author = {Najim Dehak and Pedro A. Torres-Carrasquillo and Douglas A. Reynolds
	and Reda Dehak},
  title = {{Language Recognition via Ivectors and Dimensionality Reduction}},
  booktitle = interspeech,
  year = {2011},
  file = {Dehak11.PDF:Language_reco/Dehak11.PDF:PDF}
}

@INPROCEEDINGS{Delacretaz98,
  author = {Delacretaz, DP and Hennebert, J.},
  title = {{Text-prompted speaker verification experiments with phonemespecific
	MLPs}},
  booktitle = icassp,
  year = {1998},
  volume = {2},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Deleglise96,
  author = {Paul Deleglise and Alexandrina Rogozan and Mamoun Alissali},
  title = {{Asynchronous integration of audio and visual sources in bimodal
	automatic speech recognition}},
  booktitle = eusipco,
  year = {1996},
  pages = {10--13},
  file = {Deleglise96.pdf:Ventriloquie/Deleglise96.pdf:PDF},
  journal = {Proc. EUSIPCO 1996},
  owner = {antho},
  timestamp = {2009.02.09}
}

@ARTICLE{Demenko08,
  author = {Grasyna Demenko and Stefan Grocholewski and Katarzyna Klessa and
	Jerzy Ogorkiewicz and Agnieszka Wagner and Marek Lange and Daniel
	Sledzinski and Natalia Cylwik},
  title = {{JURISDIC--Polish speech database for taking dictation of legal texts}},
  journal = {GA},
  year = {2008},
  volume = {1},
  pages = {1280--1287},
  file = {Demenko08.pdf:Base_de_donnees/Demenko08.pdf:PDF}
}

@ARTICLE{Dempster77,
  author = {Arthur Pentland Dempster and Nam M. Laird and Donald B. Rubin},
  title = {{Maximum Likelihood from Incomplete Data via the EM Algorithm}},
  journal = {Journal of the Royal Statistical Society},
  year = {1977},
  volume = {39},
  pages = {1--38},
  number = {1},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates
	from incomplete data is presented at various levels of generality.
	Theory showing the monotone behaviour of the likelihood and convergence
	of the algorithm is derived. Many examples are sketched, including
	missing value situations, applications to grouped, censored or truncated
	data, finite mixture models, variance component estimation, hyperparameter
	estimation, iteratively reweighted least squares and factor analysis.},
  file = {Dempster77.pdf:Outils/EM/Dempster77.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.04.19}
}

@ARTICLE{Digalakis95,
  author = {Vassilios Digalakis and Leonardo Neumeyer},
  title = {{Fast speaker adaptation using constrained estimation of Gaussian
	mixtures}},
  journal = tsap,
  year = {1995},
  volume = {3},
  pages = {357--366},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/Adaptation/MLLR/Digalakis95.pdf:PDF}
}

@INPROCEEDINGS{Digalakis91,
  author = {Digalakis, V. and Rohlicek, JR and Ostendorf, M.},
  title = {{A dynamical system approach to continuous speech recognition}},
  booktitle = icassp,
  year = {1991},
  pages = {289--292},
  file = {Digalakis91.pdf:Speech_reco/Continuous/Digalakis91.pdf:PDF}
}

@INPROCEEDINGS{Doddington01,
  author = {George Doddington},
  title = {{Speaker Recognition based on Idiolectal Differences between Speakers}},
  booktitle = eurospeech,
  year = {2001},
  pages = {2521-2524},
  address = {Aalborg (Denmark)},
  file = {Doddington01.pdf:Speaker_reco/Divers/Doddington01.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.06.26}
}

@INPROCEEDINGS{Doddington98,
  author = {George Doddington and Walter Liggett and Alvin Martin and Mark Przybocki
	and Douglas A. Reynolds},
  title = {{Sheep, goats, lambs and wolves: A statistical analysis of speaker
	performance in the NIST 1998 speaker recognition evaluation}},
  booktitle = icslp,
  year = {1998},
  organization = {ISCA},
  file = {Doddington98.pdf:Speech_reco/Doddington98.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Doddington00,
  author = {George R. Doddington and Mark A. Przybockib and Alvin F. Martin and
	Douglas A. Reynolds},
  title = {{The NIST speaker recognition evaluation - Overview, Methodology,
	Systems, Results, Perspective}},
  journal = {Speech communication},
  year = {2000},
  volume = {31},
  pages = {225--254},
  number = {2-3},
  abstract = {This paper, based on three presentations made in 1998 at the RLA2C
	Workshop in Avignon, discusses the evaluation of speaker recognition
	systems from several perspectives. A general discussion of the speaker
	recognition task and the challenges and issues involved in its evaluation
	is offered. The NIST evaluations in this area and specifically the
	1998 evaluation, its objectives, protocols and test data, are described.
	The algorithms used by the systems that were developed for this evaluation
	are summarized, compared and contrasted. Overall performance results
	of this evaluation are presented by means of detection error trade-off
	(DET) curves. These show the performance trade-off of missed detections
	and false alarms for each system and the effects on performance of
	training condition, test segment duration, the speakers' sex and
	the match or mismatch of training and test handsets. Several factors
	that were found to have an impact on performance, including pitch
	frequency, handset type and noise, are discussed and DET curves showing
	their effects are presented. The paper concludes with some perspective
	on the history of this technology and where it may be going.},
  doi = {10.1016/S0167-6393(99)00080-1},
  file = {Doddington00.pdf:Speaker_reco/Divers/Doddington00.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier Science Publishers B.V., Amsterdam, Netherlands},
  timestamp = {2007.10.04}
}

@ARTICLE{Doledec94,
  author = {Sylvain Doledec and Daniel Chessel},
  title = {{Co-inertia analysis: An alternative method for studying species-environment
	relationships}},
  journal = {Freshwater biology},
  year = {1994},
  volume = {31},
  pages = {277-294},
  abstract = {Methods used for the study of species-environment relationships can
	be grouped into: (i) simple indirect and direct gradient analysis
	and multivariate direct gradient analysis (e.g. canonical correspondence
	analysis), all of which search for non-symmetric patterns between
	environmental data sets and species data sets; and (ii) analysis
	of juxtaposed tables, canonical correlation analysis, and intertable
	ordination, which examine species-environment relationships by considering
	each data set equally. Different analytical techniques are appropriate
	for fulfilling different objectives. We propose a method, co-inertia
	analysis, that can synthesize various approaches encountered in the
	ecological literature. Co-inertia analysis is based on the mathematically
	coherent Euclidean model and can be universally reproduced (i.e.
	independently of software) because of its numerical stability. The
	method performs simultaneous analysis of two tables. The optimizing
	criterion in co-inertia analysis is that the resulting sample scores
	(environmental scores and faunistic scores) are the most covariant.
	Such analysis is particularly suitable for the simultaneous detection
	of faunistic and environmental features in studies of ecosystem structure.
	The method was demonstrated using faunistic and environmental data
	from Friday (Freshwater Biology 18, 87-104, 1987). In this example,
	non-symmetric analyses is inappropriate because of the large number
	of variables (species and environmental variables) compared with
	the small number of samples. Co-inertia analysis is an extension
	of the analysis of cross tables previously attempted by others. It
	serves as a general method to relate any kinds of data set, using
	any kinds of standard analysis (e.g. principal components analysis,
	correspondence analysis, multiple correspondence analysis) or between-class
	and within-class analyses.},
  file = {Doledec94.pdf:Outils/COIA/Doledec94.pdf:PDF},
  keywords = {environmental factors; models; freshwater environments},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@ARTICLE{Vandommelen87,
  author = {van Dommelen, WA},
  title = {{The Contribution of Speech Rhythm and Pitch to Speaker Recognition}},
  journal = {Language and Speech},
  year = {1987},
  volume = {30},
  pages = {325--338},
  number = {4},
  owner = {antho},
  publisher = {Kingston Press Services},
  timestamp = {2009.10.05}
}

@ARTICLE{Dong05,
  author = {Liang Dong and Say Wei Foo and Yong Lian},
  title = {{A two-channel training algorithm for Hidden Markov Model and its
	application to lip reading}},
  journal = eurasip,
  year = {2005},
  volume = {2005},
  pages = {1382--1399},
  number = {9},
  file = {Dong05.pdf:Video/Segmentation/Viseme/Dong05.pdf:PDF},
  owner = {antho},
  publisher = {Hindawi Publishing Corporation},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Dongmei02,
  author = {Dongmei, J. and Lei, X. and Rongchun, Z. and Verhelst, W. and Ravyse,
	I. and Sahli, H.},
  title = {{Acoustic viseme modelling for speech driven animation: a case study}},
  booktitle = {MPCA},
  year = {2002},
  volume = {1},
  address = {Leuven},
  file = {Dongmei02.pdf:Video/Segmentation/Viseme/Dongmei02.pdf:PDF},
  journal = {Workshop on Model based Processing and Coding of Audio (MPCA)},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Duchnowski95,
  author = {Paul Duchnowski and Martin Hunke and Dietrich Busching and Uwe Meier
	and Alex Waibel},
  title = {{Toward movement-invariant automatic lip-reading and speech recognition}},
  booktitle = icassp,
  year = {1995},
  volume = {1},
  pages = {109-112},
  address = {Detroit (USA)},
  abstract = {We present the development of a modular system for flexible human-computer
	interaction via speech. The speech recognition component integrates
	acoustic and visual information (automatic lip-reading) improving
	overall recognition, especially in noisy environments. The image
	of the lips, constituting the visual input, is automatically extracted
	from the camera picture of the speaker's face by the lip locator
	module. Finally, the speaker's face is automatically acquired and
	followed by the face tracker sub-system. Integration of the three
	functions results in the first bi-modal speech recognizer allowing
	the speaker reasonable freedom of movement within a possibly noisy
	room while continuing to communicate with the computer via voice.
	Compared to audio-alone recognition, the combined system achieves
	a 20 to 50 percent error rate reduction for various signal/noise
	conditions},
  doi = {10.1109/ICASSP.1995.479285},
  file = {Duchnowski95.pdf:Audio-Video/Duchnowski95.pdf:PDF},
  keywords = {image processing man-machine systems modules speech recognition video
	cameras visual communication acoustic information bi-modal speech
	recognizer camcorder camera picture error rate reduction face tracker
	sub-system human-computer interaction lip locator module modular
	system movement-invariant automatic lip-reading noisy environments
	signal/noise conditions speaker face speech recognition visual information
	voice communication},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Dufaux00,
  author = {Dufaux, A. and Besacier, L. and Ansorge, M. and Pellandini, F.},
  title = {{Automatic sound detection and recognition for noisy environment}},
  booktitle = eusipco,
  year = {2000},
  pages = {1033--1036},
  file = {Dufaux00.pdf:VAD/Dufaux00.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Dugelay02,
  author = {Jean Luc Dugelay and Jean-Claude Junqua and Constantine Kotropoulos
	and Roland Kuhn and Florent Perronnin and Ioannis Pitas},
  title = {{Recent advances in biometric person authentication}},
  booktitle = icassp,
  year = {2002},
  volume = {4},
  pages = {4060-4063},
  address = {Orlando (USA)},
  abstract = {Biometrics is an emerging topic in the field of signal processing.
	While technologies (e.g. audio, video) 
	
	for biometrics have mostly been studied separately, ultimately, biometric
	technologies could find their 
	
	strongest role as intertwined and complementary pieces of a multi-modal
	authentication system. 
	
	A short overview of voice, fingerprint, and face authentication algorithms
	is provided.},
  doi = {10.1109/ICASSP.2002.1004810},
  file = {Dugelay02.pdf:Audio-Video/Dugelay02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@ARTICLE{Dumas05,
  author = {Bruno Dumas and Catherine Pugin and Jean Hennebert and Dijana Petrovska-Delacr{\'e}taz
	and Andreas Humm and Florian Ev{\'e}quoz and Rolf Ingold and Didier
	Von Rotz},
  title = {{MyIdea--Multimodal biometrics database, description of acquisition
	protocols}},
  journal = {Biometrics on the Internet},
  year = {2005},
  volume = {275},
  pages = {59--62},
  file = {Dumas05.pdf:Base_de_donnees/Dumas05.pdf:PDF},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Dutta08,
  author = {Tridibesh Dutta},
  title = {{Dynamic Time Warping Based Approach to Text-Dependent Speaker Identification
	Using Spectrograms}},
  booktitle = {Congress on Image and Signal Processing},
  year = {2008},
  pages = {354--360},
  file = {Dutta08.pdf:Speaker_reco/Text_dependent/Dutta08.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.19}
}

@INPROCEEDINGS{Dutta07,
  author = {Tridibesh Dutta},
  title = {{Text dependent speaker identification based on spectrograms}},
  booktitle = {Image and Vision Computing},
  year = {2007},
  pages = {238--243},
  file = {Dutta07.pdf:Speaker_reco/Text_dependent/Dutta07.pdf:PDF},
  journal = {Proceedings of Image and vision computing}
}

@INPROCEEDINGS{Eide96,
  author = {Ellen Eide and Herbert Gish},
  title = {{A parametric approach to vocal tract length normalization}},
  booktitle = icassp,
  year = {1996},
  address = {Atlanta (USA)},
  abstract = {Differences in vocal tract size among individual speakers contribute
	to the variability of speech waveforms. The first-order effect of
	a difference in vocal tract length is a scaling of the frequency
	axis; a female speaker, for example, exhibits formants roughly 20%
	higher than the formants of from a male speaker, with the differences
	most severe in open vocal tract configurations. We describe a parametric
	method of normalisation which counteracts the effect of varied vocal
	tract length. The method is shown to be effective across a wide range
	of recognition systems and paradigms, but is particularly helpful
	in the case of a small amount of training data},
  doi = {10.1109/ICASSP.1996.541103},
  file = {Eide96.pdf:Speaker_reco/Normalisation/VTLN/Eide96.pdf:PDF},
  keywords = {acoustic signal processing parameter estimation speech processing
	speech recognition Helmholtz resonator female speaker first-order
	effect formants frequency axis scaling male speaker open vocal tract
	configurations parametric method speech recognition systems speech
	waveforms variability training data vocal tract length normalization
	vocal tract size},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Ekenel05,
  author = {Hazim Kemal Ekenel and Rainer Stiefelhagen},
  title = {{Local appearance based face recognition using discrete cosine transform}},
  booktitle = eusipco,
  year = {2005},
  organization = {Citeseer},
  file = {Ekenel05.pdf:Image/Parametres_locaux/Ekenel05.pdf:PDF}
}

@INPROCEEDINGS{Enqing02,
  author = {Dong Enqing and Liu Guizhong and Zhou Yatong and Zhang Xiaodi},
  title = {{Applying support vector machines to voice activity detection}},
  booktitle = {International Conference on Signal Processing},
  year = {2002},
  volume = {2},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Erzin05,
  author = {Engin Erzin and Y\¨{u}cel Yemez and A. Murat Tekalp},
  title = {{Multimodal speaker identification using an adaptive classifier cascade
	based on modality reliability}},
  journal = tm,
  year = {2005},
  volume = {7},
  pages = {840--852},
  number = {5},
  file = {Erzin05.pdf:Base_de_donnees/Erzin05.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Eveno05,
  author = {Nicolas Eveno and Laurent Besacier},
  title = {{A Speaker Independent "Liveness" Test for Audio-Visual Biometrics}},
  booktitle = eurospeech,
  year = {2005},
  address = {Lisboa (Portugal)},
  abstract = {In biometrics, it is crucial to detect impostors and thwart replay
	attacks. However, few researches have focused yet on the "liveness"
	verification. This test ensures that biometric cues being acquired
	are actual measurements from a live person who is present at the
	time of capture. Here, we propose a speaker independent "liveness"
	verification method for audio-video identification systems. It uses
	the correlation that exists between the lip movements and the speech
	produced. Two data analysis methods are considered to model this
	statistical link. Finally, according to tests carried out on the
	XM2VTS database, the best liveness verification EER achieved is 14.5%.},
  file = {Eveno05.pdf:Audio-Video/Eveno05.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@ARTICLE{Eveno04,
  author = {Nicolas Eveno and Alice Caplier and Pierre-Yves Coulon},
  title = {{Accurate and quasi-automatic lip tracking}},
  journal = tcsvt,
  year = {2004},
  volume = {14},
  pages = {706-715},
  month = {May},
  abstract = {Lip segmentation is an essential stage in many multimedia systems
	such as videoconferencing, lip reading, or low-bit-rate coding communication
	systems. In this paper, we propose an accurate and robust quasi-automatic
	lip segmentation algorithm. First, the upper mouth boundary and several
	characteristic points are detected in the first frame by using a
	new kind of active contour: the "jumping snake." Unlike classic snakes,
	it can be initialized far from the final edge and the adjustment
	of its parameters is easy and intuitive. Then, to achieve the segmentation,
	we propose a parametric model composed of several cubic curves. Its
	high flexibility enables accurate lip contour extraction even in
	the challenging case of a very asymmetric mouth. Compared to existing
	models, it brings a significant improvement in accuracy and realism.
	The segmentation in the following frames is achieved by using an
	interframe tracking of the keypoints and the model parameters. However,
	we show that, with a usual tracking algorithm, the keypoints' positions
	become unreliable after a few frames. We therefore propose an adjustment
	process that enables an accurate tracking even after hundreds of
	frames. Finally, we show that the mean keypoints' tracking errors
	of our algorithm are comparable to manual points' selection errors.},
  doi = {10.1109/TCSVT.2004.826754},
  file = {Eveno04.pdf:Video/Lip_reading/Eveno04.pdf:PDF},
  keywords = {edge detection gesture recognition image segmentation multimedia communication
	video signal processing},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Falavigna95,
  author = {Daniele Falavigna},
  title = {{Comparison of different HMM based methods for speaker verification}},
  booktitle = eurospeech,
  year = {1995},
  organization = {Citeseer},
  file = {Falavigna95.pdf:Speaker_reco/Text_dependent/Falavigna95.pdf:PDF}
}

@ARTICLE{Faraj07,
  author = {Maycel-Isaac Faraj and Josef Bigun},
  title = {{Audio-visual person authentication using lip-motion from orientation
	maps}},
  journal = {Pattern recognition letters},
  year = {2007},
  volume = {28},
  pages = {1368-1382},
  abstract = {This paper describes a new identity authentication technique by a
	synergetic use of lip-motion and speech. The lip-motion is defined
	as the distribution of apparent velocities in the movement of brightness
	patterns in an image and is estimated by computing the velocity components
	of the structure tensor by 1D processing, in 2D manifolds. Since
	the velocities are computed without extracting the speaker's lip-contours,
	more robust visual features can be obtained in comparison to motion
	features extracted from lip-contours. The motion estimations are
	performed in a rectangular lip-region, which affords increased computational
	efficiency. A person authentication implementation based on lip-movements
	and speech is presented along with experiments exhibiting a recognition
	rate of 98%. Besides its value in authentication, the technique can
	be used naturally to evaluate the ''liveness'' of someone speaking
	as it can be used in text-prompted dialogue. The XM2VTS database
	was used for performance quantification as it is currently the largest
	publicly available database (~300 persons) containing both lip-motion
	and speech. Comparisons with other techniques are presented.},
  file = {Faraj07.pdf:Audio-Video/Faraj07.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.08.23}
}

@TECHREPORT{Faraoun06,
  author = {Faraoun, KM and Boukelif, A.},
  title = {{Artificial Immune Systems for text-dependent speaker recognition}},
  institution = {D\'epartement d'informatique, Djillali Liab\`es University},
  year = {2006},
  file = {Faraoun06.pdf:Artificial_Immune_System/Faraoun06.pdf:PDF},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Farrell95,
  author = {Kevin R. Farrell},
  title = {{Text-dependent speaker verification using data fusion}},
  booktitle = icassp,
  year = {1995},
  volume = {1},
  pages = {349--349},
  organization = {INSTITUTE OF ELECTRICAL ENGINEERS INC (IEE)},
  file = {Farrell95.pdf:Speaker_reco/Text_dependent/Farrell95.pdf:PDF}
}

@INPROCEEDINGS{Farrell98,
  author = {Kevin R. Farrell and Ravi P. Ramachandran and Richard J. Mammone},
  title = {{An analysis of data fusion methods for speaker verification}},
  booktitle = icassp,
  year = {1998},
  doi = {10.1109/ICASSP.1998.675468},
  file = {Farrell98.pdf:Speaker_reco/Divers/Farrell98.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.24}
}

@INPROCEEDINGS{Farrell97,
  author = {Kevin R. Farrell and Ravi P. Ramachandran and Manish Sharma and Richard
	J. Mammone},
  title = {{Sub-word speaker verification using data fusion methods}},
  booktitle = {IEEE Workshop on Neural Networks for Signal Processing},
  year = {1997},
  doi = {10.1109/NNSP.1997.622435},
  file = {Farrell97.pdf:Speaker_reco/Text_dependent/Farrell97.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.24}
}

@ARTICLE{Faundez06,
  author = {Marcos Faundez-Zanuy and Julian Fierrez-Aguilar and Javier Ortega-Garcia
	and Joaquin Gonzalez-Rodriguez},
  title = {{Multimodal biometric databases: An overview}},
  journal = {IEEE Aerospace and Electronic Systems Magazine},
  year = {2006},
  volume = {21},
  pages = {29--37},
  number = {8},
  file = {Faundez06.pdf:Base_de_donnees/Faundez06.pdf:PDF},
  publisher = {IEEE}
}

@PHDTHESIS{Fauve09,
  author = {Beno\^it Fauve},
  title = {{Tackling Variabilities in Speaker Verification with a Focus on Short
	Durations}},
  school = {{School of Engineering Swansea University}},
  year = {2009},
  owner = {antho},
  timestamp = {2010.04.27}
}

@INPROCEEDINGS{Fauve08,
  author = {Benoit Fauve and Herve Bredin and Walid Karam and Florian Verdet
	and Aurelien Mayoue and Gerard Chollet and Jean Hennebert and Richard
	Lewis and John Mason and Chafic Mokbel and Dijana Petrovska},
  title = {{Some results from the biosecure talking face evaluation campaign}},
  booktitle = icassp,
  year = {2008},
  pages = {4137--4140},
  file = {Fauve08.pdf:Speaker_reco/Divers/Fauve08.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Fauve08_b,
  author = {Benoit Fauve and Nicholas Evans and John S.D. Mason},
  title = {{Improving the performance of text-independent short duration SVM-and
	GMM-based speaker verification}},
  booktitle = odyssey,
  year = {2008},
  pages = {1--7},
  file = {Fauve08_b.pdf:Speaker_reco/Short_Utterance/Fauve08_b.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Fauve07_b,
  author = {Beno\^it Fauve and Nicholas Evans and Neil Pearson and Jean-Francois
	Bonastre and John S.D. Mason},
  title = {{Influence of task duration in text-independent speaker verification}},
  booktitle = interspeech,
  year = {2007},
  pages = {794--797},
  file = {Fauve07_b.pdf:Speaker_reco/Short_Utterance/Fauve07_b.pdf:PDF},
  journal = {les actes de Interspeech}
}

@ARTICLE{Fauve07,
  author = {Fauve, BGB and Matrouf, D. and Scheffer, N. and Bonastre, J.F. and
	Mason, JSD},
  title = {{State-of-the-art performance in text-independent speaker verification
	through open-source software}},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2007},
  volume = {15},
  pages = {1960--1968},
  number = {7},
  file = {Fauve07.pdf:Speaker_reco/Divers/Fauve07.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Ferras07,
  author = {Marc Ferras and Cheung Chi Leung and Claude Barras and Jean-Luc Gauvain},
  title = {{Constrained MLLR for speaker recognition}},
  booktitle = icassp,
  year = {2007},
  volume = {4},
  pages = {IV--53},
  organization = {IEEE},
  file = {Ferras07.pdf:Speaker_reco/Adaptation/MLLR/Ferras07.pdf:PDF}
}

@INPROCEEDINGS{Ferras11,
  author = {Marc Ferras and Koichi Shinoda and Sadaoki Furui},
  title = {{Structural Joint Factor Analysis for Speaker Recognition}},
  booktitle = interspeech,
  year = {2011},
  pages = {2373--2376},
  file = {Ferras11.PDF:Speaker_reco/FA/Ferras11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.10}
}

@INPROCEEDINGS{Ferrer11,
  author = {Luciana Ferrer and Harry Bratt and Lukas Burget and Honza Cernock\^y
	and Ondrej Glembeck and Martin Graciarena and Aaron Lawson and Yun
	Lei and Pavel Matejka and Olda Plchot and Nicolas Scheffer},
  title = {{Promoting robustness for speaker modeling in the community: the
	PRISM evaluation set}},
  booktitle = {NISTE Speaker Recognition Evaluation Analysis},
  year = {2011},
  file = {Ferrer11.pdf:Base_de_donnees/Ferrer11.pdf:PDF},
  owner = {antho},
  timestamp = {2012.03.20}
}

@INPROCEEDINGS{Ferrer10,
  author = {Luciana Ferrer and Martin Graciarena and Sachin Kajarekar and Nicolas
	Scheffer and Elizabeth Shriberg and Andreas Stolcke},
  title = {{2010 NIST Speaker Recognition Evaluation SRI System Descritpion}},
  booktitle = {{NIST Speaker Recognition Evaluation Workshop}},
  year = {2010},
  file = {Ferrer10.pdf:Speaker_reco/NIST/Ferrer10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.24}
}

@INPROCEEDINGS{Ferrer06,
  author = {Luciana Ferrer and Martin Graciarena and Argyris Zymnis and Elizabeth
	Shriberg},
  title = {{System combination using auxiliary information for speaker verification}},
  booktitle = icassp,
  year = {2006},
  pages = {4853--4856},
  file = {Ferrer06.pdf:Speaker_reco/Score_Fusion/Ferrer06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.12.01}
}

@INPROCEEDINGS{Ferrer07,
  author = {Ferrer, L. and Shriberg, E. and Kajarekar, S. and Sonrnez, K.},
  title = {{Parameterization of prosodic feature distributions for SVM modeling
	in speaker recognition}},
  booktitle = icassp,
  year = {2007},
  volume = {4},
  file = {Ferrer07.pdf:Parametrisation/Ferrer07.pdf:PDF}
}

@INPROCEEDINGS{Ferrer07_b,
  author = {Luciana Ferrer and Kemal Sonmez and Elizabeth Shriberg},
  title = {{A smoothing kernel for spatially related features and its application
	to speaker verification}},
  booktitle = interspeech,
  year = {2007},
  pages = {738--741},
  organization = {Citeseer},
  file = {Ferrer07_b.pdf:Speaker_reco/SVM/Ferrer07_b.pdf:PDF}
}

@ARTICLE{Ferrer09,
  author = {Luciana Ferrer and Kemal S{\\"o}nmez and Elizabeth Shriberg},
  title = {{An Anticorrelation Kernel for Subsystem Training in Multiple Classifier
	Systems}},
  journal = {The Journal of Machine Learning Research},
  year = {2009},
  volume = {10},
  pages = {2079--2114},
  file = {Ferrer09.pdf:Speaker_reco/Score_Fusion/Ferrer09.pdf:PDF},
  issn = {1532-4435},
  publisher = {JMLR. org}
}

@INPROCEEDINGS{Ferrer08,
  author = {Luciana Ferrer and Kemal S{\\"o}nmez and Elizabeth Shriberg},
  title = {{An anticorrelation kernel for improved system combination in speaker
	verification}},
  booktitle = odyssey,
  year = {2008},
  organization = {Citeseer},
  file = {Ferrer08.pdf:Speaker_reco/Score_Fusion/Ferrer08.pdf:PDF}
}

@ARTICLE{Fierrez07,
  author = {Fierrez, J. and Ortega-Garcia, J. and Torre Toledano, D. and Gonzalez-Rodriguez,
	J.},
  title = {{Biosec baseline corpus: A multimodal biometric database}},
  journal = {Pattern Recognition},
  year = {2007},
  volume = {40},
  pages = {1389--1392},
  number = {4},
  file = {Fierrez07.pdf:Base_de_donnees/Fierrez07.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Finan96,
  author = {Finan, RA and Sapeluk, AT and Damper, RI},
  title = {{Comparison of multilayer and radial basis function neural networks
	for text-dependent speaker recognition}},
  booktitle = {International Conference on Neural Networks},
  year = {1996},
  volume = {4},
  organization = {Citeseer},
  doi = {10.1109/ICNN.1996.549207},
  file = {Finan96.pdf:Speaker_reco/Text_dependent/Finan96.pdf:PDF}
}

@INPROCEEDINGS{Fine01,
  author = {Shai Fine and Jiri Navratil and Ramesh A. Gopinath},
  title = {{A Hybrid Gmm/Svm Approach To Speaker Identification}},
  booktitle = icassp,
  year = {2001},
  volume = {1},
  pages = {417-420},
  address = {Salt Lake City (USA)},
  month = {March},
  abstract = {Proposes a classification scheme that incorporates statistical models
	and support vector machines. A hybrid system which appropriately
	combines the advantages of both the generative and discriminant model
	paradigms is described and experimentally evaluated on a text-independent
	speaker recognition task in matched and mismatched training and test
	conditions. Our results prove that the combination is beneficial
	in terms of performance and practical in terms of computation. We
	report relative improvements of up to 25% reduction in identification
	error rate compared to the baseline statistical model},
  citeseerurl = {url = "citeseer.ist.psu.edu/fine01hybrid.html"},
  doi = {10.1109/ICASSP.2001.940856},
  file = {Fine01.pdf:Speaker_reco/SVM/Fine01.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Finke97,
  author = {Michael Finke and Petra Geutner and Hermann Hild and Thomas Kemp
	and Klaus Ries and Martin Westphal},
  title = {{The Karlsruhe-Verbmobil Speech Recognition Engine}},
  booktitle = icassp,
  year = {1997},
  volume = {1},
  pages = {83-86},
  address = {Munich (Germany)},
  month = {April},
  abstract = {Verbmobil, a German research project, aims at machine translation
	of spontaneous speech input. The ultimate goal is the development
	of a portable machine translator that will allow people to negotiate
	in their native language. Within this project the University of Karlsruhe
	has developed a speech recognition engine that has been evaluated
	on a yearly basis during the project and shows very promising speech
	recognition word accuracy results on large vocabulary spontaneous
	speech. We introduce the Janus Speech Recognition Toolkit underlying
	the speech recognizer. The main new contributions to the acoustic
	modeling part of our 1996 evaluation system-speaker normalization,
	channel normalization and polyphonic clustering-are discussed and
	evaluated. Besides the acoustic models we delineate the different
	language models used in our evaluation system: word trigram models
	interpolated with class based models and a separate spelling language
	model were applied. As a result of using the toolkit and integrating
	all these parts into the recognition engine the word error rate on
	the German spontaneous scheduling task (GSST) could be decreased
	from 30% word error rate in 1995 to 13.8% in 1996},
  citeseerurl = {http://citeseer.ist.psu.edu/finke97karlsruheverbmobil.html},
  doi = {10.1109/ICASSP.1997.599552},
  file = {Finke97.pdf:Speaker_reco/Normalisation/VTLN/Finke97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29},
  url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=599552&isnumber=13187&punumber=4635&k2dockey=599552@ieeecnfs&query=the+karlsruhe-verbmobil+speech+recognition+engine+%3Cin%3E+metadata&pos=0}
}

@ARTICLE{Fisher68,
  author = {Cletus G. Fisher},
  title = {{Confusions among visually perceived consonants}},
  journal = {Journal of Speech, Language and Hearing Research},
  year = {1968},
  volume = {11},
  pages = {796},
  number = {4},
  owner = {antho},
  publisher = {ASHA},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Fisher00,
  author = {John W. Fisher and Trevor Darrell and William T. Freeman and Paul
	Viola},
  title = {{Learning joint statistical models for audio-visual fusion and segregation}},
  booktitle = {Advances neural Information Processing Systems},
  year = {2000},
  address = {Vancouver (Canada)},
  abstract = {People can understand complex auditory and visual information, often
	
	using one to disambiguate the other. Automated analysis, even at a
	low-
	
	level, faces severe challenges, including the lack of accurate statistical
	
	models for the signals, and their high-dimensionality and varied sam-
	
	pling rates. Previous approaches [6] assumed simple parametric models
	
	for the joint distribution which, while tractable, cannot capture
	the com-
	
	plex signal relationships. We learn the joint distribution of the
	visual and
	
	auditory signals using a non-parametric approach. First, we project
	the
	
	data into a maximally informative, low-dimensional subspace, suitable
	
	for density estimation. We then model the complicated stochastic rela-
	
	tionships between the signals using a nonparametric density estimator.
	
	These learned densities allow processing across signal modalities.
	We
	
	demonstrate, on synthetic and real signals, localization in video
	of the
	
	face that is speaking in audio, and, conversely, audio enhancement
	of a
	
	particular speaker selected from the video.},
  file = {Fisher00.pdf:Audio-Video/Fisher00.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.03}
}

@INPROCEEDINGS{Fisher86,
  author = {William M. Fisher and Georges R. Doddington and Kathleen M. Goudie-Marshall},
  title = {{The DARPA speech recognition research database: specifications and
	status}},
  booktitle = {DARPA Workshop on Speech Recognition},
  year = {1986},
  pages = {93--99}
}

@INPROCEEDINGS{Foo03,
  author = {Foo, S.W. and Lian, Y. and Dong, L.},
  title = {{A two-channel training algorithm for hidden Markov model to identify
	visual speech elements}},
  booktitle = {International Symposium on Circuits and Systems},
  year = {2003},
  volume = {2},
  publisher = {ISCA},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Forney73,
  author = {G. David Forney},
  title = {{The Viterbi Algorithm}},
  journal = ieee,
  year = {1973},
  volume = {61},
  pages = {268-278},
  number = {3},
  month = {March},
  abstract = {The Viterbi algorithm (VA) is a recursive optimal solution to the
	problem of estimating the state sequence of a discrete-time finite-state
	Markov process observed in memoryless noise. Many problems in areas
	such as digital communications can be cast in this form. This paper
	gives a tutorial exposition of the algorithm and of how it is implemented
	and analyzed. Applications to date are reviewed. Increasing use of
	the algorithm in a widening variety of areas is foreseen.},
  booktitle = {Proceedings of the IEEE},
  organization = {Proceedings of the IEEE},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Forrest94,
  author = {Stephanie Forrest and Alan S. Perelson and Lawrence Allen and Rajesh
	Cherukuri},
  title = {{Self-nonself discrimination in a computer}},
  booktitle = {IEEE Computer Society Symposium on Research in Security and Privacy},
  year = {1994},
  pages = {202--212},
  organization = {IEEE},
  file = {Forrest94.pdf:Artificial_Immune_System/Forrest94.pdf:PDF},
  isbn = {0818656751}
}

@ARTICLE{Fox06,
  author = {Niall A. Fox and Ralph Gross and Jeffrey F. Cohn and Richard B. Reilly},
  title = {{Robust Biometric Person Identification Using Automatic Classifier
	Fusion of Speech, Mouth, and Face Experts}},
  journal = tm,
  year = {2006},
  volume = {9},
  pages = {701--714},
  number = {4},
  abstract = {Information about person identity is multimodal. Yet, most person
	recognition systems limit themselves to only a single modality, such
	as facial appearance. With a view to exploiting the complementary
	nature of different modes of information and increasing pattern recognition
	robustness to test signal degradation, we developed a multiple expert
	biometric person identification system that combines information
	from three experts: audio, visual speech, and face. The system uses
	multimodal fusion in an automatic unsupervised manner, adapting to
	the local performance (at the transaction level) and output reliability
	of each of the three experts. The expert weightings are chosen automatically
	such that the reliability measure of the combined scores is maximized.
	To test system robustness to train/test mismatch, we used a broad
	range of acoustic babble noise and JPEG compression to degrade the
	audio and visual signals, respectively. Identification experiments
	were carried out on a 248-subject subset of the XM2VTS database.
	The multimodal expert system outperformed each of the single experts
	in all comparisons. At severe audio and visual mismatch levels tested,
	the audio, mouth, face, and tri-expert fusion accuracies were 16.1%,
	48%, 75%, and 89.9% respectively, representing a relative improvement
	of 19.9% over the best performing expert.},
  file = {Fox06.pdf:Audio-Video/Fox06.pdf:PDF},
  keywords = {biometric fusion, person recognition, mouth features, hidden Markov
	models, robustness, expert reliability, multimodal, tri-expert, image
	information loss},
  owner = {larcher},
  timestamp = {2007.03.14}
}

@INPROCEEDINGS{Fox05,
  author = {Niall A. Fox and Brian A. O'Mullane and Richard B. Reilly},
  title = {{The Realistic Multi-modal VALID database and Visual Speaker Identification
	Comparison Experiments}},
  booktitle = avbpa,
  year = {2005},
  address = {New York (US)},
  month = {July},
  file = {Fox05.pdf:Base_de_donnees/Fox05.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.07.25}
}

@INPROCEEDINGS{Fox_OMullane05,
  author = {Niall A. Fox and Brian A. O'Mullane and Richard B. Reilly},
  title = {{Audio-Visual Speaker Identification via Adaptive Fusion Using Reliability
	Estimates of Both Modalities}},
  booktitle = avbpa,
  year = {2005},
  pages = {20-22},
  address = {New York (US)},
  month = {July},
  abstract = {An audio-visual speaker identification system is described, where
	the audio and visual speech modalities are fused by an automatic
	unsupervised process that adapts to local classifier performance,
	by taking into account the output score based reliability estimates
	of both modalities. Previously reported methods do not consider that
	both the audio and the visual modalities can be degraded. The visual
	modality uses the speakers lip information. To test the robustness
	of the system, the audio and visual modalities are degraded to emulate
	various levels of train/test mismatch; employing additive white Gaussian
	noise for the audio and JPEG compression for the visual signals.
	Experiments are carried out on a large augmented data set from the
	XM2VTS database. The results show improved audio-visual accuracies
	at all tested levels of audio and visual degradation, compared to
	the individual audio or visual modality accuracies. For high mismatch
	levels, the audio, visual, and auto- adapted audio-visual accuracies
	are 37.1%, 48%, and 71.4% respectively.},
  file = {Fox_OMullane05.pdf:Audio-Video/Fox_OMullane05.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.03.14}
}

@INPROCEEDINGS{Fox03,
  author = {Niall Fox and Richard B. Reilly},
  title = {{Audio-Visual Speaker Identification Based on the Use of Dynamic
	Audio and Visual Features}},
  booktitle = avbpa,
  year = {2003},
  address = {Guildford (UK)},
  month = {June},
  abstract = {This paper presents a speaker identification system based on dynamical
	features of both the audio and visual modes. Speakers are modeled
	using a text dependent HMM methodology. Early and late audio-visual
	integration are investigated. Experiments are carried out for 252
	speakers from the XM2VTS database. From our experimental results,
	it has been shown that the addition of the dynamical visual information
	improves the speaker identification accuracies for both clean and
	noisy audio conditions compared to the audio only case. The best
	audio, visual and audio-visual identification accuracies achieved
	were 86.91%, 57.14% and 94.05% respectively.},
  file = {Fox03.pdf:Audio-Video/Fox03.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.03.14}
}

@INPROCEEDINGS{Franco10,
  author = {Javier Franco-Pedroso and Ignacio Lopez-Moreno and Doroteo T. Toledano
	and Joaquin Gonzalez-Rodriguez},
  title = {{ATVS-UAM System Description for the Audio Segmentation and Speaker
	Diarization Albayzin 2010 Evaluation}},
  booktitle = {FALA "VI Jornadas en Tecnología del Habla" and II Iberian SLTech
	Workshop},
  year = {2010},
  pages = {415--418},
  file = {Franco10.pdf:Speaker_Diarization/Franco10.pdf:PDF},
  owner = {antho},
  timestamp = {2011.02.01}
}

@PHDTHESIS{Fredouille00,
  author = {Corinne Fredouille},
  title = {{Approche Statistique pour la Reconnaissance Automatique du Locuteur:
	Informations Dynamiques et Normalisation Bayesienne des Vraisemblances}},
  school = {Universit\'e d'Avignon, Avignon, FRANCE},
  year = {2000},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Fredouille99,
  author = {Corinne Fredouille and Jean-Fran{\c c}ois Bonastre and Teva Merlin},
  title = {{Similarity Normalization Method Based on World Model and a Posteriori
	Probability for Speaker Verification}},
  booktitle = eurospeech,
  year = {1999},
  volume = {2},
  pages = {983-986},
  address = {Budapest (Hungary)},
  month = {September},
  abstract = {For the task of speaker verification, similarity measure normalization
	methods are relevant to cope with variability problems and with data
	and/or decision fusion issues. The aim of this paper is to suggest
	a new normalization method, which combines classical world model-based
	normalization techniques with a posteriori probability-based ones.
	This method presents the well-known advantages of the a posteriori
	probability-based methods without requiring data and speaker specific
	processing. Here, it is experimented through a temporal-segmental,
	multi-recognizer speaker verification system. The results obtained
	on a subset of the Switchboard-Nist98 database demonstrate the ability
	of this method to normalize similarity measures (in probability domain)
	without decreasing performance. The second advantage of this method
	is borne out by the performance of the multi-recognizer system, which
	reveals that this normalization is able to make the fusion step easier
	without requiring any weighting function even if individual recognizer
	performance is dissimilar.},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@ARTICLE{Frissen05,
  author = {Frissen, I. and Vroomen, J. and de Gelder, B. and Bertelson, P.},
  title = {{The aftereffects of ventriloquism: Generalization across sound-frequencies}},
  journal = {Acta psychologica},
  year = {2005},
  volume = {118},
  pages = {93--100},
  number = {1-2},
  file = {Frissen05.pdf:Ventriloquie/Frissen05.pdf:PDF},
  publisher = {Elsevier}
}

@TECHREPORT{Fromherz97,
  author = {Fromherz, T. and Stucki, P. and Bichsel, M.},
  title = {{A survey of face recognition}},
  institution = {Dept. of Computer Science, University of Zurich},
  year = {1997},
  journal = {Dept. of Computer Science, University of Zurich, Zurich MML Technical
	Report},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Frumkin09,
  author = {Frumkin, D. and Wasserstrom, A. and Davidson, A. and Grafit, A.},
  title = {{Authentication of forensic DNA samples}},
  journal = {Forensic Science International: Genetics},
  year = {2009},
  publisher = {Elsevier}
}

@ARTICLE{Furui86,
  author = {Sadaoki Furui},
  title = {{Speaker-independent isolated word recognition using dynamic features
	of speech spectrum}},
  journal = {IEEE Transactions on Acoustics, Speech and Signal Processing},
  year = {1986},
  volume = {34},
  pages = {52--59},
  number = {1},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Furui81,
  author = {Sadaoki Furui},
  title = {{Cepstral analysis technique for automatic speaker verification}},
  journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing [see
	also IEEE Transactions on Signal Processing]},
  year = {1981},
  volume = {29},
  pages = {254--272},
  number = {2},
  file = {Furui81.pdf:Parametrisation/Furui81.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Gagnon01,
  author = {Luc Gagnon and Peter Stubley and Ghislain Mailhot},
  title = {{Password-Dependent Speaker Verification Using Quantized Acoustic
	Trajectories}},
  booktitle = icassp,
  year = {2001},
  volume = {1},
  pages = {449-452},
  address = {Salt Lake City (USA)},
  abstract = {Speaker verification requires either two steps (identity claim and
	verification) or the use of speech recognition to determine the password
	phrase. The single step method using speech recognition is text-and
	language-dependent. We describe a single-step method based on Gaussian
	mixture models and quantized acoustic trajectories that does not
	use any linguistic knowledge and is thus text-and language-independent.
	Although a two-step process can be more accurate, our approach is
	significantly better than speaker identification and is more convenient
	than a two-step process},
  doi = {10.1109/ICASSP.2001.940864},
  keywords = {acoustic signal processing biometrics (access control) covariance
	matrices pattern clustering probability quantisation (signal) speaker
	recognition},
  owner = {larcher},
  timestamp = {2006.06.21}
}

@ARTICLE{Gales96,
  author = {Mark J.F. Gales and Phil C. Woodland},
  title = {{Mean and Variance adaptation within the MLLR framework}},
  journal = csl,
  year = {1996},
  volume = {10},
  pages = {249-264},
  month = {April},
  abstract = {One of the key issues for adaptation algorithms is to modify a large
	number of parameters with only a small amount of adaptation data.
	Speaker adaptation techniques try to obtain near speaker-dependent
	(SD) performance with only small amounts of speaker-specific data,
	and are often based on initial speaker-independent (SI) recognition
	systems. Some of these speaker adaptation techniques may also be
	applied to the task of adaptation to a new acoustic environment.
	In this case an SI recognition system trained in, typically, a clean
	acoustic environment is adapted to operate in a new, noise-corrupted,
	acoustic environment. This paper examines the maximum likelihood
	linear regression (MLLR) adaptation technique. MLLR estimates linear
	transformations for groups of model parameters to maximize the likelihood
	of the adaptation data. Previously, MLLR has been applied to the
	mean parameters in mixture-Gaussian HMM systems. In this paper MLLR
	is extended to also update the Gaussian variances and re-estimation
	formulae are derived for these variance transforms. MLLR with variance
	compensation is evaluated on several large vocabulary recognition
	tasks. The use of mean and variance MLLR adaptation was found to
	give an additional 2% to 7% decrease in word error rate over mean-only
	MLLR adaptation.},
  doi = {10.1006/csla.1996.0013},
  file = {Gales96.pdf:Speaker_reco/Adaptation/MLLR/Gales96.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@ARTICLE{Gales02,
  author = {Mark J. F. Gales},
  title = {{Maximum likelihood multiple projection schemes for hidden Markov
	models}},
  journal = tsap,
  year = {2002},
  pages = {37--47},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/Adaptation/MLLR/Gales02.pdf:PDF},
  publisher = {Citeseer}
}

@ARTICLE{Gannot98,
  author = {Gannot, S. and Burshtein, D. and Weinstein, E.},
  title = {{Iterative and sequential Kalman filter-based speech enhancementalgorithms}},
  journal = {IEEE Transactions on Speech and Audio Processing},
  year = {1998},
  volume = {6},
  pages = {373--385},
  number = {4},
  file = {Gannot98.pdf:Speech_reco/Continuous/Gannot98.pdf:PDF}
}

@ARTICLE{Garcia04,
  author = {Christophe Garcia and Manolis Delakis},
  title = {{Convolutional face finder: a neural architecture for fast and robust
	face detection}},
  journal = pami,
  year = {2004},
  volume = {26},
  pages = {1408-1423},
  number = {11},
  month = {november},
  abstract = {In this paper, we present a novel face detection approach based on
	a convolutional neural architecture, designed to robustly detect
	highly variable face patterns, rotated up to /spl plusmn/20 degrees
	in image plane and turned up to /spl plusmn/60 degrees, in complex
	real world images. The proposed system automatically synthesizes
	simple problem-specific feature extractors from a training set of
	face and nonface patterns, without making any assumptions or using
	any hand-made design concerning the features to extract or the areas
	of the face pattern to analyze. The face detection procedure acts
	like a pipeline of simple convolution and subsampling modules that
	treat the raw input image as a whole. We therefore show that an efficient
	face detection system does not require any costly local preprocessing
	before classification of image areas. The proposed scheme provides
	very high detection rate with a particularly low level of false positives,
	demonstrated on difficult test sets, without requiring the use of
	multiple networks for handling difficult cases. We present extensive
	experimental results illustrating the efficiency of the proposed
	approach on difficult test sets and including an in-depth sensitivity
	analysis with respect to the degrees of variability of the face patterns.},
  doi = {10.1109/TPAMI.2004.97},
  file = {Garcia04.pdf:Video/Garcia04.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.03}
}

@INPROCEEDINGS{Garcia11,
  author = {Daniel Garcia-Romero and Carol Y. Espy-Wilson},
  title = {{Analysis of i-vector length normalization in speaker recognition
	systems}},
  booktitle = interspeech,
  year = {2011},
  pages = {249--252},
  file = {Garcia11.PDF:Speaker_reco/FA/I-Vector/Garcia11.PDF:PDF}
}

@INPROCEEDINGS{Garcia10,
  author = {Daniel Garcia-Romero and Carol Y. Espy-Wilson},
  title = {{Joint factor analysis for speaker recognition reinterpreted as signal
	coding using overcomplete dictionaries}},
  booktitle = odyssey,
  year = {2010},
  file = {Garcia10.pdf:Speaker_reco/FA/Garcia10.pdf:PDF}
}

@INPROCEEDINGS{Garcia04_b,
  author = {Daniel Garcia-Romero and Julian Fierrez-Aguilar and Joaquin Gonzalez-Rodriguez
	and Javier Ortega-Garcia},
  title = {{On the use of quality measures for text-independent speaker recognition}},
  booktitle = odyssey,
  year = {2004},
  organization = {Citeseer},
  file = {Garcia04_b.pdf:quality_speaker-reco/Garcia04_b.pdf:PDF}
}

@ARTICLE{Garciasalicetti03,
  author = {Garcia-Salicetti, S. and Beumier, C. and Chollet, G. and Dorizzi,
	B. and Jardins, J.L. and Lunter, J. and Ni, Y. and Petrovska-Delacretaz,
	D.},
  title = {{BIOMET: A Multimodal Person Authentication Database Including Face,
	Voice, Fingerprint, Hand and Signature Modalities}},
  journal = {Lecture Notes in Computer Science},
  year = {2003},
  volume = {2688/2003},
  pages = {845--853},
  file = {Garciasalicetti03.pdf:Base_de_donnees/Garciasalicetti03.pdf:PDF},
  owner = {antho},
  publisher = {Springer},
  timestamp = {2009.10.05}
}

@ARTICLE{Garofolo93,
  author = {John S. Garofolo and Lori F. Lamel and William M. Fisher and Jonathan
	G. Fiscus and David S. Pallett and Nancy Dahlgren and Victor Zue},
  title = {TIMIT Acoustic-Phonetic Continuous Speech Corpus Linguistic Data
	Consortium},
  journal = {Philadelphia, PA},
  year = {1993},
  volume = {1}
}

@INPROCEEDINGS{Gauvain94,
  author = {Jean-Luc Gauvain and Chin-Hui Lee},
  title = {{Maximum a posteriori estimation for multivariate gaussian mixture
	observations of Markov chains}},
  booktitle = icassp,
  year = {1994},
  volume = {2},
  pages = {291--298},
  abstract = {In this paper, a framework for maximum a posteriori (MAP) estimation
	of hidden Markov models (HMM) is presented. Three key issues of MAP
	estimation, namely, the choice of prior distribution family, the
	specification of the parameters of prior densities, and the evaluation
	of the MAP estimates, are addressed. Using HMM's with Gaussian mixture
	state observation densities as an example, it is assumed that the
	prior densities for the HMM parameters can be adequately represented
	as a product of Dirichlet and normal-Wishart densities. The classical
	maximum likelihood estimation algorithms, namely, the forward-backward
	algorithm and the segmental k-means algorithm, are expanded, and
	MAP estimation formulas are developed. Prior density estimation issues
	are discussed for two classes of applications-parameter smoothing
	and model adaptation-and some experimental results are given illustrating
	the practical interest of this approach. Because of its adaptive
	nature, Bayesian learning is shown to serve as a unified approach
	for a wide range of speech recognition applications},
  citeseerurl = {http://citeseer.csail.mit.edu/gauvain94maximum.html},
  file = {Gauvain94.pdf:Speaker_reco/Adaptation/MAP/Gauvain94.pdf:PDF},
  journal = icassp,
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Gauvain04,
  author = {Jean-Luc Gauvain and Abdel Messaoudi and Holger Schwenk},
  title = {{Language recognition using phone latices}},
  booktitle = interspeech,
  year = {2004},
  file = {Gauvain04.pdf:Language_reco/Gauvain04.pdf:PDF}
}

@PHDTHESIS{Genoud99,
  author = {Dominique Genoud},
  title = {{Reconnaissance et transformation de locuteurs}},
  school = {Ecole Polytechnique de lausanne (EPFL)},
  year = {1999},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@INPROCEEDINGS{Genoud98,
  author = {Dominique Genoud and Miguel Moreira and Eddy Mayoraz},
  title = {{Text dependent speaker verification using binary classifiers}},
  booktitle = {IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS SPEECH AND SIGNAL PROCESSING},
  year = {1998},
  volume = {1},
  pages = {129--132},
  organization = {INSTITUTE OF ELECTRICAL ENGINEERS INC (IEE)},
  file = {Genoud98.pdf:Speaker_reco/Text_dependent/Genoud98.pdf:PDF}
}

@ARTICLE{Georghiades01,
  author = {Athinodoros S. Georghiades and Peter N. Belhumeur and David J. Kriegman},
  title = {{From Few to Many: Illumination Cone Models for Face Recognition
	under Variable Lighting and Pose}},
  journal = pami,
  year = {2001},
  volume = {6},
  pages = {643--660},
  owner = {antho},
  timestamp = {2008.11.17}
}

@BOOK{Gittins85,
  title = {{Canonical Analysis: A Review with Applications in Ecology}},
  publisher = {Springer-Verlag},
  year = {1985},
  author = {Gittins, R.},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Glembeck11_a,
  author = {Ondrej Glembeck and Lukas Burget and Pavel Matejka and Martin Karafiat
	and Patrick Kenny},
  title = {{Simplification and optimization of I-Vector extraction}},
  booktitle = icassp,
  year = {2011},
  pages = {4516--4519},
  file = {Glembeck11_a.pdf:Speaker_reco/FA/I-Vector/Glembeck11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@INPROCEEDINGS{Glembeck09,
  author = {Ondrej Glembek and Lukas Burget and Najim Dehak and Niko Brummer
	and Patrick Kenny},
  title = {{Comparison of Scoring Methods used in Speaker Recognition with Joint
	Factor Analysis}},
  booktitle = icassp,
  year = {2009},
  address = {Taipei (Taiwan)},
  file = {Glembeck09.pdf:Speaker_reco/FA/Fast_scoring/Glembeck09.pdf:PDF},
  owner = {antho},
  timestamp = {2009.09.28}
}

@INPROCEEDINGS{Glembeck08,
  author = {Ondrej Glembek and Pavel Matejka and Lukas Burget and Tomas Mikolov},
  title = {{Advances in phonotactic language recognition}},
  booktitle = interspeech,
  year = {2008},
  pages = {743--746},
  file = {Glembeck08.pdf:Language_reco/Glembeck08.pdf:PDF},
  owner = {antho},
  timestamp = {2011.01.10}
}

@INPROCEEDINGS{Goecke05,
  author = {Roland Goecke},
  title = {{3D Lip Tracking and Co-Inertia Analysis for Improved Robustness
	of Audio-Video Automatic Speech Recognition}},
  booktitle = avsp,
  year = {2005},
  address = {Vancouver Island (Canada)},
  abstract = {Multimodality is a key issue in robust human-computer interaction.
	The joint use of audio and video speech variables has been shown
	to improve the performance of automatic speech recognition (ASR)
	systems. However, robust methods in particular for the real-time
	extraction of video speech features are still an open research area.
	This paper addresses the robustness issue of audio-video (AV) ASR
	systems by exploring a real-time 3D lip tracking algorithm based
	on stereo vision and by investigating how learned statistical relationships
	between the sets of audio and video speech variables can be employed
	in AV ASR systems. The 3D lip tracking algorithm combines colour
	information from each cameras' images with knowledge about the structure
	of the mouth region for different degrees of mouth openness. By using
	a calibrated stereo camera system, 3D coordinates of facial features
	can be recovered, so that the visual speech variable measurements
	become independent from the head pose. Multivariate statistical analyses
	enable the analysis of relationships between sets of variables. Co-inertia
	analysis is a relatively new method and has not yet been widely used
	in AVSP research. Its advantage is its superior numerical stability
	compared to other multivariate methods in the case of small sample
	size. Initial results are presented, which show how 3D video speech
	information and learned statistical relationships between audio and
	video speech variables can improve the performance of AV ASR systems.},
  file = {Goecke05.pdf:Audio-Video/Goecke05.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Goecke08,
  author = {Roland Goecke and Akshay Asthana},
  title = {{A Comparative Study of 2D and 3D Lip Tracking Methods for AV ASR}},
  booktitle = avsp,
  year = {2008},
  owner = {antho},
  timestamp = {2008.10.24}
}

@INPROCEEDINGS{Goecke03,
  author = {Roland Goecke and Bruce Millar},
  title = {{Statistical Analysis of the Relationship between Audio and Video
	Speech Parameters for Australian English}},
  booktitle = avsp,
  year = {2003},
  address = {St Jorioz (France)},
  month = {september},
  abstract = {After decades of research, automatic speech processing has become
	more and more viable in recent years. Audio-video speech recognition
	has been shown to improve the recognition rate in noise-degraded
	environments. However, which audio and video speech parameters to
	choose for an optimal system and how they are related is still an
	open research issue. Here we present a number of statistical analyses
	that aim at increasing our understanding of such audio-video relationships.
	In particular, we look at the canonical correlation analysis and
	the coinertia analysis which investigate the relationship of linear
	combinations of parameters. The analyses are performed on Australian
	English as an example.},
  citeseerurl = {citeseer.ist.psu.edu/goecke03statistical.html},
  file = {Goecke03.pdf:Audio-Video/Goecke03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29},
  url = {citeseer.ist.psu.edu/goecke03statistical.html}
}

@INPROCEEDINGS{Goecke00,
  author = {Roland Goecke and Bruce Millar and Alexander Zelinsky and Jordi Robert-Ribes},
  title = {Automatic Extraction of Lip Feature Points},
  booktitle = {Australian Conference on Robotics and Automation, ACRA},
  year = {2000},
  pages = {31-36},
  address = {Melbourne (Australia)},
  month = {August},
  abstract = {We present a novel algorithm for the robust and reliable automatic
	extraction of lip feature points for speechreading. The algorithm
	uses a combination of colour information in the image data and knowledge
	about the structure of the mouth area to find certain feature points
	on the inner lip contour. A new confidence measure quantifying how
	well the feature extraction process worked is introduced. A parameter
	set describing the shape of the mouth is derived from the positions
	of the feature points. Using a stereo camera system, measurements
	are in 3D. Such a 3D parameter set is of great value for automatic
	speech-reading systems.},
  citeseerurl = {citeseer.ist.psu.edu/goecke00automatic.html},
  file = {Goecke00.pdf:Video/Lip_reading/Goecke00.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Goff96,
  author = {Bertrand Le Goff and Christian Benoit},
  title = {{A text-to-audiovisual-speech synthesizer for french}},
  booktitle = icslp,
  year = {1996},
  organization = {ISCA},
  file = {Goff96.pdf:Video/Segmentation/Viseme/Goff96.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Gonzalez10,
  author = {Javier Gonzalez-Dominguez and Igniacio Lopez-Moreno and Javier Franco-Pedroso
	and Daniel Ramos and Doroteo Torre Toledano and Joaquin Gonzalez-Rodriguez},
  title = {{Multilevel and Session Variability Compensated Language Recognition:
	ATVS-UAM Systems at NIST LRE 2009}},
  journal = {Selected Topics in Signal Processing, IEEE Journal of},
  year = {2010},
  volume = {4},
  pages = {1084--1093},
  number = {6},
  file = {Gonzalez10.pdf:Language_reco/Gonzalez10.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Gonzalez06,
  author = {Joaquin Gonzalez-Rodriguez and Andrzej Drygajlo and Daniel Ramos-Castro
	and Marta Garcia-Gomar and Javier Ortega-Garcia},
  title = {{Robust estimation, interpretation and assessment of likelihood ratios
	in forensic speaker recognition}},
  journal = csl,
  year = {2006},
  volume = {20},
  pages = {331--355},
  number = {2},
  file = {Gonzalez06.pdf:Speaker_reco/Useful_information/Gonzalez06.pdf:PDF},
  publisher = {Elsevier}
}

@BOOK{Gonzalez07,
  title = {{Forensic Automatic Speaker Classification in the "Coming Paradigm
	Shift"}},
  publisher = {Springer},
  year = {2007},
  author = {Joaquin Gonzalez-Rodriguez. and Daniel Ramos},
  pages = {205--217},
  file = {Gonzalez07.pdf:Speaker_reco/Divers/Gonzalez07.pdf:PDF},
  journal = {Speaker Classification I}
}

@ARTICLE{Grezl07,
  author = {Frantisek Gr\'ezl and Jan Cernock\^y},
  title = {TRAP-based Techniques for Recognition of Noisy Speech},
  journal = {Lecture Notes in Computer Science},
  year = {2007},
  volume = {2007},
  pages = {270-277},
  number = {9},
  owner = {antho},
  timestamp = {2008.11.12}
}

@INPROCEEDINGS{Graciarena09,
  author = {Martin Graciarena and Tobias Bocklet and Elizabeth Shriberg and Andreas
	Stolcke and Sachin Kajarekar},
  title = {{Feature-Based and Channel-Based Analyses of Intrinsic Variability
	in Speaker Verification}},
  booktitle = interspeech,
  year = {2009},
  publisher = {Citeseer},
  file = {Graciarena09.pdf:Speaker_reco/FA/Graciarena09.pdf:PDF}
}

@MISC{gravier-spro,
  author = {Gravier, G.},
  title = {{SPro: speech signal processing toolkit}},
  journal = {Software available at http://gforge. inria. fr/projects/spro}
}

@ARTICLE{Gray84,
  author = {Robert M. Gray},
  title = {Vector Quantization},
  journal = {IEEE ASSP Magazine},
  year = {1984},
  volume = {1},
  pages = {4-29},
  number = {2},
  month = {April},
  abstract = {A vector quantizer is a system for mapping a sequence of continuous
	or discrete vectors into a digital sequence suitable for communication
	over or storage in a digital channel. The goal of such a system is
	data compression: to reduce the bit rate so as to minimize communication
	channel capacity or digital storage memory requirements while maintaining
	the necessary fidelity of the data. The mapping for each vector may
	or may not have memory in the sense of depending on past actions
	of the coder, just as in well established scalar techniques such
	as PCM, which has no memory, and predictive quantization, which does.
	Even though information theory implies that one can always obtain
	better performance by coding vectors instead of scalars, scalar quantizers
	have remained by far the most common data compression system because
	of their simplicity and good performance when the communication rate
	is sufficiently large. In addition, relatively few design techniques
	have existed for vector quantizers. During the past few years several
	design algorithms have been developed for a variety of vector quantizers
	and the performance of these codes has been studied for speech waveforms,
	speech linear predictive parameter vectors, images, and several simulated
	random processes. It is the purpose of this article to survey some
	of these design techniques and their applications.},
  file = {Gray84.pdf:Speaker_reco/VQ/Gray84.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.23}
}

@INPROCEEDINGS{Guo07,
  author = {Wu Guo and Pan Lei and Ren-Hua Wang and Li-Rong Dai},
  title = {{Angle of Models Distance as Test Algorithm in Speaker Verification}},
  booktitle = {International Conference on Fuzzy Systems and Knowledge Discovery},
  year = {2007},
  volume = {4},
  pages = {231--234},
  organization = {IEEE},
  file = {Guo07.pdf:Speaker_reco/Scoring/Guo07.pdf:PDF}
}

@ARTICLE{Gupta07,
  author = {Gupta, V. and Kenny, P. and Ouellet, P. and Boulianne, G. and Dumouchel,
	P.},
  title = {{Combining Gaussianized/non-Gaussianized Features to Improve Speaker
	Diarization of Telephone Conversations}},
  journal = {IEEE Signal Processing Letters},
  year = {2007},
  volume = {14},
  pages = {1040},
  number = {12},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_Diarization/Gupta07.pdf:PDF},
  publisher = {INSTITUTE OF ELECTRICAL AND ELECTRONICS ENGINEERS}
}

@INPROCEEDINGS{Gutman02,
  author = {Dan Gutman and Yuval Bistritz},
  title = {{Speaker verification using phoneme-adapted gaussian mixture models}},
  booktitle = eurospeech,
  year = {2002},
  volume = {3},
  pages = {85--88},
  file = {Gutman02.pdf:Speaker_reco/Phonetic/Gutman02.pdf:PDF}
}

@INPROCEEDINGS{Gutschoven00,
  author = {B. Gutschoven and P. Verlinde},
  title = {Multi-modal identity verification using support vector machines (SVM)},
  booktitle = {Conference on Information Fusion, 2000. FUSION 2000. Proceedings
	of the Third International},
  year = {2000},
  volume = {2},
  pages = {THB3/3-THB3/8},
  abstract = {The contribution of this paper is twofold: (1) to formulate a decision
	fusion problem that is encountered in the design of a multi-modal
	identity verification system as a particular classification problem,
	and (2) to solve this problem by using a support vector machine (SVM).
	The multi-modal identity verification system under consideration
	is built of d modalities in parallel, each one delivering as output
	a scalar number, called a score, stating how well the claimed identity
	is verified. A fusion module receiving the d scores as input has
	to take a binary decision: to accept or reject the identity. This
	fusion problem has been solved using SVMs. The performance of this
	fusion module has been evaluated and compared with other proposed
	methods on a multi-modal database containing both vocal and visual
	modalities.},
  owner = {larcher},
  timestamp = {2006.06.19}
}

@INPROCEEDINGS{Hansen06,
  author = {Eric G. Hansen and Raymond E. Slyh and Timothy R. Anderson},
  title = {{Supervised and unsupervised speaker adaptation in the nist 2005
	speaker recognition evaluation}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--8},
  organization = {IEEE},
  file = {Hansen06.pdf:Speaker_reco/Unsupervised/Hansen06.pdf:PDF}
}

@INPROCEEDINGS{Hansen04,
  author = {Eric G. Hansen and Raymond E. Slyh and Timothy R. Anderson},
  title = {{Speaker recognition using phoneme-specific GMMs}},
  booktitle = odyssey,
  year = {2004},
  organization = {ISCA},
  file = {Hansen04.pdf:Speaker_reco/Text_dependent/Hansen04.pdf:PDF}
}

@INPROCEEDINGS{Hansen90,
  author = {Hansen, J.H.L. and Bria, O.N.},
  title = {{Lombard effect compensation for robust automatic speech recognition
	in noise}},
  booktitle = {First International Conference on Spoken Language Processing},
  year = {1990},
  organization = {ISCA},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Hansen09,
  author = {John Hansen and Vaishnevi Varadarajan},
  title = {{Analysis and compensation of Lombard speech across noise type and
	levels with application to in-set/out-of-set speaker recognition}},
  journal = taslp,
  year = {2009},
  volume = {17},
  pages = {366--378},
  number = {2},
  file = {Hansen09.pdf:Speaker_reco/Variability/Hansen09.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Harshavardhan10_b,
  author = {Harshavardhan, S. and Seelamantula, C.S. and Sreenivas, T.V.},
  title = {{A Multimodal Density Function Estimation Approach to Formant Tracking}},
  booktitle = interspeech,
  year = {2010},
  pages = {2410--2413},
  file = {Harshavardhan10_b.pdf:Outils/StudentT/Harshavardhan10_b.pdf:PDF}
}

@INPROCEEDINGS{Harshavardhan10,
  author = {Harshavardhan, S. and Sreenivas, T.V.},
  title = {{Robust Mixture Modeling Using T-Distribution: Application to Speaker
	ID}},
  booktitle = interspeech,
  year = {2010},
  pages = {2750--2753},
  file = {Harshavardhan10.pdf:Outils/StudentT/Harshavardhan10.pdf:PDF}
}

@TECHREPORT{Hart02,
  author = {Emma Hart},
  title = {{Immunology as a metaphor for computational information processing:
	Fact or fiction ?}},
  institution = {Institute Division of Informatics, University of Edinburgh},
  year = {2002},
  file = {Hart02.pdf:Artificial_Immune_System/Hart02.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.02}
}

@ARTICLE{Hart08,
  author = {Emma Hart and Jon Timmis},
  title = {{Application areas of AIS: The past, the present and the future}},
  journal = {Applied Soft Computing},
  year = {2008},
  volume = {8},
  pages = {191--201},
  number = {1},
  file = {Hart08.pdf:Artificial_Immune_System/Hart08.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Hatch06,
  author = {Andrew O. Hatch and Sachin Kajarekar and Andreas Stolcke},
  title = {{Within-Class Covariance Normalization for SVM-based Speaker Recognition}},
  booktitle = interspeech,
  year = {2006},
  pages = {1471--1474},
  file = {Hatch06.pdf:Speaker_reco/WCCN/Hatch06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.24}
}

@INPROCEEDINGS{Hatch06_b,
  author = {Andrew O. Hatch and Andreas Stolcke},
  title = {{Generalized linear kernels for one-versus-all classification: application
	to speaker recognition}},
  booktitle = icassp,
  year = {2006},
  pages = {585--588},
  file = {Hatch06_b.pdf:Speaker_reco/WCCN/Hatch06_b.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.24}
}

@BOOK{Haton06,
  title = {{Reconnaissance automatique de la parole, du signal à son inteprétation}},
  publisher = {Dunod},
  year = {2006},
  author = {Jean-Paul Haton and Christophe Cerisara and Dominique Fohr and Yves
	Laprie and Kamel Smaili},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Hautomaki11,
  author = {Ville Hautomaki and Kong Aik Lee and Anthony Larcher and Tomi Kinnunen
	and Bin Ma and Haizhou Li},
  title = {{Experiments with large scale regularized fusion on NIST SRE 2010}},
  booktitle = {NIST-SRE Analysis Workshop},
  year = {2011},
  file = {:/home/antho/I2R/Tex/Articles/25_NIST-SRE-Analysis_-Score_Fusion/regularized-fusion-SRE_V3.pdf:PDF},
  owner = {antho},
  timestamp = {2012.03.02}
}

@ARTICLE{Hawley07,
  author = {Mark S. Hawley and Pam Enderby and Phil Green and Stuart Cunningham
	and Simon Brownsell and
	
	James Carmichael and Mark Parker and Athanassios Hatzis and Peter
	O'Neill and Rebecca Palmer},
  title = {{A speech-controlled environmental control system for people with
	severe dysarthria}},
  journal = {Medical engineering \& physics},
  year = {2007},
  volume = {29},
  pages = {586--593},
  number = {5},
  file = {Hawley07.pdf:Customisation/Hawley07.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Hayakawa94,
  author = {Shoji Hayakawa and Fumitada Itakura},
  title = {{Text-dependent speaker recognition using the information in the
	higher frequency band}},
  booktitle = icassp,
  year = {1994},
  pages = {137--140},
  organization = {IEEE},
  file = {Hayakawa94.pdf:Speaker_reco/Text_dependent/Hayakawa94.pdf:PDF}
}

@MASTERSTHESIS{Woo05,
  author = {Ram H. Woo Timothy J. Hazen},
  title = {{Exploration of small enrollment speaker verification on handheld
	devices}},
  school = {Department of Electrical Engineering and Computer Science - MIT},
  year = {2005},
  file = {Woo05.pdf:Speaker_reco/Text_dependent/Woo05.pdf:PDF},
  publisher = {Massachusetts Institute of Technology}
}

@INPROCEEDINGS{Hazen93,
  author = {Timothy Hazen and Victor W. Zue},
  title = {{Automatic language identification using a segment-based approach}},
  booktitle = interspeech,
  year = {1993},
  file = {Hazen93.pdf:Language_reco/Hazen93.pdf:PDF},
  owner = {antho},
  timestamp = {2011.01.12}
}

@ARTICLE{Hazen06,
  author = {Timothy J. Hazen},
  title = {Visual model structures and synchrony constraints for audio-visual
	speech recognition},
  journal = tassp,
  year = {2006},
  volume = {14},
  pages = {1082-1089},
  number = {3},
  month = {May},
  abstract = {This paper presents the design and evaluation of a speaker-independent
	audio-visual speech recognition (AVSR) system that utilizes a segment-based
	modeling strategy. The audio and visual feature streams are integrated
	using a segment-constrained hidden Markov model, which allows the
	visual classifier to process visual frames with a constrained amount
	of asynchrony relative to proposed acoustic segments. The core experiments
	in this paper investigate several different visual model structures,
	each of which provides a different means for defining the units of
	the visual classifier and the synchrony constraints between the audio
	and visual streams. Word recognition experiments are conducted on
	the AV-TIMIT corpus under variable additive noise conditions. Over
	varying acoustic signal-to-noise ratios, word error rate reductions
	between 14% and 60% are observed when integrating the visual information
	into the automatic speech recognition process.},
  doi = {10.1109/TSA.2005.857572},
  file = {Hazen06.pdf:Video/Segmentation/Viseme/Hazen06.pdf:PDF;Hazen06.pdf:Audio-Video/Hazen06.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.05.28}
}

@INPROCEEDINGS{Hazen03,
  author = {Timothy J. Hazen and Douglas A. Jones and Alex Park amd Linda C.
	Kukolich and Douglas A. Reynolds},
  title = {{Integration of speaker recognition into conversational spoken dialogue
	systems}},
  booktitle = {Eighth European Conference on Speech Communication and Technology},
  year = {2003},
  pages = {1961--1964},
  address = {Geneva, Switzerland},
  organization = {Citeseer},
  file = {Hazen03.pdf:Speaker_reco/Divers/Hazen03.pdf:PDF}
}

@INPROCEEDINGS{Hazen04,
  author = {Timothy J. Hazen and Kate Saenko and Chia-Hao La and James R. Glass},
  title = {A segment-based audio-visual speech recognizer: data collection,
	development, and initial experiments},
  booktitle = {International Conference on Multimodal Interfaces},
  year = {2004},
  pages = {235-242},
  abstract = {This paper presents the development and evaluation of a speaker-independent
	audio-visual speech recognition (AVSR) system that utilizes a segment-based
	modeling strategy. To support this research, we have collected a
	new video corpus, called Audio-Visual TIMIT (AV-TIMIT), which consists
	of 4 total hours of read speech collected from 223 different speakers.
	This new corpus was used to evaluate our new AVSR system which incorporates
	a novel audio-visual integration scheme using segment-constrained
	Hidden Markov Models (HMMs). Preliminary experiments have demonstrated
	improvements in phonetic recognition performance when incorporating
	visual information into the speech recognition process.},
  file = {Hazen04.pdf:Audio-Video/Hazen04.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.05.28}
}

@INPROCEEDINGS{Hebert03,
  author = {Matthieu Hebert and Larry P. Heck},
  title = {Phonetic Class-Based Speaker Verification},
  booktitle = eurospeech,
  year = {2003},
  pages = {1665-1668},
  address = {Geneva},
  month = {September},
  file = {Hebert03.pdf:Speaker_reco/Text_dependent/Hebert03.pdf:PDF},
  owner = {antho},
  timestamp = {2008.07.21}
}

@INPROCEEDINGS{Hebert04,
  author = {Matthieu Hebert and Nikki Mirghafori},
  title = {{Desperately seeking impostors: Data-mining for competitive impostor
	testing in a text-dependent speaker verification system}},
  booktitle = icassp,
  year = {2004},
  pages = {361--364},
  organization = {Citeseer},
  file = {Hebert04.pdf:Speaker_reco/Text_dependent/Hebert04.pdf:PDF}
}

@INPROCEEDINGS{Heck00,
  author = {Larry P. Heck and Nikki Mirghafori},
  title = {{On-line unsupervised adaptation in speaker verification}},
  booktitle = interspeech,
  year = {2000},
  pages = {454--457},
  file = {Heck00.pdf:Speaker_reco/Unsupervised/Heck00.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.08}
}

@ARTICLE{Hermansky90,
  author = {Hynek Hermansky},
  title = {{Perceptual linear predictive (PLP) analysis of speech}},
  journal = jasa,
  year = {1990},
  volume = {87},
  pages = {1738-1752},
  citeseerurl = {http://citeseer.ist.psu.edu/context/19019/0},
  file = {Hermansky90.pdf:Parametrisation/Hermansky90.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Hermansky92,
  author = {Hynek Hermansky and Nelson Morgan and Aruna Bayya and Phil Kohn},
  title = {{RASTA-PLP speech analysis technique}},
  booktitle = icassp,
  year = {1992},
  volume = {1},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Hermansky91,
  author = {Hynek Hermansky and Nelson Morgan and Aruna Bayya and Phil Kohn},
  title = {{Compensation for the effect of the communication channel in auditory-like
	analysis of speech (RASTA-PLP)}},
  booktitle = eurospeech,
  year = {1991},
  organization = {ISCA},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Hermansky99,
  author = {Hermansky, H. and Sharma, S.},
  title = {{Temporal patterns (TRAPs) in ASR of noisy speech}},
  booktitle = icassp,
  year = {1999},
  volume = {1},
  file = {Hermansky99.pdf:Parametrisation/Hermansky99.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Hershey00,
  author = {John Hershey and Javier Movellan},
  title = {Audio vision : using audio visual synchrony to locate sounds},
  journal = {Advances in Neural Information Processing Systems},
  year = {2000},
  volume = {12},
  pages = {813-819},
  file = {Hershey00.pdf:Audio-Video/Hershey00.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.26}
}

@ARTICLE{Higgins91,
  author = {Alan L. Higgins and Lawrence Bahler and Jack Porter},
  title = {{Speaker verification using randomized phrase prompting}},
  journal = dsp,
  year = {1991},
  volume = {1},
  pages = {89--106},
  booktitle = dsp,
  file = {Higgins91.pdf:Speaker_reco/Text_dependent/Higgins91.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Hjelmas01,
  author = {Eric Hjelmas and Boon Kee Low},
  title = {{Face detection: A survey}},
  journal = {Computer Vision and Image Understanding},
  year = {2001},
  volume = {83},
  pages = {236--274},
  number = {3},
  owner = {antho},
  timestamp = {2009.02.09}
}

@INPROCEEDINGS{Ho92,
  author = {Tin Kam Ho and Jonathan J. Hull and Sargur N. Srihari},
  title = {Combination of decisions by multiple classifiers},
  booktitle = {Structured Document Image Analysis},
  year = {1992},
  pages = {188--202},
  publisher = {Springer-Verlag},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Hoffmeister07,
  author = {Hoffmeister, B. and Hillard, D. and Hahn, S. and Schluter, R. and
	Ostendorf, M. and Ney, H.},
  title = {{Cross-site and intra-site ASR system combination: Comparisons on
	lattice and 1-best methods}},
  booktitle = icassp,
  year = {2007},
  volume = {4},
  organization = {IEEE},
  isbn = {1424407273},
  issn = {1520-6149}
}

@INPROCEEDINGS{Hofmann99,
  author = {Thomas Hofmann},
  title = {{Probabilistic latent semantic analysis}},
  booktitle = {Uncertainty in Artificial Intelligence},
  year = {1999},
  pages = {21},
  organization = {Citeseer},
  file = {Hofmann99.pdf:Information_Retrieval/Hofmann99.pdf:PDF}
}

@ARTICLE{Hollien74,
  author = {Hollien, H. and Majewski, W. and Hollien, PA},
  title = {{Perceptual identification of voices under normal, stress, and disguised
	speaking conditions}},
  journal = {The Journal of the Acoustical Society of America},
  year = {1974},
  volume = {56},
  pages = {S53},
  file = {Hollien74.pdf:Divers/Hollien74.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Hong99,
  author = {Lin Hong and Anil Jain and Sarath Pankanti},
  title = {Can Multibiometrics Improve Performance ?},
  booktitle = {AutoID'99},
  year = {1999},
  pages = {59-64},
  month = {October},
  owner = {larcher},
  timestamp = {2006.06.19}
}

@ARTICLE{Hotelling36,
  author = {Hotelling, H.},
  title = {Relations between two sets of variates},
  journal = {Biometrika},
  year = {1936},
  volume = {28},
  pages = {321--377},
  number = {3-4},
  owner = {antho},
  publisher = {Biometrika Trust},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Huang06,
  author = {Chao Huang and Yingchun Huang and Frank Kao Ping Soong and Jianlai
	Zhou},
  title = {Weighted Likelihood Ratio (WLR) Hidden Markov Model for Noisy Speech
	Recognition},
  booktitle = icassp,
  year = {2006},
  volume = {1},
  pages = {37-40},
  address = {Toulouse},
  month = {mai},
  abstract = {In this paper we present a weighted likelihood ratio (WLR) based Hidden
	Markov Model and apply it to speech recognition in noise. The WLR
	measure emphasizes spectral peaks than valleys in comparing two given
	speech spectra. The measure is more consistent with human perception
	of speech formants where natural resonances of vocal track are and
	tends to be more robust to broad-band noise interferences than other
	measures. A complete HMM framework of this measure is derived and
	a mixture of exponential kernels is used to model the output probability
	density function. The new WLR-HMM is tested on the Aurora2 connected
	digits database in noise. It shows more robust performance than the
	MFCC trained GMM baseline system. When combined with the dynamic
	cepstral features, the multiple-stream WLR-HMM shows a 39% relative
	improvement over the baseline},
  file = {Huang06.pdf:Speech_reco/Continuous/Huang06.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.04.11}
}

@INPROCEEDINGS{Huang08,
  author = {Chien-Lin Huang and Bin Ma and Chung-Hsien Wu and Brian Mak and Haizhou
	Li},
  title = {{Robust speaker verification using short-time frequency with long-time
	window and fusion of multi-resolutions}},
  booktitle = interspeech,
  year = {2008},
  file = {:/Volumes/Donnees/LIA/biblio/Parametrisation/Huang08.pdf:PDF}
}

@INPROCEEDINGS{Huang02,
  author = {Huang, K. and Trivedi, M.},
  title = {Streaming Face Recognition Using Multicamera Video Arrays},
  booktitle = {International Conference on Pattern recognition},
  year = {2002},
  volume = {16},
  pages = {213--216},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Huang95,
  author = {William Y. Huang and Bhaskar D. Rao},
  title = {{Channel and noise compensation for text dependent speaker verification
	over telephone}},
  booktitle = icassp,
  year = {1995},
  volume = {1},
  pages = {337--337},
  organization = {INSTITUTE OF ELECTRICAL ENGINEERS INC (IEE)},
  file = {Huang95.pdf:Speaker_reco/Text_dependent/Huang95.pdf:PDF}
}

@BOOK{Huang01,
  title = {{Spoken language processing: A guide to theory, algorithm, and system
	development}},
  publisher = {Prentice Hall PTR Upper Saddle River, NJ, USA},
  year = {2001},
  author = {Xuedong Huang and Alejandro Acero and Hsiao-Wuen Hon}
}

@ARTICLE{Huenupan10,
  author = {Fernando Huenup{\'a}n and Nestor Becerra Yoma and Claudio Garret{\'o}n
	and Carlos Molina},
  title = {{On-Line Linear Combination of Classifiers Based on Incremental Information
	in Speaker Verification}},
  journal = {ETRI Journal},
  year = {2010},
  volume = {32},
  pages = {395--405},
  number = {3},
  file = {Huenupan10.pdf:Speaker_reco/Score_Fusion/Huenupan10.pdf:PDF}
}

@INPROCEEDINGS{Huerta98,
  author = {Juan M. Huerta and Richard M. Stern},
  title = {{Speech recognition from GSM codec parameters}},
  booktitle = icslp,
  year = {1998},
  volume = {4},
  pages = {1463--1466},
  organization = {Citeseer},
  file = {Huerta98.pdf:Speaker_reco/Compression/Huerta98.pdf:PDF}
}

@ARTICLE{Hunt96,
  author = {John E. Hunt and Denise Cooke},
  title = {{Learning using an artificial immune system}},
  journal = {Journal of network and computer applications},
  year = {1996},
  volume = {19},
  pages = {189--212},
  number = {2},
  file = {Hunt96.pdf:Artificial_Immune_System/Hunt96.pdf:PDF},
  publisher = {London; New York: Academic Press, 1982-1995.}
}

@ARTICLE{Hyvarinen00,
  author = {Hyv{\\"a}rinen, A. and Oja, E.},
  title = {{Independent component analysis: algorithms and applications}},
  journal = {Neural networks},
  year = {2000},
  volume = {13},
  pages = {411--430},
  number = {4-5},
  file = {Hyvarinen00.pdf:Outils/Dimensionality_Reduction/Hyvarinen00.pdf:PDF},
  issn = {0893-6080},
  publisher = {Elsevier}
}

@BOOK{Hebert08,
  title = {{Text-dependent speaker recognition}},
  publisher = {Springer-Verlag, Heidelberg},
  year = {2008},
  author = {Matthieu H{\'e}bert},
  pages = {743--762},
  file = {Hebert08.pdf:Speaker_reco/Text_dependent/Hebert08.pdf:PDF}
}

@INPROCEEDINGS{Hebert05,
  author = {Matthieu H{\'e}bert and Daniel Boies},
  title = {{T-norm for text-dependent commercial speaker verification applications:
	Effect of lexical mismatch}},
  booktitle = icassp,
  year = {2005},
  pages = {729--732},
  file = {Hebert05.pdf:Speaker_reco/Text_dependent/Hebert05.pdf:PDF}
}

@ARTICLE{Ikedo98,
  author = {Jotaro Ikedo},
  title = {{Voice activity detection using neural network}},
  journal = {IEICE Transactions on Communications},
  year = {1998},
  volume = {81},
  pages = {2509--2513},
  number = {12},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Ioffe06,
  author = {Sergey Ioffe},
  title = {{Probabilistic linear discriminant analysis}},
  journal = {Computer Vision},
  year = {2006},
  pages = {531--542},
  file = {Ioffe06.pdf:Outils/PLDA/Ioffe06.pdf:PDF},
  publisher = {Springer}
}

@INPROCEEDINGS{Ismail98,
  author = {Shanin Ismail and Botros Nazeih},
  title = {{Text-Dependent Speaker Identification Using Hidden Markov Model
	with Stress Compensation Technique}},
  booktitle = {IEEE Southeastcon '98},
  year = {1998},
  pages = {61--64},
  doi = {10.1109/SECON.1998.673292},
  file = {Ismail98.pdf:Speaker_reco/Text_dependent/Ismail98.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.19}
}

@ARTICLE{Israel05,
  author = {Steven A. Israel and John M. Irvine and Andrew Cheng and Mark D.
	Wiederhold and Brenda K. Wiederhold},
  title = {{ECG to identify individuals}},
  journal = {Pattern Recognition},
  year = {2005},
  volume = {38},
  pages = {133--142},
  number = {1},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@BOOK{Iyengar95,
  title = {Advances in Distributed Sensor Technology},
  publisher = {Prentice-Hall},
  year = {1995},
  author = {Iyengar, SS and Prasad, L. and Min, H.},
  journal = {Englewood Cli. s, NJ},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Jaakkola99,
  author = {Tommi S. Jaakkola and David Haussler},
  title = {Exploiting Generative Models in Discriminative Classifiers},
  journal = {Advances in Neural Informations Processing Systems},
  year = {1999},
  volume = {11},
  pages = {487--493},
  owner = {antho},
  publisher = {MIT; 1998},
  timestamp = {2009.10.05}
}

@ARTICLE{Jain05,
  author = {Anil Jain and Karthik Nandakumar and Arun Ross},
  title = {{Score normalization in multimodal biometric systems}},
  journal = {Pattern recognition},
  year = {2005},
  volume = {38},
  pages = {2270--2285},
  number = {12},
  file = {Jain05.pdf:Speaker_reco/Score_Fusion/Jain05.pdf:PDF},
  issn = {0031-3203},
  publisher = {Elsevier}
}

@ARTICLE{Jain04,
  author = {Anil K. Jain and Arun Ross and Salil Prabhakar},
  title = {An introduction to biometric recognition},
  journal = {Circuits and Systems for Video Technology, IEEE Transactions on},
  year = {2004},
  volume = {14},
  pages = {4--20},
  number = {1},
  file = {Jain04.pdf:Divers/Jain04.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@BOOK{Jain99,
  title = {Biometrics: Personal Identification in Networked Society},
  publisher = {Kluwer Academic Publishers},
  year = {1999},
  author = {De Anil K. Jain and Ruud Bolle and Sharath Pankanti},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Jancik10,
  author = {Zdenek Jancik and Oldrich Plchot and Niko Brummer and Lukas Burget
	and Ondrej Glembek and Valiantsina Hubeika and Martin Karafiat and
	Pavel Matejka and Tomas Mikolov and Albert Strasheim and Jan Cernocky},
  title = {{Data selection and calibration issues in automatic language recognition
	- investigation with BUT-AGNITIO NIST LRE 2009 system}},
  booktitle = odyssey,
  year = {2010},
  file = {Jancik10.pdf:Language_reco/Jancik10.pdf:PDF},
  owner = {antho},
  timestamp = {2011.03.11}
}

@ARTICLE{Jelinek76,
  author = {Frederick Jelinek},
  title = {Continuous speech recognition by statistical methods},
  journal = ieee,
  year = {1976},
  volume = {64},
  pages = {532-556},
  abstract = {Statistical methods useful in automatic recognition of continuous
	speech are described. They concern modeling of a speaker and of an
	acoustic processor, extraction of the models' statistical parameters
	and hypothesis search procedures and likelihood computations of linguistic
	decoding. Experimental results are presented that indicate the power
	of the methods.},
  file = {Jelinek76.pdf:Speech_reco/Continuous/Jelinek76.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.08.21}
}

@INPROCEEDINGS{Jin98,
  author = {Hubert Jin and Spyros Matsoukas and Richard Schwartz and and Francis
	Kubala},
  title = {Fast robust inverse transform SAT and multi-stage adaptation},
  booktitle = {Proceedings DARPA Broadcast News Transcription and Understanding
	Workshop},
  year = {1998},
  pages = {105-109},
  address = {Lansdowne (USA)},
  abstract = {We present a new method of Speaker Adapted Training (SAT) that is
	more robust, faster, and results in lower error rate than the previous
	methods. The method, called Inverse Transform SAT (ITSAT) is based
	on removing the di#erences between speakers before training, rather
	than modeling the di#erences during training. We develop several
	methods to avoid the problems associated with inverting the transformation.
	In one method, weinterpolate the transformation matrix with an identity
	or diagonal transformation. We also apply constraints to the matrix
	to avoid estimation problems. We show that by using many diagonal-only
	transformation matrices with constraints we can achieve performance
	that is comparable to that of the original SAT method at a fraction
	of the cost. In addition, we describe a multi-stage approach to Maximum
	Likelihood Linear Regression (MLLR) unsupervised adaptation and we
	show that is more effective than a single stage regular MMLR adaptation.
	As a final stage, we adapt the resulting model at a finer resolution,
	using maximum A Posteriori (MAP) adaptation. With the combination
	of all the above adaptation methods we obtain a 13.6% overall reduction
	in WER relative to speaker independent (SI) training and decoding.},
  citeseerurl = {http://citeseer.ist.psu.edu/jin98fast.html},
  file = {Jin98.pdf:Speaker_reco/Adaptation/SAT/Jin98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Jin03,
  author = {Qin Jin and Jiri Navratil and Douglas A. Reynolds and Joseph P. Campbell
	and Walter D. Andrews and Joy S. Abramson},
  title = {{Combining cross-stream and time dimensions in phonetic speaker recognition}},
  booktitle = icassp,
  year = {2003},
  volume = {4},
  organization = {IEEE},
  file = {Jin03.pdf:Speaker_reco/Phonetic/Jin03.pdf:PDF},
  isbn = {0780376633},
  issn = {1520-6149}
}

@PHDTHESIS{Johnson97,
  author = {Sue Johnson},
  title = {Speaker Tracking},
  school = {University of Cambridge},
  year = {1997},
  file = {Johnson97.pdf:Divers/Speaker_tracking/Johnson97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@ARTICLE{Jolliffe02,
  author = {Ian Jolliffe},
  title = {{Principal component analysis}},
  journal = {Encyclopedia of Statistics in Behavioral Science},
  year = {2002},
  publisher = {Wiley Online Library}
}

@PHDTHESIS{Jourlin98,
  author = {Pierre Jourlin},
  title = {Approche Bimodale du Traitement Automatique de la Parole : application
	\`a la Reconnaissance du Message et du Locuteur},
  school = {Universit\'e d'Avignon et des Pays de Vaucluse},
  year = {1998},
  month = {April},
  file = {Jourlin98.pdf:Audio-Video/Jourlin98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@INPROCEEDINGS{Jourlin97_2,
  author = {Pierre Jourlin},
  title = {Estimating acoustic-labial weights in connected speech recognition
	systems based on HMM},
  booktitle = icsmc,
  year = {1997},
  volume = {1},
  pages = {168-173},
  address = {Orlando (USA)},
  month = {October},
  abstract = {Describes an approach for weighting the contribution of the acoustic
	and visual sources of information in a bimodal connected speech recognition
	system. We consider that a different acoustic-labial weight is attached
	to each recognition unit. The values of the weighting vector are
	optimised in order to minimise the error rate on a learning set.
	Experiments are performed on a two-speakers audiovisual database,
	composed of connected letters, with two different acoustic-labial
	speech recognition systems. For both speakers and both systems, the
	weights optimisation allows us to increase the recognition rate of
	our bimodal system},
  doi = {10.1109/ICSMC.1997.625743},
  file = {Jourlin97_2.pdf:Audio-Video/Jourlin97_2.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@INPROCEEDINGS{Jourlin97_3,
  author = {Pierre Jourlin},
  title = {Word-Dependent Acoustic-Labial Weights in HMM-based Speech Recognition},
  booktitle = avsp,
  year = {1997},
  pages = {69-72},
  address = {Rhodes (Greece)},
  abstract = {This paper describes a novel approach for weighting
	
	the contribution of the acoustic and visual sources
	
	of information in a bimodal connected speech recognition
	
	system. We consider that a different acousticlabial
	
	weight is attached to each recognition unit. The
	
	values of the weighting vector are optimised in order
	
	to minimise error rate on a learning set. Experiments
	
	are performed on a two-speakers audio-visual
	
	database, composed of connected letters, with two
	
	different acoustic-labial speech recognition systems.
	
	For both speakers and both systems, the weights optimisation
	
	allows us to increase the recognition rate
	
	of our bimodal system.},
  citeseerurl = {citeseer.ist.psu.edu/279607.html},
  file = {Jourlin97_3.pdf:Audio-Video/Jourlin97_3.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@ARTICLE{Jourlin97_1,
  author = {Pierre Jourlin and Juergen Luettin and Dominique Genoud and Hubert
	Wassner},
  title = {Acoustic-Labial Speaker Verification},
  journal = {Pattern Recognition Letters},
  year = {1997},
  volume = {18},
  pages = {853-858},
  number = {9},
  abstract = {This paper describes a multimodal approach for speaker verification.
	The system consists of two classifiers, one using visual features,
	the other using acoustic features. A lip tracker is used to extract
	visual information from the speaking face which provides shape and
	intensity features. We describe an approach for normalizing and mapping
	different modalities onto a common confidence interval. We also describe
	a novel method for integrating the scores of multiple classifiers.
	Verification experiments are reported for the individual modalities
	and for the combined classifier. The integrated system outperformed
	each sub-system and reduced the false acceptance rate of the acoustic
	sub-system from 2.3% to 0.5%. q 1997 Elsevier Science B.V.},
  citeseerurl = {citeseer.ist.psu.edu/article/jourlin97acousticlabial.html},
  file = {Jourlin97_1.pdf:Audio-Video/Jourlin97_1.pdf:PDF},
  keywords = {Person authentication; Bimodal speech; Decision fusion; Lip feature
	extraction; Hidden Markov models},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Juang85,
  author = {B. Juang and L. Rabiner and S. Levinson and M. Sondhi},
  title = {Recent developments in the application of hidden Markov models to
	speaker-independent isolated word recognition},
  booktitle = icassp,
  year = {1985},
  volume = {10},
  pages = {9-12},
  address = {Tampa (US)},
  month = {April},
  abstract = {In this paper we extend previous work on isolated word recognition
	based on hidden Markov models by replacing the discrete symbol representation
	of the speech signal by a continuous Gaussian mixture density. In
	this manner the inherent quantization error introduced by the discrete
	representation is essentially eliminated. The resulting recognizer
	was tested on a vocabulary of the 10 digits across a wide range of
	talkers and test conditions, and shown to have an error rate at least
	comparable to that of the best template recognizers and significantly
	lower than that of the discrete symbol hidden Markov model system.
	Several issues involved in the training of the continuous density
	models and in the implementation of the recognizer are discussed.},
  owner = {larcher},
  timestamp = {2007.04.02}
}

@PHDTHESIS{these_Kahn,
  author = {Juliette Kahn},
  title = {{Parole de locuteur : performance et confiance en identification
	biométrique vocale}},
  school = {University of Avignon},
  year = {2011},
  file = {:Theses/these_Kahn .pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.07}
}

@INPROCEEDINGS{Kahn11,
  author = {Juliette Kahn and Nicolas Audibert and Jean-Francois Bonastre and
	Solange Rossato},
  title = {{Inter and intra-speaker variability in French: an analysis of oral
	vowels and itsimplication for automatic speaker verification}},
  booktitle = icphs,
  year = {2011},
  pages = {1002--1005},
  file = {Kahn11.pdf:Speaker_reco/Useful_information/Kahn11.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.08}
}

@INPROCEEDINGS{Kahn11_a,
  author = {Juliette Kahn and Nicolas Audibert and Solange Rossato and Jean-Francois
	Bonastre},
  title = {{Speaker verification by inexperienced and experienced listeners
	vs. speaker verification system}},
  booktitle = icassp,
  year = {2011},
  pages = {5912--5915},
  file = {Kahn11_a.pdf:Speaker_reco/HASR/Kahn11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@INPROCEEDINGS{Kahn10,
  author = {Juliette Kahn and Nicolas Audibert and Solange Rossato and Jean-Francois
	Bonastre},
  title = {{Intra-speaker variability effects on Speaker Verification performance}},
  booktitle = odyssey,
  year = {2010},
  pages = {109--116},
  file = {Kahn10.pdf:Speaker_reco/Divers/Kahn10.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.21}
}

@INPROCEEDINGS{Kahn09_b,
  author = {Juliette Kahn and Solange Rossato},
  title = {{Do Humans and speaker verification system use the same information
	to differentiate voices?}},
  booktitle = interspeech,
  year = {2009},
  pages = {2375--2378},
  file = {Kahn09_b.pdf:Speaker_reco/Useful_information/Kahn09_b.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.21}
}

@INPROCEEDINGS{Kahn09,
  author = {Juliette Kahn and Solange Rossato and Jean_Francois Bonastre},
  title = {{Beyond Doddington menagerie, a first step towards}},
  booktitle = icassp,
  year = {2009},
  file = {Kahn09.pdf:Speaker_reco/Divers/Kahn09.pdf:PDF}
}

@INPROCEEDINGS{Kajarekar09,
  author = {Kajarekar, S.S. and Scheffer, N. and Graciarena, M. and Shriberg,
	E. and Stolcke, A. and Ferrer, L. and Bocklet, T.},
  title = {{THE SRI NIST 2008 speaker recognition evaluation system}},
  booktitle = {Proceedings of the 2009 IEEE International Conference on Acoustics,
	Speech and Signal Processing-Volume 00},
  year = {2009},
  pages = {4205--4208},
  organization = {IEEE Computer Society},
  file = {Kajarekar09.pdf:Speaker_reco/Divers/Kajarekar09.pdf:PDF}
}

@INPROCEEDINGS{Kajarekar10,
  author = {Sachin S. Kajarekar},
  title = {{Across-phone variability and diagonal term in joint factor analysis
	for speaker recognition}},
  booktitle = icassp,
  year = {2010},
  pages = {4406--4409},
  organization = {IEEE},
  file = {Kajarekar10.pdf:Speaker_reco/FA/Kajarekar10.pdf:PDF},
  issn = {1520-6149}
}

@INPROCEEDINGS{Kajarekar08,
  author = {Sachin S. Kajarekar},
  title = {{Phone-based Cepstral Polynomial SVM System for Speaker Recognition}},
  booktitle = interspeech,
  year = {2008},
  file = {Kajarekar08.pdf:Speaker_reco/Phonetic/Kajarekar08.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Kajarekar01,
  author = {Sachin S. Kajarekar and Yegnanarayana, B. and Hynek Hermansky},
  title = {{A study of two dimensional linear discriminants for ASR}},
  booktitle = icassp,
  year = {2001},
  volume = {1},
  organization = {Citeseer},
  file = {Kajarekar01.pdf:Speech_reco/Kajarekar01.pdf:PDF}
}

@INPROCEEDINGS{Kanagasundaram11,
  author = {Ahilan Kanagasundaram and Robbie Vogt and David Dean and Sridha Sridharan
	and Michael Mason},
  title = {{i-vector Based Speaker Recognition on Short Utterances}},
  booktitle = interspeech,
  year = {2011},
  file = {Kanagasundaram11.PDF:Speaker_reco/FA/I-Vector/Kanagasundaram11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.08.25}
}

@INPROCEEDINGS{Kanak03,
  author = {A. Kanak and E. Erzin and Y. Yemez and A.M. Tekalp},
  title = {Joint audio-video processing for biometric speaker identification},
  booktitle = icassp,
  year = {2003},
  volume = {3},
  pages = {561-564},
  address = {Hong Kong},
  month = {april},
  abstract = {In this paper we present a bimodal audio-visual speaker identification
	system. The objective is to improve the recognition performance over
	conventional unimodal schemes. The proposed system exploits not only
	the temporal and spatial correlations existing in speech and video
	signals of a speaker, but also the cross-correlation between these
	two modalities. Lip images extracted for each video frame are transformed
	onto an eigenspace. The obtained eigenlip coefficients are interpolated
	to match the rate of the speech signal and fused with mel frequency
	cepstral coefficients (MFCC) of the corresponding speech signal.
	The resulting joint feature vectors are used to train and test a
	hidden Markov model (HMM) based identification system. Experimental
	results are also included for demonstration of the system performance.},
  file = {Kanak03.pdf:Audio-Video/Kanak03.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.05.28}
}

@INPROCEEDINGS{Karam07,
  author = {Karam, Z.N. and Campbell, W.M.},
  title = {{A new kernel for SVM MLLR based speaker recognition}},
  booktitle = interspeech,
  year = {2007},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Karam10,
  author = {Zahi N. Karam and William M. Campbell},
  title = {{Graph-embedding for speaker recognition}},
  booktitle = interspeech,
  year = {2010},
  pages = {2742--2745},
  file = {Karam10.PDF:Speaker_reco/Divers/Karam10.PDF:PDF},
  owner = {antho},
  timestamp = {2010.10.07}
}

@INPROCEEDINGS{Karam11_a,
  author = {Zahi N. Karam and William M. Campbell and Najim Dehak},
  title = {{Towards reduced false-alarms using cohorts}},
  booktitle = icassp,
  year = {2011},
  pages = {4512--4515},
  file = {Karam11_a.pdf:Speaker_reco/Normalisation/Karam11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@INPROCEEDINGS{Kato03,
  author = {Tsuneo Kato and Tohru Shimizu},
  title = {{Improved speaker, verification over the cellular phone network using
	phoneme-balanced and digit-sequence-preserving connected digit patterns}},
  booktitle = icassp,
  year = {2003},
  pages = {57--60},
  file = {Kato03.pdf:Speaker_reco/Text_dependent/Kato03.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.08}
}

@ARTICLE{Kekre10,
  author = {Kekre, HB and Sarode, T.K. and Natu, S.J. and Natu, P.J.},
  title = {{Performance Comparison Of 2-D DCT On Full/Block Spectrogram And
	1-D DCT On Row Mean Of Spectrogram For Speaker Identification}},
  journal = {International Journal of Biometrics and Bioinformatics (IJBB)},
  year = {2010},
  volume = {4},
  pages = {100},
  number = {3},
  file = {Kekre10.pdf:Speaker_reco/Text_dependent/Kekre10.pdf:PDF}
}

@INPROCEEDINGS{Kenny10,
  author = {Patrick Kenny},
  title = {{Bayesian speaker verification with heavy-tailed priors}},
  booktitle = odyssey,
  year = {2010},
  owner = {antho},
  timestamp = {2011.11.17}
}

@TECHREPORT{Kenny05_2,
  author = {Kenny, P.},
  title = {{Joint factor analysis of speaker and session variability: Theory
	and algorithms}},
  institution = {CRIM},
  year = {2005},
  file = {Kenny05_2.pdf:Speaker_reco/FA/Kenny05_2.pdf:PDF},
  journal = {CRIM, Montreal, Canada}
}

@ARTICLE{Kenny05_b,
  author = {Patrick Kenny and Gilles Boulianne and Pierre Dumouchel},
  title = {{Eigenvoice modeling with sparse training data}},
  journal = tsap,
  year = {2005},
  volume = {13},
  pages = {345--354},
  number = {3},
  file = {Kenny05_b.pdf:Speaker_reco/FA/Kenny05_b.pdf:PDF}
}

@ARTICLE{Kenny07,
  author = {Patrick Kenny and Boulianne, G. and Ouellet, P. and Dumouchel, P.},
  title = {{Joint factor analysis versus eigenchannels in speaker recognition}},
  journal = taslp,
  year = {2007},
  volume = {15},
  pages = {1435},
  number = {4},
  file = {Kenny07.pdf:Speaker_reco/FA/Kenny07.pdf:PDF},
  owner = {antho},
  publisher = {IEEE},
  timestamp = {2009.10.05}
}

@ARTICLE{Kenny07_b,
  author = {Patrick Kenny and Gilles Boulianne and Pierre Ouellet and Pierre
	Dumouchel},
  title = {{Speaker and session variability in GMM-based speaker verification}},
  journal = taslp,
  year = {2007},
  volume = {15},
  pages = {1448--1460},
  file = {Kenny07_b.pdf:Speaker_reco/FA/Kenny07_b.pdf:PDF},
  owner = {antho},
  timestamp = {2011.11.11}
}

@INPROCEEDINGS{Kenny05,
  author = {Patrick Kenny and Boulianne, G. and Ouellet, P. and Dumouchel, P.},
  title = {{Factor analysis simplified}},
  booktitle = icassp,
  year = {2005},
  volume = {1},
  file = {Kenny05.pdf:Speaker_reco/FA/Kenny05.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Kenny04,
  author = {Kenny, P. and Dumouchel, P.},
  title = {{Disentangling speaker and channel effects in speaker verification}},
  booktitle = icassp,
  year = {2004},
  pages = {37--40},
  file = {Kenny04.pdf:Speaker_reco/FA/Kenny04.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Kenny03,
  author = {Patrick Kenny and Mihoubi, M. and Dumouchel, P.},
  title = {{New MAP estimators for speaker recognition}},
  booktitle = eurospeech,
  year = {2003},
  organization = {ISCA},
  file = {Kenny03.pdf:Speaker_reco/FA/Kenny03.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Kenny08,
  author = {Patrick Kenny and Pierre Ouellet and Najim Dehak and Vishwa Gupta
	and Pierre Dumouchel},
  title = {{A study of inter-speaker variability in speaker verification}},
  journal = taslp,
  year = {2008},
  volume = {16},
  pages = {980--988},
  number = {5},
  file = {Kenny08.pdf:Speaker_reco/FA/Kenny08.pdf:PDF}
}

@ARTICLE{Kenny09,
  author = {Kenny, P. and Reynolds, D. and Castaldo, F.},
  title = {{Diarization of Telephone Conversations using Factor Analysis}},
  journal = {{IEEE Journal of Selected Topics in Signal Processing}},
  year = {2009},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_Diarization/Kenny09.pdf:PDF}
}

@INPROCEEDINGS{Kharroubi01,
  author = {Jamal Kharroubi and Dijana Petrovska-Delakr\'etaz and G\'erard Chollet},
  title = {Combining GMM's with Support Vector Machines for Text-independent
	Speaker Verification},
  booktitle = eurospeech,
  year = {2001},
  pages = {1761-1764},
  address = {Scandinavia},
  owner = {larcher},
  timestamp = {2006.06.19}
}

@INPROCEEDINGS{Kim02,
  author = {Kim, Y.E. and Whitman, B.},
  title = {{Singer identification in popular music recordings using voice coding
	features}},
  booktitle = {International Conference on Music Information Retrieval},
  year = {2002},
  pages = {13--17},
  file = {Kim02.pdf:Divers/Music_Recognition/Kim02.pdf:PDF}
}

@ARTICLE{Kinnunen06,
  author = {Tomi Kinnunen and Evgeny Karpov and Pasi Franti},
  title = {{Real-time speaker identification and verification}},
  journal = taslp,
  year = {2006},
  volume = {14},
  pages = {277--288},
  number = {1},
  file = {Kinnunen06.pdf:Speaker_reco/Text_dependent/Kinnunen06.pdf:PDF}
}

@ARTICLE{Kinnunen10,
  author = {Tommi Kinnunen and Haizhou Li},
  title = {{An overview of text-independent speaker recognition: From features
	to supervectors}},
  journal = {Speech Communication},
  year = {2010},
  volume = {52},
  pages = {12--40},
  number = {1},
  file = {Kinnunen10.pdf:Speaker_reco/Divers/Kinnunen10.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Kittler98,
  author = {Josef Kittler and Mohamad Hatef and Robert P.W. Duin and Jiri Matas},
  title = {On Combining Classifiers},
  journal = pami,
  year = {1998},
  volume = {20},
  pages = {226-239},
  number = {3},
  month = {March},
  abstract = {We develop a common theoretical framework for combining classifiers
	which use distinct pattern representations and show that many existing
	schemes can be considered as special cases of compound classification
	where all the pattern representations are used jointly to make a
	decision. An experimental comparison of various classifier combination
	schemes demonstrates that the combination rule developed under the
	most restrictive assumptions-the sum rule-outperforms other classifier
	combinations schemes. A sensitivity analysis of the various schemes
	to estimation errors is carried out to show that this finding can
	be justified theoretically},
  doi = {10.1109/34.667881},
  owner = {larcher},
  timestamp = {2006.06.19}
}

@INPROCEEDINGS{Klessa09,
  author = {Katarzina Klessa and Grazina Demenko},
  title = {{Structure and Annotation of Polish LVCSR Speech Database}},
  booktitle = {Tenth Annual Conference of the International Speech Communication
	Association},
  year = {2009},
  file = {Klessa09.pdf:Base_de_donnees/Klessa09.pdf:PDF}
}

@INPROCEEDINGS{Kockmann10,
  author = {Marcel Kockmann and Lukas Burget and Ondrej Glembeck and Luciana
	Ferrer and Jan Cernocky},
  title = {{Prosodic Speaker Verification using Subspace Multinomial Models
	with Intersession Compensation}},
  booktitle = interspeech,
  year = {2010},
  pages = {1061--1064},
  file = {Kockmann10.pdf:Speaker_reco/FA/I-Vector/Kockmann10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.10.04}
}

@INPROCEEDINGS{Koolwaaij00,
  author = {Johan Koolwaaij and Loo Boves and Hans Jongebloed and Els Den Os},
  title = {{On model quality and evaluation in speaker verification}},
  booktitle = icassp,
  year = {2000},
  volume = {6},
  pages = {3759--3762},
  organization = {IEEE},
  file = {Koolwaaij00.pdf:Speaker_reco/Data_selection/Koolwaaij00.pdf:PDF}
}

@ARTICLE{Koprinska01,
  author = {Irena Koprinska and Sergio Carrato},
  title = {{Temporal video segmentation: A survey}},
  journal = {Signal Processing: Image Communication},
  year = {2001},
  volume = {16},
  pages = {477--500},
  number = {5},
  abstract = {Temporal video segmentation is the first step towards automatic annotation
	of digital video for browsing and retrieval. This article gives an
	overview of existing techniques for video segmentation that operate
	on both uncompressed and compressed video stream. The performance,
	relative merits and limitations of each of the approaches are comprehensively
	discussed and contrasted. The gradual development of the techniques
	and how the uncompressed domain methods were tailored and applied
	into compressed domain are considered. In addition to the algorithms
	for shot boundaries detection, the related topic of camera operation
	recognition is also reviewed.},
  file = {Koprinska01.pdf:Video/Segmentation/Koprinska01.pdf:PDF},
  keywords = {Temporal video segmentation; Shot boundaries detection; Camera operations;
	Video databases},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2007.10.11}
}

@INPROCEEDINGS{Kshirsagar01,
  author = {Kshirsagar, S. and Magnenat-Thalmann, N.},
  title = {{Viseme space for realistic speech animation}},
  booktitle = avsp,
  year = {2001},
  organization = {ISCA},
  file = {Kshirsagar01.pdf:Video/Segmentation/Viseme/Kshirsagar01.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Kuhn00,
  author = {Roland Kuhn and Jean-Claude Junqua and Patrick Nguyen and Nancy Niedzielski},
  title = {{Rapid speaker adaptation in eigenvoice space}},
  journal = tsap,
  year = {2000},
  volume = {8},
  pages = {695--707},
  number = {6},
  file = {Kuhn00.pdf:Speech_reco/Kuhn00.pdf:PDF},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Kuhn98_2,
  author = {Roland Kuhn and Patrick Nguyen and Jean-Claude Junqua and Lloyd Goldwasser},
  title = {Eigenfaces and Eigenvoices: Dimensionality Reduction for Specialized
	Pattern Recognition},
  booktitle = {IEEE Second Workshop on Multimedia Signal Processing, 1998},
  year = {1998},
  pages = {71-76},
  address = {Victoria (Canada)},
  month = {December},
  abstract = {There are hidden analogies between two dissimilar research areas:
	face recognition and speech recognition. The standard representations
	for faces and voices misleadingly suggest that they have a high number
	of degrees of freedom. However, human faces have two eyes, a nose,
	and a mouth in predictable locations; such constraints ensure that
	possible images of faces occupy a tiny portion of the space of possible
	2D images. Similarly, physical and cultural constraints on acoustic
	realizations of words uttered by a particular speaker imply that
	the true number of degrees of freedom for speaker-dependent hidden
	Markov models (HMMs) is quite small. Face recognition researchers
	have adopted representations that make explicit the underlying low
	dimensionality of the task, greatly improving the performance of
	their systems while reducing computational costs. We argue that speech
	researchers should use similar techniques to represent variation
	between speakers, and discuss applications to speaker adaptation,
	speaker identification and speaker verification},
  doi = {10.1109/MMSP.1998.738915},
  file = {Kuhn98_2.pdf:Speaker_reco/FA/Eigenvoices/Kuhn98_2.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@INPROCEEDINGS{Kuhn98_1,
  author = {Roland Kuhn and Patrick Nguyen and Jean-Claude Junqua and Lloyd Goldwasser
	and Nancy Niedzielski and Steven Fincke and Ken Field and Matteo
	Contolini},
  title = {Eigenvoices for Speaker Adaptation},
  booktitle = icslp,
  year = {1998},
  pages = {1771-1774},
  address = {Sydney (Australia)},
  abstract = {We have devised a new class of fast adaptation techniques for speech
	recognition. These techniques are based on prior knowledge of speaker
	variation, obtained by applying Principal Component Analysis (PCA)
	or a similar technique to T vectors of dimension D derived from T
	speaker-dependent models. This offline step yields T basis vectors
	called ``eigenvoices''. We constrain the model for new speaker S
	to be located in the space spanned by the first K eigenvoices. Speaker
	adaptation involves estimating the K eigenvoice coefficients for
	the new speaker; typically, K is very small compared to D. We conducted
	mean adaptation experiments on the Isolet database. With a large
	amount of supervised adaptation data, most eigenvoice techniques
	performed slightly better than MAP or MLLR; with small amounts of
	supervised adaptation data or for unsupervised adaptation, some eigenvoice
	techniques performed much better. We believe that the eigenvoice
	approach would yield rapid adaptation for most speech recognition
	systems.},
  file = {Kuhn98_1.pdf:Speaker_reco/FA/Eigenvoices/Kuhn98_1.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@INPROCEEDINGS{Kumar07,
  author = {Akshat Kumar and Shivashankar B. Nair},
  title = {{An artificial immune system based approach for English grammar checking}},
  booktitle = {International conference on Artificial immune systems},
  year = {2007},
  pages = {348--357},
  organization = {Springer-Verlag},
  file = {Kumar07.pdf:Artificial_Immune_System/Kumar07.pdf:PDF}
}

@INPROCEEDINGS{Kumar98,
  author = {N. Kumar AND A.G. Andreou},
  title = {{Heteroscedastic Discriminant Analysis and Reduced Rank {{HMM}s}
	for Improved Speech Recognition}},
  booktitle = {Speech Communication},
  year = {1998},
  volume = {26},
  pages = {283-297},
  month = {December},
  abstract = {HLDA}
}

@INPROCEEDINGS{Kumar11,
  author = {Pawan Kumar and Nitika Jakhanwal and Mahesh Chandra},
  title = {{Text Dependent Speaker Identification in Noisy Environment}},
  booktitle = {International Conference on Devices and Communications},
  year = {2011},
  owner = {antho},
  timestamp = {2011.04.14}
}

@ARTICLE{Kwon04,
  author = {Oh-Wook Kwon and Te-Won Lee},
  title = {{Phoneme recognition using ICA-based feature extraction and transformation}},
  journal = {Signal Processing},
  year = {2004},
  volume = {84},
  pages = {1005--1019},
  number = {6},
  file = {Kwon04.pdf:Parametrisation/Kwon04.pdf:PDF},
  publisher = {Elsevier}
}

@PHDTHESIS{Levy_phd,
  author = {Christophe L\'evy},
  title = {Modeles acoustiques compacts pour les systemes embarques},
  school = {Ecole Doctorale Sciences et Agronomie Laboratoire Informatique d'Avignon},
  year = {2006},
  owner = {antho},
  timestamp = {2008.01.18}
}

@INPROCEEDINGS{Levy07,
  author = {Christophe L\'evy and Georges Linares and Jean-Fran{\c c}ois Bonastre},
  title = {Fast Adaptation of GMM-Based compact models},
  booktitle = {Interspeech},
  year = {2007},
  address = {Antwerpen},
  month = {August},
  owner = {antho},
  timestamp = {2007.09.28}
}

@INBOOK{Levy06,
  chapter = {7 in Digital Signal Processing for In-Vehicle and Mobile Systems
	2},
  pages = {71--84},
  title = {Mobile Phone Embedded Digit-Recognition},
  publisher = {Springer Sciences},
  year = {2006},
  author = {Christophe L\'evy and Georges Linares and Pascal Nocera and Jean-Fran{\c
	c}ois Bonastre},
  file = {Levy06.pdf:Systemes_embarques/Levy06.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.28}
}

@ARTICLE{Lades93,
  author = {Martin Lades and Jan C. Vorbruggen and Joachim and Jo\¨e Lange and
	Christoph von der Malsburg and Rolf P. Wurtz and Wolfgang Konen},
  title = {Distortion invariant object recognition in the dynamic linkarchitecture},
  journal = {Computers, IEEE Transactions on},
  year = {1993},
  volume = {42},
  pages = {300--311},
  number = {3},
  file = {Lades93.pdf:Video/Lades93.pdf:PDF}
}

@INPROCEEDINGS{Lafferty01,
  author = {Lafferty, J. and McCallum, A. and Pereira, F.},
  title = {{Conditional random fields: Probabilistic models for segmenting and
	labeling sequence data}},
  booktitle = {Machine learning international workshop},
  year = {2001},
  pages = {282--289}
}

@INPROCEEDINGS{Lampropoulos10,
  author = {Aristomenis S. Lampropoulos and Dionyssios N. Sotiropoulos and George
	A. Tsihrintzis},
  title = {{A Music Recommender Based on Artificial Immune Systems}},
  booktitle = {International Symposium on Intelligent/Interactive/Multimedia Systems
	and Services (KES-IIMSS-10)},
  year = {2010},
  editor = {Springer},
  volume = {6},
  pages = {167--179},
  file = {:/media/517B63F378DF3840/Tex/Biblio/Artificial_Immune_System/Lampropoulos10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.04}
}

@ARTICLE{Lanitis95,
  author = {A. Lanitis and C. J. Taylor and T. F. Cootes},
  title = {Automatic Face Identification System Using Flexible Appearance Models},
  journal = ivc,
  year = {1995},
  volume = {13},
  pages = {393-401},
  number = {5},
  month = {June},
  citeseerurl = {citeseer.ist.psu.edu/article/lanitis95automatic.html},
  file = {Lanitis95.pdf:Video/Face_detection/Lanitis95.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.30}
}

@PHDTHESIS{Larcher_phd,
  author = {Anthony Larcher},
  title = {{Mod\`eles acoustiques \`a structure temporelle renforc\'ee pour
	la v\'erification du locuteur embarqu\'ee.}},
  school = {University of Avignon},
  year = {2009},
  file = {:/home/antho/I2R/Tex/These/Document/these_antho.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.09}
}

@TECHREPORT{Larcher_rapportAV06,
  author = {Anthony Larcher},
  title = {Etat de l'art de la biom\'{e}trie Audio-Vid\'{e}o},
  institution = {Laboratoire d'Informatique d'Avignon (LIA)},
  year = {2006},
  owner = {antho},
  timestamp = {2008.07.01}
}

@MASTERSTHESIS{Larcher05,
  author = {Anthony Larcher},
  title = {{Approche multi-énergies avec un détecteur spectrométrique en radiographie
	appliquée à la reconnaissance de matériaux.}},
  school = {Institut Nationale Polytechnique de Grenoble (INPG)},
  year = {2005},
  file = {:/home/antho/I2R/Tex/Articles/0_Stage_master/larcher_master.pdf:PDF},
  owner = {antho},
  timestamp = {2009.06.03}
}

@INPROCEEDINGS{Larcher_SAC10,
  author = {Anthony Larcher and Jean-Francois Bonastre and John S.D. Mason},
  title = {{Constrained Viterbi decoding for embedded user-customised password
	speaker recognition}},
  booktitle = sac,
  year = {2010},
  pages = {1501--1502},
  file = {:/home/antho/I2R/Tex/Articles/8-SAC_10a/AB-105.pdf:PDF},
  owner = {antho},
  timestamp = {2010.06.29}
}

@INPROCEEDINGS{Larcher_jep08,
  author = {Anthony Larcher and Jean-Francois Bonastre and John S.D. Mason},
  title = {Utilisation de la structure de mots de passe personnalises pour la
	reconnaissance de locuteurs embarquee},
  booktitle = jep,
  year = {2008},
  address = {Avignon (France)},
  month = {june},
  file = {:/home/antho/I2R/Tex/Articles/4-JEP_08/Utilisation de la structure de mots de passe personnalisés pour la reconnaissance de locuteurs embarquée.pdf:PDF},
  owner = {antho},
  timestamp = {2008.07.01}
}

@INPROCEEDINGS{Larcher_eusipco08,
  author = {Anthony Larcher and Jean-Francois Bonastre and John S. D. Mason},
  title = {From GMM to HMM for Embedded Password-Based Speaker Recognition},
  booktitle = eusipco,
  year = {2008},
  address = {Lausanne (Switzerland)},
  month = {august},
  file = {:/home/antho/I2R/Tex/Articles/5-Eusipco_08/From GMM to HMM for Embedded Password-Based Speaker Recognition.pdf:PDF},
  owner = {antho},
  timestamp = {2008.07.01}
}

@INPROCEEDINGS{Larcher_interspeech08,
  author = {Anthony Larcher and Jean-Francois Bonastre and John S. D. Mason},
  title = {{Reinforced temporal structure information for embedded utterance-based
	speaker recognition}},
  booktitle = interspeech,
  year = {2008},
  pages = {371--374},
  file = {:/home/antho/I2R/Tex/Articles/6-Interspeech_08/Reinforced Temporal Structure Information For Embedded Utterance-Based Speaker Recognition.pdf:PDF},
  owner = {antho},
  timestamp = {2008.07.01}
}

@INPROCEEDINGS{Larcher_mmsp08,
  author = {Anthony Larcher and Jean-Francois Bonastre and John S. D. Mason},
  title = {{Short utterance-based video aided speaker recognition}},
  booktitle = mmsp,
  year = {2008},
  pages = {897--901},
  file = {:/home/antho/I2R/Tex/Articles/7-MMSP_08/Short Utterance-based Video Aided Speaker Recognition.pdf:PDF},
  owner = {antho},
  timestamp = {2008.07.01}
}

@INPROCEEDINGS{Larcher12_a,
  author = {Anthony Larcher and Pierre-Michel Bousquet and Kong Aik Lee and Driss
	Matrouf and Haizhou Li and Jean-Francois Bonastre},
  title = {{I-vectors in the context of phonetically-constrained short utterances
	for speaker verification}},
  booktitle = icassp,
  year = {2012},
  file = {:/home/antho/I2R/Tex/Articles/21_ICASSP2012_Text-dependent-IVectors/3649.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.09}
}

@INPROCEEDINGS{Larcher_JEP10,
  author = {Anthony Larcher and Christophe L\'evy and Driss Matrouf and Jean-Francois
	Bonastre},
  title = {{Reconnaissance automatique du locuteur embarqu'ee dans un t\'el\'ephone
	portable}},
  booktitle = {{Proceedings of journees d'\'etudes sur le parole, JEP}},
  year = {2010},
  address = {Mons (Belgium)},
  file = {:/Volumes/Donnees/LIA/SVN/Articles/10_JEP_2010/jep2010.pdf:PDF},
  owner = {antho},
  timestamp = {2010.04.20}
}

@INPROCEEDINGS{Larcher_NIST10,
  author = {Anthony Larcher and Christophe L\'evy and Driss Matrouf and Jean-Francois
	Bonastre},
  title = {{LIA NIST-SRE'10 systems}},
  booktitle = {{NIST Speaker Recognition Evaluation Workshop}},
  year = {2010},
  owner = {antho},
  timestamp = {2010.10.11}
}

@INPROCEEDINGS{Larcher_IS10,
  author = {Anthony Larcher and Christophe L\'{e}vy and Driss Matrouf and Jean-Francois
	Bonastre},
  title = {{Decoupling session variability modelling and speaker characterisation}},
  booktitle = interspeech,
  year = {2010},
  file = {:/home/antho/I2R/Tex/Articles/13_Interspeech_10_ExpandedFA/Decoupling_session_variability_modelling_and_speaker_characterisation.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.08}
}

@TECHREPORT{Larcher_TD1,
  author = {Anthony Larcher and Kong Aik Lee and Bin Ma and Helen Thai},
  title = {{User-Specific Score Normalisation for Text-Dependent Speaker Verification}},
  institution = {Institute for Infocomm Research (I2R)},
  year = {2011},
  type = {Technologie Disclosure form},
  number = {1},
  month = {August},
  file = {:/home/antho/I2R/Tex/Articles/22_TD_User_specific_score_normalization_TD2011069/TD_Text-dependent_normalisation_v6.pdf:PDF},
  owner = {antho},
  timestamp = {2011.08.08}
}

@INPROCEEDINGS{Larnel91,
  author = {Larnel, L.F. and Gauvain, J.L. and Eskenazi, M.},
  title = {{BREF, a Large Vocabulary Spoken Corpus for French}},
  booktitle = eurospeech,
  year = {1991},
  organization = {ISCA},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Law04,
  author = {Martin H. C. Law and Mario A. T. Figueiredo and Anil K. Jain},
  title = {{Simultaneous feature selection and clustering using mixture models}},
  journal = pami,
  year = {2004},
  volume = {26},
  pages = {1154--1166},
  number = {9},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Lawson11,
  author = {A. Lawson and P. Vabishchevich and M. Huggins and Ardis and B. Battles
	and A. Stauffer},
  title = {{Survey and evaluation of acoustic features for speaker recognition}},
  booktitle = icassp,
  year = {2011},
  file = {Lawson11.pdf:Parametrisation/Lawson11.pdf:PDF},
  owner = {antho},
  timestamp = {2012.01.27}
}

@INPROCEEDINGS{Laxman03,
  author = {Srivatsan Laxman and P.S. Sastry},
  title = {Text-dependent speaker recognition using speaker specific compensation},
  booktitle = {Conference on Convergent Technologies for Asia-Pacific Region, TENCON},
  year = {2003},
  volume = {1},
  pages = {384-387},
  address = {Bangalore (India)},
  month = {October},
  abstract = {This paper proposes a new method for text-dependent speaker recognition.
	The scheme is based on learning (what we refer to as) speaker-specific
	compensators for each speaker in the system. The compensator is essentially
	a speaker to speaker transformation which enables the recognition
	of the speech of one speaker through a speaker-dependent speech recognition
	system built for the other. Such a transformation, adequate for our
	purposes, may be achieved by a simple vector addition in the cepstral
	domain. This speaker-specific compensator captures the characteristics
	of the speaker we wish to recognize. For each speaker who is registered
	into the system, we learn a unique set of compensators. The speaker
	recognition decision is then based on which compensator achieves
	best speech recognition scores.},
  file = {Laxman03.pdf:Speaker_reco/Text_dependent/Laxman03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@INPROCEEDINGS{Lee09,
  author = {Akinobu Lee and Tatsuya Kawahara},
  title = {{Recent development of open-source speech recognition engine Julius}},
  booktitle = {{Asia-Pacific Signal and Information Processing Association Annual
	Summit and Conference}},
  year = {2009},
  file = {Lee09.pdf:Speech_reco/Lee09.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.31}
}

@ARTICLE{Lee06,
  author = {Lee, Heungkyu and Ko, Hanseok},
  title = {Competing models-based text-prompted speaker independent verification
	algorithm},
  journal = {Speech Communication},
  year = {2006},
  volume = {48},
  pages = {28--44},
  number = {1},
  owner = {larcher},
  publisher = {Elsevier},
  timestamp = {2007.07.30}
}

@INPROCEEDINGS{Lee00,
  author = {Jay J. Lee and Jahwan Kim and Jin H. Kim},
  title = {Data-driven design of hmm topology for on-line handwriting recognition},
  booktitle = {Workshop on Frontiers in Handwriting Recognition},
  year = {2000},
  citeseerurl = {http://citeseer.ist.psu.edu/lee00datadriven.html},
  file = {Lee00.pdf:Divers/Writting_reco/Lee00.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.04.02}
}

@ARTICLE{Lee89,
  author = {Lee, K.F.},
  title = {{Large-vocabulary speaker-independent continuous speech recognition:
	The SPHINX system.}},
  journal = {Dissertation Abstracts International Part B: Science and Engineering},
  year = {1989},
  volume = {49},
  number = {10},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Lee11_b,
  author = {Kong Aik Lee and Anthony Larcher and Helen Thai and Bin Ma and Haizhou
	Li},
  title = {{Joint Application of Speech and Speaker Recognition for Automation
	and Security in Smart Home}},
  booktitle = interspeech,
  year = {2011},
  file = {:/home/antho/I2R/Tex/Articles/18_Show-and-Tell_IS11/Lee11_b.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.09}
}

@INPROCEEDINGS{Lee11_a,
  author = {Kong Aik Lee and Chang Huai You and Ville Hautomaki and Anthony Larcher
	and Haizhou Li},
  title = {{Spoken Language Recognition in the Latent Topic Simplex}},
  booktitle = interspeech,
  year = {2011},
  file = {:/home/antho/I2R/Tex/Articles/19_LDA_IS11/Lee11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.09}
}

@ARTICLE{Lee10,
  author = {Kong Aik Lee and Chang Huai You and Haizhou Li and Tommi Kinnunen
	and Khe Chai Sim},
  title = {{Using Discrete Probabilities with Bhattacharyya Measure for SVM-based
	Speaker Verification}},
  journal = taslp,
  year = {2010},
  pages = {1--10},
  number = {99},
  file = {Lee10.pdf:Speaker_reco/SVM/Lee10.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Lee05,
  author = {Khuang-Chih Lee and Jeffrey Ho. Ming-Hsuan Yang and David Kriegman},
  title = {Visual tracking and recognition using probabilistic appearance manifolds},
  journal = {Computer Vision and Image Understanding},
  year = {2005},
  volume = {99},
  pages = {303-331},
  number = {3},
  month = {september},
  doi = {10.1016/j.cviu.2005.02.002},
  file = {Lee05.pdf:Video/Lee05.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.19}
}

@INPROCEEDINGS{VanLeeuwen09,
  author = {David van Leeuwen and Javier Gonzalez-Dominguez},
  title = {{The TNO system for LRE-2009}},
  booktitle = NIST # Language # Recognition # Evaluation,
  year = {2009},
  file = {VanLeeuwen09.pdf:Language_reco/VanLeeuwen09.pdf:PDF},
  owner = {antho},
  timestamp = {2011.04.20}
}

@ARTICLE{Van07,
  author = {David Van Leeuwen and Niko Br{\\"u}mmer},
  title = {{An introduction to application-independent evaluation of speaker
	recognition systems}},
  journal = {Speaker Classification I},
  year = {2007},
  volume = {1},
  pages = {330--353},
  file = {Van07.pdf:Calibration/Van07.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Leggetter95,
  author = {Chris J. Leggetter and Phil C. Woodland},
  title = {Maximum likelihood linear regression for speaker adaptation of continuous
	density hidden markov models},
  journal = csl,
  year = {1995},
  volume = {9},
  pages = {171-185},
  number = {2},
  month = {April},
  abstract = {A method of speaker adaptation for continuous density hidden Markov
	models (HMMs) is presented. An initial speaker-independent system
	is adapted to improve the modelling of a new speaker by updating
	the HMM parameters. Statistics are gathered from the available adaptation
	data and used to calculate a linear regression-based transformation
	for the mean vectors. The transformation matrices are calculated
	to maximize the likelihood of the adaptation data and can be implemented
	using the forward-backward algorithm. By tying the transformations
	among a number of distributions, adaptation can be performed for
	distributions which are not represented in the training data. An
	important feature of the method is that arbitrary adaptation data
	can be used no special enrolment sentences are needed.
	
	Experiments have been performed on the ARPA RM1 database using an
	HMM system with cross-word triphones and mixture Gaussian output
	distributions. Results show that adaptation can be performed using
	as little as 11 s of adaptation data, and that as more data is used
	the adaptation performance improves. For example, using 40 adaptation
	utterances, a 37% reduction in error from the speaker-independent
	system was achieved with supervised adaptation and a 32% reduction
	in unsupervised mode.},
  doi = {10.1006/csla.1995.0010},
  file = {Leggetter95.pdf:Speaker_reco/Adaptation/MLLR/Leggetter95.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Lehr10,
  author = {Maider Lehr and Izhak Shafran},
  title = {{Discriminatively estimated joint acoustic, duration, and language
	model for speech recognition}},
  booktitle = icassp,
  year = {2010},
  pages = {5542--5545},
  organization = {IEEE},
  file = {Lehr10.pdf:Speech_reco/Lehr10.pdf:PDF},
  issn = {1520-6149}
}

@ARTICLE{Lei11_b,
  author = {Yun Lei and John H.L. Hansen},
  title = {{Mismatch modeling and compensation for robust speaker verification}},
  journal = {Speech Communication},
  year = {2011},
  volume = {53},
  pages = {257--268},
  number = {2},
  file = {Lei11_b.pdf:Speaker_reco/FA/Lei11_b.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Lei11,
  author = {Zhenchun Lei and Yingchun Yang},
  title = {{Maximum Likelihood i-vector Space Using PCA for Speaker Verification}},
  booktitle = interspeech,
  year = {2011},
  pages = {2725--2728},
  file = {Lei11.PDF:Speaker_reco/FA/Lei11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.10}
}

@INPROCEEDINGS{Leung09,
  author = {Cheung-Chi Leung and Rong Tong and Bin Ma and Haizhou Li},
  title = {{A Lattice-Based Phonotactic Language Recognition System with CMLLR
	Adaptation and Its Implementation Issues}},
  booktitle = {2009 International Conference on Asian Language Processing},
  year = {2009},
  pages = {285--288},
  organization = {IEEE},
  file = {Leung09.pdf:Language_reco/Leung09.pdf:PDF}
}

@ARTICLE{Leung07,
  author = {Kevin Leung and France Cheong and Christopher Cheong},
  title = {{Generating compact classifier systems using a simple artificial
	immune system}},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  year = {2007},
  volume = {37},
  pages = {1344--1356},
  number = {5},
  file = {Leung07.pdf:Artificial_Immune_System/Leung07.pdf:PDF}
}

@INPROCEEDINGS{Leung95,
  author = {T. K. Leung and M.C. Burl and P. Perona},
  title = {Finding faces in cluttered scenes using random labeled graph matching},
  booktitle = cv,
  year = {1995},
  pages = {678-384},
  address = {Cambridge (UK)},
  month = {June},
  abstract = {An algorithm for locating quasi-frontal views of human faces in cluttered
	scenes is presented. The algorithm works by coupling a set of local
	feature detectors with a statistical model of the mutual distances
	between facial features it is invariant with respect to translation,
	rotation (in the plane), and scale and can handle partial occlusions
	of the face. On a challenging database with complicated and varied
	backgrounds, the algorithm achieved a correct localization rate of
	95% in images where the face appeared quasi-frontally},
  doi = {10.1109/ICCV.1995.466878},
  file = {Leung95.pdf:Video/Face_detection/Leung95.pdf:PDF},
  keywords = {computer vision face recognition feature extraction graph theory image
	matching image recognition random processes},
  owner = {larcher},
  timestamp = {2006.05.29}
}

@ARTICLE{Li02,
  author = {Baoxin Li and Rama Chellappa},
  title = {A generic approach to simultaneous tracking and verification in video},
  journal = tip,
  year = {2002},
  volume = {11},
  pages = {530-544},
  abstract = {A generic approach to simultaneous tracking and verification in video
	data is presented. The approach is based on posterior density estimation
	using sequential Monte Carlo methods. Visual tracking, which is in
	essence a temporal correspondence problem, is solved through probability
	density propagation, with the density being defined over a proper
	state space characterizing the object configuration. Verification
	is realized through hypothesis testing using the estimated posterior
	density. In its most basic form, verification can be performed as
	follows. Given a measurement vector Z and two hypotheses H/sub 1/
	and H0, we first estimate posterior probabilities P(H/sub 0/|Z) and
	P(H/sub 1/|Z), and then choose the one with the larger posterior
	probability as the true hypothesis. Several applications of the approach
	are illustrated by experiments devised to evaluate its performance.
	The idea is first tested on synthetic data, and then experiments
	with real video sequences are presented, illustrating vehicle tracking
	and verification, human (face) tracking and verification, facial
	feature tracking, and image sequence stabilization.},
  doi = {10.1109/TIP.2002.1006400},
  file = {Li02.pdf:Video/Face_tracking/Li02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.19}
}

@INPROCEEDINGS{Li00,
  author = {Baoxin Li and R. Chellappa},
  title = {Simultaneous tracking and verification via sequential posterior estimation},
  booktitle = cvpr,
  year = {2000},
  volume = {2},
  pages = {110-117},
  address = {Hilton Head Island (USA)},
  abstract = {An approach to simultaneous tracking and verification in video data
	is presented. The approach is based on posterior estimation using
	sequential Monte Carlo methods. Visual tracking, which is in essence
	a temporal correspondence problem, is solved through probability
	density propagation, with the density being defined over a proper
	state space characterizing the object configuration. Verification
	is realized through hypothesis testing using the estimated posterior
	density. In its most basic form, verification can be performed as
	follows. Given measurement Z and two hypothesis H1 and H0, we first
	estimate posterior probabilities P(H0|Z) and P(H1 |Z); and choose
	the one with the larger posterior probability as the true hypothesis.
	Applications of the approach are illustrated with experiments devised
	to evaluated the performance. The idea is first tested on synthetic
	data, and then experiments with real video sequences are presented},
  doi = {10.1109/CVPR.2000.854755},
  file = {Li00.pdf:Video/Face_tracking/Li00.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@ARTICLE{Li01_1,
  author = {Baoxin Li and Rama Chellappa and Zheng Qinfen and S.Z. Der},
  title = {Model-based temporal object verification using video},
  journal = {IEEE Transactions on Image Processing},
  year = {2001},
  volume = {10},
  pages = {897-908},
  abstract = {An approach to model-based dynamic object verification and identification
	using video is proposed. From image sequences containing the moving
	object, we compute its motion trajectory. Then we estimate its three-dimensional
	(3-D) pose at each time step. Pose estimation is formulated as a
	search problem, with the search space constrained by the motion trajectory
	information of the moving object and assumptions about the scene
	structure. A generalized Hausdorff (1962) metric, which is more robust
	to noise and allows a confidence interpretation, is suggested for
	the matching procedure used for pose estimation as well as the identification
	and verification problem. The pose evolution curves are used to assist
	in the acceptance or rejection of an object hypothesis. The models
	are acquired from real image sequences of the objects. Edge maps
	are extracted and used for matching. Results are presented for both
	infrared and optical sequences containing moving objects involved
	in complex motions},
  doi = {10.1109/83.923286},
  file = {Li01_1.pdf:Video/Li01_1.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.19}
}

@INPROCEEDINGS{Li03,
  author = {Bo Li and WenJu Liu and QiuHai Zhong},
  title = {Text-dependent speaker identification using Fisher differentiation
	vector},
  booktitle = {International Conference on Natural Language Processing and Knowledge
	Engineering},
  year = {2003},
  pages = {309-314},
  address = {Beijing (China)},
  abstract = {We put forward a new algorithm for speaker identification. The difficulties
	for speaker recognition were first analyzed. Because most methods
	for speaker identification are based on parameter estimation, we
	put forward a nonparameter method for speaker identification. The
	method is based on Fisher differentiation vector. The influences
	of different factors to the identification accuracy were analyzed.
	The experiment shows that it is an effective method for text-dependent
	speaker identification.},
  doi = {10.1109/NLPKE.2003.1275920},
  file = {Li03.pdf:Speaker_reco/Text_dependent/Li03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@ARTICLE{Li08,
  author = {Haizhou Li and Jin Shea Kuo and Jian Su and Chih Lung LIN},
  title = {{Mining live transliterations using incremental learning algorithms}},
  journal = {International Journal of Computer Processing Of Languages},
  year = {2008},
  volume = {21},
  pages = {183--203},
  number = {2},
  file = {Li08.pdf:Spoken_Document_Retrieval/Li08.pdf:PDF}
}

@INPROCEEDINGS{Li05,
  author = {Haizhou Li and Bin Ma},
  title = {{A phonotactic language model for spoken language identification}},
  booktitle = {Annual Meeting on Association for Computational Linguistics},
  year = {2005},
  pages = {515--522},
  organization = {Association for Computational Linguistics},
  file = {Li05.pdf:Language_reco/Li05.pdf:PDF}
}

@ARTICLE{Li07,
  author = {Haizhou Li and Bin Ma and Chin-Hui Lee},
  title = {{A vector space modeling approach to spoken language identification}},
  journal = {IEEE Transactions on Audio, Speech and Language Processing},
  year = {2007},
  volume = {15},
  pages = {271--284},
  number = {1},
  file = {Li07.pdf:Language_reco/Li07.pdf:PDF},
  issn = {1558-7916},
  publisher = {Institute of Electrical and Electronics Engineers, Inc, 3 Park Avenue,
	17 th Fl New York NY 10016-5997 USA}
}

@INPROCEEDINGS{Li09,
  author = {Haizhou Li and Bin Ma and Kong-Aik Lee and Hanwu Sun and Donglai
	Zhu and Khe Chai Sim and Changhuai You and Rong Tong and Ismo Kärkkäinen
	and Chien-Lin Huang and Vladimir Pervouchine1 and Wu Guo and Yijie
	Li and Lirong Dai and Mohaddeseh Nosratighods and Thiruvaran Tharmarajah
	and Julien Epps and Eliathamby Ambikairajah and Eng-Siong Chng and
	Tanja Schultz and Qin Jin},
  title = {{The I4U system in NIST 2008 speaker recognition evaluation}},
  booktitle = {Proceedings of the 2009 IEEE International Conference on Acoustics,
	Speech and Signal Processing-Volume 00},
  year = {2009},
  pages = {4201--4204},
  organization = {IEEE Computer Society},
  file = {Li09.pdf:Speaker_reco/Divers/Li09.pdf:PDF}
}

@INPROCEEDINGS{Li88,
  author = {Kung-Pu Li and Jack E. Porter},
  title = {Normalizations and selection of speech segments for speaker recognition
	scoring},
  booktitle = icassp,
  year = {1998},
  volume = {1},
  pages = {595-598},
  address = {New York (USA)},
  month = {April},
  abstract = {Normalization and selection techniques are described which improve
	speaker recognition accuracy using very short uncontrolled speech
	samples. The first normalization depends on the means and variances
	of scores for a short, unknown sample matched to different models
	for many speakers. The selection procedure discards portions of a
	speech sample with poor speaker-discrimination ability. A second
	normalization is based on the range of matching scores of the supposed
	speaker's model against other speaker's models. It facilitates setting
	acceptance thresholds for speaker verification against an open population},
  doi = {10.1109/ICASSP.1988.196655},
  file = {Li88.pdf:Speaker_reco/Normalisation/Li88.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@ARTICLE{Li12,
  author = {Peng Li and Yun Fu and Umar Mohammed and James H. Elder and Simon
	J.D. Prince},
  title = {{Probabilistic models for inference about identity}},
  journal = pami,
  year = {2012},
  pages = {1--1},
  number = {99},
  file = {:Outils/PLDA/Li12_appendix.pdf:PDF;Li12.pdf:Outils/PLDA/Li12.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Li01_2,
  author = {Yongmin Li and Shaogang Gong and H. Liddell},
  title = {Constructing facial identity surfaces in a nonlinear discriminating
	space},
  booktitle = cvpr,
  year = {2001},
  volume = {2},
  pages = {258-263},
  address = {Hawa\"i},
  abstract = {Recognising face with large pose variation is more challenging than
	that in a fixed view, e.g. frontal-view, due to the severe non-linearity
	caused by rotation in depth, self-shading and self-occlusion. To
	address this problem, a multi-view dynamic face model is designed
	to extract the shape-and-pose-free facial texture patterns from multi-view
	face images. Kernel Discriminant Analysis is developed to extract
	the significant non-linear discriminating features which maximise
	the between-class variance and minimise the within-class variance.
	By using the kernel technique, this process is equivalent to a Linear
	Discriminant Analysis in a high-dimensional feature space which can
	be solved conveniently. The identity surfaces are then constructed
	from these non-linear discriminating features. Face recognition can
	be performed dynamically from an image sequence by matching an object
	trajectory and model trajectories on the identity surfaces.},
  citeseerurl = {http://citeseer.ist.psu.edu/633846.html},
  doi = {10.1109/CVPR.2001.990969},
  file = {Li01_2.pdf:Video/Li01_2.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.04}
}

@INPROCEEDINGS{Li09_b,
  author = {Zhifei Li and Chris Callison-Burch and Chris Dyer and Juri Ganitkevitch
	and Sanjeev Khudanpur and Lane Schwartz and Wren N. G. Thornton and
	Jonathan Weese and Omar F. Zaidan},
  title = {{Joshua: An open source toolkit for parsing-based machine translation}},
  booktitle = {Workshop on Statistical Machine Translation},
  year = {2009},
  pages = {135--139},
  publisher = {Citeseer},
  file = {Li09_b.pdf:Machine_Translation/Li09_b.pdf:PDF}
}

@INPROCEEDINGS{Lievin98,
  author = {Marc Lievin and Franck Luthon},
  title = {{Lip Features Automatic Extraction}},
  booktitle = icip,
  year = {1998},
  volume = {3},
  pages = {168-172},
  address = {Chicago (USA)},
  abstract = {An algorithm for speaker's lip segmentation and features extraction
	is presented. A color video sequence of speaker's face is acquired,
	under natural lighting conditions and without any particular make-up.
	First, a logarithmic color transform is performed from the RGB to
	HI (hue, intensity) color space. Second, a statistical approach using
	Markov random field modeling determines the red hue prevailing region
	and motion in a spatiotemporal neighborhood. Third, the final label
	field is used to extract ROI (region of interest) and geometrical
	features},
  citeseerurl = {http://citeseer.ist.psu.edu/lievin98lip.html},
  doi = {10.1109/ICIP.1998.727160},
  file = {Lievin98.pdf:Video/Lip_reading/Lievin98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Lin08,
  author = {Hui Lin and Jeff Bilmes and Dimitra Vergyri and Katrin Kirchhoff},
  title = {{OOV detection by joint word/phone lattice alignment}},
  booktitle = asru,
  year = {2008},
  pages = {478--483},
  organization = {IEEE},
  file = {Lin08.pdf:Speech_reco/Lin08.pdf:PDF}
}

@INPROCEEDINGS{Linares07,
  author = {Georges Linar\`es and Christophe L\'evy},
  title = {{Fast discriminative training of semi-continuous HMM}},
  booktitle = {International Conference of Text, Speech and Dialogue` (TSD)},
  year = {2007},
  owner = {antho},
  timestamp = {2008.10.26}
}

@INPROCEEDINGS{Lindh09,
  author = {Jonas Lindh},
  title = {{A first step towards a text-independent speaker verification Praat
	plug-in using Mistral/Alize tools}},
  booktitle = {The XXIInd Swedish Phonetics Conference},
  year = {2009},
  pages = {194--197},
  address = {Department of Linguistics, Stockholm University}
}

@INPROCEEDINGS{Liou95,
  author = {Han Sheng Liou and Richard J. Mammone},
  title = {{A subword neural tree network approach to text-dependent speaker
	verification}},
  booktitle = icassp,
  year = {1995},
  volume = {1},
  pages = {357--357},
  organization = {INSTITUTE OF ELECTRICAL ENGINEERS INC (IEE)},
  file = {Liou95.pdf:Speaker_reco/Text_dependent/Liou95.pdf:PDF}
}

@INPROCEEDINGS{Liu99_b,
  author = {Chengjun Liu and Harry Wechsler},
  title = {{Comparative assessment of independent component analysis (ICA) for
	face recognition}},
  booktitle = avbpa,
  year = {1999},
  organization = {Citeseer},
  file = {Liu99_b.pdf:Image/EigenSpace/Liu99_b.pdf:PDF}
}

@INPROCEEDINGS{Liu99,
  author = {Li Liu and Jialong He},
  title = {On the Use of Orthogonal GMM in Speaker recognition},
  booktitle = icassp,
  year = {1999},
  volume = {2},
  pages = {845-848},
  address = {Phoenix (USA)},
  publisher = {Institute of Electrical Engineers Inc.},
  abstract = {The Gaussian mixture modeling (GMM) techniques are increasingly being
	used for both speaker identification and verification. Most of these
	models assume diagonal covariance matrices. Although empirically
	any distribution can be approximated with a diagonal GMM, a large
	number of mixture components are usually needed to obtain a good
	approximation. A consequence of using a large GMM is that its training
	is time consuming and its response speed is very slow. This paper
	proposes a modification to the standard diagonal GMM approach. The
	proposed scheme includes an orthogonal transformation: feature vectors
	are first transformed to the space spanned by the eigenvectors of
	the covariance matrix before applying to the diagonal GMM. Only a
	small computational load is introduced by this transformation, but
	results from both speaker identification and verification experiments
	indicated that the orthogonal transformation considerably improves
	the recognition performance. For a specific performance level, the
	GMM with orthogonal transform needs only one-fourth the number of
	Gaussian functions required by the standard GMM},
  doi = {10.1109/ICASSP.1999.759803},
  file = {Liu99.pdf:Speaker_reco/GMM-UBM/Liu99.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Liu08,
  author = {Wei Ming Liu and Keith A. Jellyman and Nicholas W.D. Evans and John
	S.D. Mason},
  title = {Assessment of Objective Quality Measures for Speech Intelligibility},
  booktitle = interspeech,
  year = {2008},
  volume = {1},
  file = {:/Volumes/Donnees/LIA/biblio/Divers/Speech_quality/Liu08.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Liu03,
  author = {Xiaoming Liu and Tsuhan Chen},
  title = {{Video-Based Face Recognition Using Adaptive Hidden Markov Models}},
  booktitle = cvpr,
  year = {2003},
  volume = {1},
  pages = {340-345},
  address = {Madison (USA)},
  month = {june},
  abstract = {While traditional face recognition is typically based on still images,
	face recognition from video sequences has become popular. In this
	paper, we propose to use adaptive hidden Markov models (HMM) to perform
	video-based face recognition. During the training process, the statistics
	of training video sequences of each subject, and the temporal dynamics,
	are learned by an HMM. During the recognition process, the temporal
	characteristics of the test video sequence are analyzed over time
	by the HMM corresponding to each subject. The likelihood scores provided
	by the HMMs are compared, and the highest score provides the identity
	of the test video sequence. Furthermore, with unsupervised learning,
	each HMM is adapted with the test video sequence, which results in
	better modeling over time. Based on extensive experiments with various
	databases, we show that the proposed algorithm results in better
	performance than using majority voting of image-based recognition
	results.},
  doi = {10.1109/CVPR.2003.1211373},
  file = {Liu03.pdf:Video/Liu03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.24}
}

@INPROCEEDINGS{Liu06,
  author = {Ying Liu and Martin Russell and Michael Carey},
  title = {{The role of dynamic features in text-dependent and independent speaker
	verification}},
  booktitle = icassp,
  year = {2006},
  file = {Liu06.pdf:Speaker_reco/Text_dependent/Liu06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.17}
}

@INPROCEEDINGS{Long09,
  author = {Yanhua Long and Wu Guo and Bin Ma and Eng Siong Chng and Donglai
	Zhu and Lirong Dai and Haizhou Li},
  title = {{Subspace construction and selection for speaker recognition}},
  booktitle = {International Conference on Information, Communications and Signal
	Processing},
  year = {2009},
  pages = {1--4},
  organization = {IEEE},
  file = {Long09.pdf:Speaker_reco/Divers/Long09.pdf:PDF}
}

@PHDTHESIS{Louradour07,
  author = {J\'er{\^o}me Louradour},
  title = {{Noyaux de s\'{e}quences pour la v\'{e}rification du locuteur par
	Machines {\`a} Vecteurs de Support}},
  school = {Universit\'{e} Toulouse III - Paul Sabatier},
  year = {2007},
  owner = {antho},
  timestamp = {2009.04.14}
}

@INPROCEEDINGS{Louradour05,
  author = {Louradour, J. and Daoudi, K.},
  title = {{SVM speaker verification using a new sequence kernel}},
  booktitle = eusipco,
  year = {2005},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Louradour07_b,
  author = {Jerome Louradour and Khalid Daoudi and Francis Bach},
  title = {{Feature space mahalanobis sequence kernels: Application to svm speaker
	verification}},
  journal = taslp,
  year = {2007},
  volume = {15},
  pages = {2465--2475},
  number = {8},
  file = {Louradour07_b.pdf:Speaker_reco/SVM/Louradour07_b.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Lu08,
  author = {Haoze Lu and Haruka Okamoto and Masafumi Nishida and Yasuo Horiuchi
	and and Shingo Kuroiwa},
  title = {{Text-independent speaker identification based on feature transformation
	to phoneme-independent subspace}},
  booktitle = icct,
  year = {2008},
  pages = {692--695},
  doi = {10.1109/ICCT.2008.4716204},
  file = {Lu08.pdf:Speaker_reco/Text_dependent/Lu08.pdf:PDF}
}

@INPROCEEDINGS{Luan06,
  author = {Luan, J. and Hao, J. and Kakino, T. and Ikumi, T.},
  title = {{Template Compression and Distance Normalization for Reliable Text-dependent
	Speaker Verification}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--4},
  organization = {IEEE},
  file = {Luan06.pdf:Speaker_reco/Text_dependent/Luan06.pdf:PDF}
}

@INPROCEEDINGS{Lucey05,
  author = {Patrick Lucey and David Dean and Sridha Sridharan},
  title = {Problems Associated With Current Area-Based Visual Speech Feature
	Extraction Techniques},
  booktitle = avsp,
  year = {2005},
  address = {British Columbia, Canada.},
  file = {Lucey05.pdf:Video/Lucey05.pdf:PDF},
  owner = {antho},
  timestamp = {2008.10.24}
}

@INPROCEEDINGS{Lucey07,
  author = {Patrick Lucey and Gerasimos Potamianos and Sridha Sridharan},
  title = {A Unified Approach to Multi-Pose Audio-Visual ASR},
  booktitle = interspeech,
  year = {2007},
  journal = {Proc. Interspeech, 2007},
  owner = {antho},
  timestamp = {2009.10.05}
}

@PHDTHESIS{Lucey02,
  author = {Simon Lucey},
  title = {Audio-visual Speech Processing},
  school = {Queensland University of Technology},
  year = {2002},
  file = {Lucey02.pdf:Audio-Video/Lucey02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.18}
}

@INPROCEEDINGS{Lucey03,
  author = {Simon Lucey and Tsuhan Chen},
  title = {Improved audio visual speaker recognition via the use of a hybrid
	combination strategy},
  booktitle = avbpa,
  year = {2003},
  pages = {929-936},
  address = {Guildford (UK)},
  abstract = {In this paper an in depth analysis is undertaken into effective strategies
	for integrating the audio-visual
	
	modalities for the purposes of text dependent speaker recognition.
	Our work is based around the well 
	
	known hidden Markov model (HMM) classifier framework for modelling
	speech. A framework is proposed 
	
	to handle the mismatch between train and test observation sets, so
	as to provide effective classifier 
	
	combination performance between the acoustic and visual HMM classifiers.
	From this framework, it can 
	
	be shown that strategies for combining independent classifiers, such
	as the weighted product or sum
	
	rules, naturally emerge depending on the influence of the mismatch.Based
	on the assumption that poor 
	
	performance in most audio visual speaker recognition applications
	can be attributed to train test
	
	mismatches we propose that the main impetus of practical audio-visual
	integration is to dampen 
	
	the independent errors, resulting from the mismatch, rather than trying
	to model any bimodal speech
	
	dependencies. To this end a strategy is recommended, based on theory
	and empirical evidence, using 
	
	a hybrid between the weighted product and weighted sum rules in the
	presence of varyingacoustic noise. 
	
	Results are presented on the M2VTS database.},
  file = {Lucey03.pdf:Audio-Video/Lucey03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.20}
}

@ARTICLE{Lucey04,
  author = {Simon Lucey and Tsuhan Chen and Sridha Sridharan and Vinod Chandran},
  title = {Integration strategies for audio-visual speech processing: Applied
	to text dependent speaker recognition},
  journal = tm,
  year = {2004},
  volume = {7},
  pages = {495-506},
  number = {3},
  month = {june},
  abstract = {In this paper, an in-depth analysis is undertaken into effective strategies
	for integrating the audio-visual speech modalities with respect to
	two major questions. Firstly, at what level should integration occur?
	Secondly, given a level of integration how should this integration
	be implemented? Our work is based around the well-known hidden Markov
	model (HMM) classifier framework for modeling speech. A novel framework
	for modeling the mismatch between train and test observation sets
	is proposed, so as to provide effective classifier combination performance
	between the acoustic and visual HMM classifiers. From this framework,
	it can be shown that strategies for combining independent classifiers,
	such as the weighted product or sum rules, naturally emerge depending
	on the influence of the mismatch. Based on the assumption that poor
	performance in most audio-visual speech processing applications can
	be attributed to train/test mismatches we propose that the main impetus
	of practical audio-visual integration is to dampen the independent
	errors, resulting from the mismatch, rather than trying to model
	any bimodal speech dependencies. To this end a strategy is recommended,
	based on theory and empirical evidence, using a hybrid between the
	weighted product and weighted sum rules in the presence of varying
	acoustic noise for the task of text-dependent speaker recognition.},
  doi = {10.1109/TMM.2005.846777},
  file = {Lucey04.pdf:Audio-Video/Lucey04.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.20}
}

@PHDTHESIS{Luettin97,
  author = {Juergen Luettin},
  title = {Visual Speech and Speaker Recognition},
  school = {Department of Computer Science University of Sheffield},
  year = {1997},
  file = {Luettin97.pdf:Audio-Video/Luettin97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.18}
}

@ARTICLE{Luettin97_1,
  author = {Juergen Luettin and Neil A. Thacker},
  title = {Speechreading using Probabilistic Models},
  journal = {Computer Vision and Image Understanding},
  year = {1997},
  volume = {65},
  pages = {163-178},
  number = {2},
  month = {February},
  file = {Luettin97_1.pdf:Video/Face_tracking/Luettin97_1.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.06.08}
}

@INPROCEEDINGS{Luettin96,
  author = {J\"urgen Luettin and Neil A. Thacker and Steve W. Beet},
  title = {Speaker Identification By Lipreading},
  booktitle = icslp,
  year = {1996},
  volume = {1},
  pages = {62-65},
  address = {Philadelphia (USA)},
  abstract = {This paper describes a new approach for speaker identification based
	on lipreading. Visual features are extracted from image sequences
	of the talking face and consist of shape parameters which describe
	the lip boundary and intensity parameters which describe the grey-level
	distribution of the mouth area. Intensity information is based on
	principal component analysis using eigenspaces which deform with
	the shape model. The extracted parameters account for both, speech
	dependent and speaker dependent information. We built spatio-temporal
	speaker models based on these features, using HMMs with mixtures
	of Gaussians. Promising results were obtained for text dependent
	and text independent speaker identification tests performed on a
	small video database},
  citeseerurl = {http://citeseer.ist.psu.edu/85712.html},
  doi = {10.1109/ICSLP.1996.607030},
  file = {Luettin96.pdf:Video/Lip_reading/Luettin96.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Luo10,
  author = {Canhua Luo and Xiaojun Wu and Thomas Fang Zheng and Linlin Wang},
  title = {{Segmentation-based method for text-dependent speaker recognition
	in embedded applications}},
  booktitle = apsipa,
  year = {2010},
  owner = {antho},
  timestamp = {2010.12.16}
}

@ARTICLE{Lyngso01,
  author = {Rune B. Lyngso and Christian N.S. Pedersen},
  title = {{Complexity of comparing hidden Markov models}},
  journal = {Algorithms and Computation},
  year = {2001},
  volume = {1},
  pages = {416--428},
  file = {Lyngso01.pdf:Speech_reco/Lyngso01.pdf:PDF},
  publisher = {Springer}
}

@INPROCEEDINGS{Lyngso99,
  author = {Rune B. Lyngso and Christian N.S. Pedersen and Henrik Nielsen},
  title = {{Metrics and similarity measures for hidden Markov models}},
  booktitle = {{International Conference on Intelligent Systems for Molecular Biology
	(ISMB)}},
  year = {1999},
  pages = {178--186},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Machlica09,
  author = {Lukas Machlica and Znynek Zaj{\i}c, Z. and Praz{\'a}k, A.},
  title = {{Methods of unsupervised adaptation in online speech recognition}},
  booktitle = specom,
  year = {2009},
  journal = {Specom, St. Petersburg}
}

@INPROCEEDINGS{Macskassy04,
  author = {S. Macskassy and F. Provost},
  title = {{Confidence bands for ROC curves: Methods and an empirical study}},
  booktitle = {Workshop on ROC Analysis in A.I.},
  year = {2004},
  organization = {Proceedings of the First Workshop on ROC Analysis in AI. August 2004.}
}

@BOOK{Mahalanobis36,
  title = {On the generalized distance in statistics},
  year = {1936},
  author = {Prasanta Chandra Mahalanobis},
  volume = {2},
  pages = {49--55},
  booktitle = {Proc. Nat. Inst. Sci. India},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Maison99,
  author = {Maison, B. and Neti, C. and Senior, A. and Center, I.B.M.T.J.W.R.
	and Heights, Y.},
  title = {Audio-visual speaker recognition for video broadcast news: some fusion
	techniques},
  booktitle = mmsp,
  year = {1999},
  pages = {161--167},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Mak01,
  author = {Mak, MW and Zhang, WD and He, MX},
  title = {{A new two-stage scoring normalization approach to speaker verification}},
  booktitle = {International Symposium on Intelligent Multimedia, Video and Speech
	Processing},
  year = {2001},
  pages = {107--110},
  organization = {IEEE},
  file = {Mak01.pdf:Speaker_reco/Scoring/Mak01.pdf:PDF}
}

@INPROCEEDINGS{Mak06,
  author = {Man-Wai Mak and Roger Hsiao and Brian Mak},
  title = {A comparison of various adaptation methods for speaker verification
	with limited enrollment data},
  booktitle = icassp,
  year = {2006},
  pages = {929--932},
  file = {Mak06.pdf:Speaker_reco/Short_Utterance/Mak06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.18}
}

@INPROCEEDINGS{Mallauran05,
  author = {Caroline Mallauran and Jean-Luc Dugelay and Florent Perronnin and
	Christophe Garcia},
  title = {Online face detection and user authentication},
  booktitle = {Proceedings of the 13th annual ACM International Conferencec on Multimedia},
  year = {2005},
  pages = {219-220},
  address = {Singapore},
  abstract = {The ability to verify automatically and with great accuracy the identity
	of a person has become crucial in everyday life. Biometrics is an
	emerging topic in the field of signal processing. Our research on
	biometrics aims at developing a complete framework useful to control
	access. This technical demo shows the latest image processing techniques
	for face detection developed at France Telecom and for face recognition
	developed at Eurécom. Using only one computer and one standard webcam,
	our biometric system detects the user face and the recognition algorithm
	uses this image to enable the access to a resource, a service or
	a location.},
  doi = {1101149.1101185},
  file = {Mallauran05.pdf:Video/Mallauran05.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.28}
}

@BOOK{maltoni09,
  title = {{Handbook of fingerprint recognition}},
  publisher = {Springer},
  year = {2009},
  author = {Maltoni, D. and Jain, AK and Prabhakar, S.}
}

@INPROCEEDINGS{Mami04,
  author = {Yassine Mami and Delphine Charlet},
  title = {Repr\'esentation compacte des locuteurs par distribution sur les
	mod\`eles d'ancrage},
  booktitle = jep,
  year = {2004},
  address = {Fes (Maroc)},
  abstract = {Speaker representation by location in a reference space is
	
	a new technique of speaker recognition and adaptation. It 
	
	consists in representing a speaker not absolutely but ra-
	
	ther relatively, by comparing him to a set of well trained
	
	speaker models. The main motivation is that the dimension
	
	(number of parameters) of the absolute speaker models is
	
	very large compared to the amount of free parameters that
	
	can be reliably estimated with few training data. In this
	
	paper, we recall the concept of relative location for spea- 
	
	ker recognition. Then, we introduce a statistical approach
	
	for speaker location to cope with the weaknessess of the
	
	classical relative approach. In-depth evaluations on a tele-
	
	phone database show that this concept of relative location
	
	is a promising way, as it leads to recognition rates simi-
	
	lar to those obtained with the GMM-UBM approach with
	
	more compact models.},
  file = {Mami04.pdf:Speaker_reco/Anchor_models/Mami04.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@INPROCEEDINGS{Mandasari11,
  author = {Miranti Indar Mandasari and Mitchell McLaren and David van Leeuwen},
  title = {{Evaluation of i-vector Speaker Recognition Systems for Forensic
	Application}},
  booktitle = interspeech,
  year = {2011},
  file = {Mandasari11.pdf:Speaker_reco/FA/I-Vector/Mandasari11.pdf:PDF},
  owner = {antho},
  timestamp = {2011.08.25}
}

@INPROCEEDINGS{Marcel06,
  author = {Sebastien Marcel and Johnny Mari\'ethoz and Yann Rodriguez and Fabien
	Cardinaux},
  title = {Bi-Modal Face and Speech Authentication: A BioLogin demonstration
	System},
  booktitle = mmua,
  year = {2006},
  address = {Toulouse (France)},
  month = {July},
  file = {Marcel06.pdf:Audio-Video/Marcel06.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.06.20}
}

@ARTICLE{Marcel10,
  author = {Sebastien Marcel and Christopher McCool and Pavel Matejka and Jan
	Cernocky and Joseph Kittler and Ondrej Glembek and Oldrich Plchot
	and Zdenrk Jancik and Anthony Larcher and Christophe Levy},
  title = {{On the Results of the First Mobile Biometry (MOBIO) Face and Speaker
	Verification Evaluation}},
  journal = {Lecture Notes in Computer Science},
  year = {2010},
  volume = {2010},
  pages = {210--225},
  number = {08},
  booktitle = {Recognizing Patterns in Signals, Speech, Images, and Videos},
  file = {Marcel10.pdf:Audio-Video/Marcel10.pdf:PDF},
  isbn = {978-3-642-17710-1},
  issn = {0302-9743},
  language = {english},
  location = {Istanbul, TR},
  publisher = {Springer Verlag},
  series = {LNCS, vol. 6388, pp. 210-225. Springer, Heidelberg (2010).},
  url = {http://www.fit.vutbr.cz/research/view_pub.php?id=9449}
}

@ARTICLE{Marcel07,
  author = {Sebastien Marcel and Jose del R. Millan.},
  title = {{Person Authentication using Brainwaves (EEG) and Maximum A Posteriori
	Model Adaptation.}},
  journal = pami,
  year = {2007},
  volume = {29(4)},
  pages = {743-748},
  file = {Marcel07.pdf:Divers/EEG/Marcel07.pdf:PDF},
  owner = {antho},
  timestamp = {2009.06.05}
}

@PHDTHESIS{Mariethoz06,
  author = {Johnny Mariethoz},
  title = {{Algorithmes d'apprentissage discriminants en v{\'e}rification du
	locuteur}},
  school = {Lyon II Lumi{\`e}re},
  year = {2006},
  owner = {antho},
  timestamp = {2009.03.20}
}

@ARTICLE{Mariethoz05,
  author = {Johnny Mari{\'e}thoz and Samy Bengio},
  title = {{A unified framework for score normalization techniques applied to
	text-independent speaker verification}},
  journal = {{Signal Processing Letters}},
  year = {2005},
  volume = {12},
  pages = {532--535},
  number = {7},
  file = {Mariethoz05.pdf:Speaker_reco/Normalisation/Mariethoz05.pdf:PDF},
  issn = {1070-9908},
  publisher = {IEEE}
}

@INPROCEEDINGS{Mariethoz02,
  author = {Johnny Mari{\'e}thoz and Samy Bengio},
  title = {{A comparative study of adaptation methods for speaker verification}},
  booktitle = interspeech,
  year = {2002},
  pages = {581--584},
  organization = {Citeseer},
  file = {Mariethoz02.pdf:Speaker_reco/Adaptation/Mariethoz02.pdf:PDF}
}

@ARTICLE{Marti02,
  author = {Marti, U.V. and Bunke, H.},
  title = {{The IAM-database: an English sentence database for offline handwriting
	recognition}},
  journal = {International Journal on Document Analysis and Recognition},
  year = {2002},
  volume = {5},
  pages = {39--46},
  number = {1},
  owner = {antho},
  publisher = {Springer},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Martin10,
  author = {Alvin Martin and Craig Greenberg},
  title = {{The 2009 NIST Language Recognition Evaluation}},
  booktitle = Odyssey,
  year = {2010},
  file = {Martin10.pdf:Language_reco/Martin10.pdf:PDF},
  owner = {antho},
  timestamp = {2011.03.11}
}

@ARTICLE{Martin00,
  author = {Martin, A. and Przybocki, M.},
  title = {{The NIST 1999 speaker recognition evaluation - An overview}},
  journal = dsp,
  year = {2000},
  volume = {10},
  pages = {1--18},
  number = {1-3},
  file = {Martin00.pdf:Speaker_reco/NIST/Martin00.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier Inc.},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Martin97,
  author = {Alvin F. Martin and George R. Doddington and Kamm, T. and Ordowski,
	M. and Mark A. Przybocki},
  title = {{The DET Curve in Assessment of Detection Task Performance}},
  booktitle = eurospeech,
  year = {1997},
  organization = {ISCA},
  file = {Martin97.pdf:Outils/DET curve and ROC/Martin97.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Martin09,
  author = {Alvin F. Martin and Creg S. Greenberg},
  title = {{NIST 2008 speaker recognition evaluation: performance across telephone
	and room microphone channels}},
  booktitle = interspeech,
  year = {2009},
  pages = {2579--2582},
  file = {Martin09.pdf:Speaker_reco/NIST/Martin09.pdf:PDF}
}

@ARTICLE{Martin06,
  author = {Terrence Martin and Brendan Baker and Eddie Wong and Sridha Sridharan},
  title = {{A syllable-scale framework for language identification}},
  journal = {Computer Speech \& Language},
  year = {2006},
  volume = {20},
  pages = {276--302},
  number = {2},
  file = {Martin06.pdf:Speaker_reco/Phonetic/Martin06.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Martinez01,
  author = {A. M. Martinez and A. C. Kak},
  title = {{PCA versus LDA}},
  journal = pami,
  year = {2001},
  volume = {23},
  pages = {228-233},
  number = {2},
  month = {February},
  abstract = {In the context of the appearance-based paradigm for object recognition,
	it is generally believed that algorithms based on LDA (linear discriminant
	analysis) are superior to those based on PCA (principal components
	analysis). In this communication, we show that this is not always
	the case. We present our case first by using intuitively plausible
	arguments and, then, by showing actual results on a face database.
	Our overall conclusion is that when the training data set is small,
	PCA can outperform LDA and, also, that PCA is less sensitive to different
	training data sets},
  doi = {10.1109/34.908974},
  file = {Martinez01.pdf:Video/Face_detection/Martinez01.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.30}
}

@INPROCEEDINGS{Martinez11,
  author = {D. Martinez and O. Plchot and L. Burget and O. Glembek and P. Matejka},
  title = {{Language Recognition in iVectors Space}},
  booktitle = {Interspeech},
  year = {2011},
  file = {Martinez11.PDF:Language_reco/Martinez11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.09.07}
}

@INPROCEEDINGS{Mason02,
  author = {John S. Mason and John D. Brand},
  title = {The role of dynamics in visual speech biometrics},
  booktitle = icassp,
  year = {2002},
  volume = {4},
  pages = {4076-4079},
  address = {Orlando (USA)},
  month = {May},
  abstract = {This paper begins by introducing biometrics and their underlying performance
	factors. Biometrics are sometimes classed as either behavioural or
	physiological. Difficulties with these classes are discussed in terms
	of the importance of dynamics, highlighting the key point that definitions
	are clarified if the biometric information-bearing signal itself
	is considered. Emphasis is then given to visual speech in the form
	of lip profiles The case is made that these are a special case in
	that they provide a vehicle for a twin biometric: both behavioural
	and physiological. It is argued that lips might well be unique in
	providing a practical twin biometric. Illustration is presented in
	the form of practical experiments based around visual speech and
	lip profiles. Experimental results using short, test and training
	segments from video recordings give recognition error rates as: physiological
	lip-profiles 2% and behavioural lip-profiles 15%.},
  doi = {10.1109/ICASSP.2002.1004814},
  file = {Mason02.pdf:Audio-Video/Mason02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.24}
}

@TECHREPORT{Mason96,
  author = {John S.D. Mason and F. Deravi and C. C. Chibelushi and S. Gandon},
  title = {{Project: DAVID (Digital Audio Visual Integrated Database)}},
  institution = {Department of Electrical and Electronic Engineering, University of
	Wales Swansea},
  year = {1996},
  file = {Mason96.pdf:Base_de_donnees/Mason96.pdf:PDF},
  owner = {antho},
  timestamp = {2012.03.06}
}

@INPROCEEDINGS{Mason89,
  author = {John S.D. Mason and John Oglesby and Li-Qun Xu},
  title = {Codebooks to Optimise Speaker Recognition},
  booktitle = {First European Conference on Speech Communication and Technology},
  year = {1989},
  organization = {ISCA}
}

@ARTICLE{Mason05,
  author = {John S. D. Mason and Nicholas W. D. Evans and Robert Stapert and
	Roland Auckenthaler},
  title = {Data-Model Relationship in Text-Independent Speaker Recognition},
  journal = eurasip,
  year = {2005},
  volume = {4},
  pages = {471-481},
  abstract = {Text-independent speaker recognition systems such as those based on
	Gaussian mixture models (GMMs) do not include time sequence information
	(TSI) within the model itself. The level of importance of TSI in
	speaker recognition is an interesting question and one addressed
	in this paper. Recent works has shown that the utilisation of higher-level
	information such as idiolect, pronunciation, and prosodics can be
	useful in reducing speaker recognition error rates. In accordance
	with these developments, the aim of this paper is to show that as
	more data becomes available, the basic GMM can be enhanced by utilising
	TSI, even in a text-independent mode. This paper presents experimental
	work incorporating TSI into the conventional GMM. The resulting system,
	known as the segmental mixture model (SMM), embeds dynamic time warping
	(DTW) into a GMM framework. Results are presented on the 2000-speaker
	SpeechDat Welsh database which show improved speaker recognition
	performance with the SMM.},
  doi = {10.1155/ASP.2005.471},
  file = {Mason05.pdf:Speaker_reco/GMM-UBM/Mason05.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.09.10}
}

@INPROCEEDINGS{Mason05_b,
  author = {Mickael W. Mason and Robert J. Vogt and Brendan J. Baker and Sridha
	Sridharan},
  title = {{Data-driven clustering for blind feature mapping in speaker verification}},
  booktitle = interspeech,
  year = {2005},
  publisher = {International Speech Communication Association (ISCA)},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/FA/Mason05.pdf:PDF}
}

@INPROCEEDINGS{Matejka11_a,
  author = {Pavel Matejka and Ondrej Glembeck and Fabio Castaldo and M.J. Alam
	and Oldrich Plchot and Patrick Kenny and Lukas Burget and Jan Cernocky},
  title = {{Full-covariance UBM and heavy-tailed PLDA in I-Vector speaker verification}},
  booktitle = interspeech,
  year = {2011},
  pages = {4828--4831},
  file = {Matejka11_a.pdf:Speaker_reco/FA/I-Vector/Matejka11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.07.26}
}

@ARTICLE{Matejka05_b,
  author = {Pavel Matejka and Petr Schwarz and Jan Cernock{\`y} and Pavel Chytil},
  title = {{Phonotactic language identification}},
  journal = {Proc. Radioelektronika},
  year = {2005},
  volume = {1},
  pages = {1--4},
  booktitle = {Radioelektronika},
  file = {Matejka05_b.pdf:Language_reco/Matejka05_b.pdf:PDF}
}

@CONFERENCE{Matejka05,
  author = {Pavel Matejka and Petr Schwarz and Jan Honza Cernock{\`y} and Pavel
	Chytil},
  title = {{Phonotactic language identification using high quality phoneme recognition}},
  booktitle = interspeech,
  year = {2005},
  pages = {2237--2240},
  file = {Matejka05.pdf:Language_reco/Phonotactic/Matejka05.pdf:PDF}
}

@ARTICLE{Matey09,
  author = {Matey, J.R. and Kennell, L.R.},
  title = {{Iris Recognition--Beyond One Meter}},
  journal = {Handbook of Remote Biometrics for Surveillance and Security, Springer,
	Berlin},
  year = {2009},
  volume = {1},
  pages = {23--59},
  publisher = {Springer}
}

@INPROCEEDINGS{Matrouf03,
  author = {Driss Matrouf and Olivier Bellot and Pascal Nocera and Georges Linares
	and Jean-Francois Bonastre},
  title = {Structural Linear Model-Space Transformations for Speaker Adaptation},
  booktitle = eurospeech,
  year = {2003},
  address = {Geneva (Switzerland)},
  month = {September},
  file = {Matrouf03.PDF:Speaker_reco/Adaptation/MAP/Matrouf03.PDF:},
  owner = {larcher},
  timestamp = {2009.10.05},
  url = {http://www.lia.univ-avignon.fr/php/publications2.php?page=5&selection=auteur&tableau2=matrouf}
}

@INPROCEEDINGS{Matrouf06,
  author = {Driss Matrouf and Jean-Francois Bonastre},
  title = {{Accurate Log-Likelihood Ratio Estimation by using Test Statistical
	Model for Speaker Verification}},
  booktitle = odyssey,
  year = {2006},
  pages = {1-5},
  month = {June},
  doi = {10.1109/ODYSSEY.2006.248139},
  file = {Matrouf06.pdf:Speaker_reco/Scoring/Matrouf06.pdf:PDF},
  keywords = {Gaussian processes, maximum likelihood estimation, protocols, speaker
	recognition, statistical testingGMM-UBM, Gaussian mixture model,
	LLR estimation, MAP-based speaker model adaptation, NIST SRE 2005
	protocol, Speaker Recognition Evaluation, log-likelihood ratio, speaker
	verification, test statistical model, universal background model}
}

@INPROCEEDINGS{Matrouf_NIST08,
  author = {Driss Matrouf and Jean-Francois Bonastre and Corinne Fredouille and
	Anthony Larcher and Salah Mezaache and Mitchell McLaren and Fernando
	Huenupan},
  title = {{LIA GMM-SVM system description: NIST SRE08}},
  booktitle = {NIST Speaker Recognition Evaluation Workshop},
  year = {2008},
  address = {Montreal (Canada)},
  month = {april},
  owner = {antho},
  timestamp = {2008.07.01}
}

@INPROCEEDINGS{Matrouf07,
  author = {Driss Matrouf and Nicolas Scheffer and Benoit Fauve and Jean-Francois
	Bonastre},
  title = {{A straightforward and efficient implementation of the factor analysis
	model for speaker verification}},
  booktitle = interspeech,
  year = {2007},
  file = {Matrouf07.pdf:Speaker_reco/FA/Matrouf07.pdf:PDF},
  journal = {Proc. Interspeech 2007},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Matsui93,
  author = {Tomoko Matsui and Sadaoki Furui},
  title = {Concatenated phoneme models for text-variable speaker recognition},
  booktitle = icassp,
  year = {1993},
  volume = {2},
  pages = {391-394},
  abstract = {Methods that create models to specify both speaker and phonetic information
	accurately by using only a small amount of training data for each
	speaker are investigated. For a text-dependent speaker recognition
	method, in which arbitrary key texts are prompted from the recognizer,
	speaker-specific phoneme models are necessary to identify the key
	text and recognize the speaker. Two methods of making speaker-specific
	phoneme models are discussed: phoneme-adaptation of a phoneme-independent
	speaker model and speaker-adaptation of universal phoneme models.
	The authors also investigate supplementing these methods by adding
	a phoneme-independent speaker model to make up for the lack of speaker
	information. This combination achieves a rejection rate as high as
	98.5% for speech that differs from the key text and a speaker verification
	rate of 100.0%},
  file = {Matsui93.pdf:Speaker_reco/Text_dependent/Matsui93.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@PHDTHESIS{Matta08,
  author = {Federico Matta},
  title = {{V}ideo person recognition strategies using head motion and facial
	appearance},
  school = {{U}niversity of {N}ice {S}ophia-{A}ntipolis ({UNSA})},
  year = {2008},
  month = {Avril},
  owner = {antho},
  timestamp = {2009.02.09}
}

@INPROCEEDINGS{Matta06,
  author = {Federico Matta and Jean-Luc Dugelay},
  title = {Person recognition using human head motion information},
  booktitle = amdo,
  year = {2006},
  pages = {326-335},
  address = {Andratx (Spain)},
  month = {July},
  owner = {larcher},
  timestamp = {2006.07.05}
}

@INPROCEEDINGS{Matthews98,
  author = {Iain Matthews and Tim Cootes and Stephen Cox and Richard Harvey and
	J. Andrew Bangham},
  title = {Lipreading Using Shape, Shading and Scale},
  booktitle = avsp,
  year = {1998},
  pages = {73--78},
  address = {Sydney, Australia},
  organization = {ISCA},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Matusov08,
  author = {Evgeny Matusov and Bjorn Hoffmeister and Hermann Ney},
  title = {{ASR word lattice translation with exhaustive reordering is possible}},
  booktitle = interspeech,
  year = {2008},
  pages = {2342--2345},
  file = {Matusov08.pdf:Machine_Translation/Matusov08.pdf:PDF}
}

@ARTICLE{Mcaulay86,
  author = {Robert J McAulay and Thomas F. Quatieri},
  title = {{Speech Analysis/Synthesis Based on a Sinusoidal Representation}},
  journal = tasp,
  year = {1986},
  volume = {34},
  pages = {744--754},
  file = {Mcaulay86.pdf:Parametrisation/Mcaulay86.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.13}
}

@INPROCEEDINGS{McCool09,
  author = {Christopher McCool and Sebastien Marcel},
  title = {Parts-based face verification using local frequency bands.},
  booktitle = icb,
  year = {2009},
  owner = {antho},
  timestamp = {2009.06.05}
}

@INPROCEEDINGS{Mccree08,
  author = {Alan McCree and Fred Richardson and Elliot Singer and Doug Reynolds},
  title = {{Beyond frame independence: Parametric modelling of time duration
	in speaker and language recognition}},
  booktitle = interspeech,
  year = {2008},
  pages = {767--770},
  file = {Mccree08.pdf:Normalisation/Mccree08.pdf:PDF}
}

@ARTICLE{Mcewan09,
  author = {McEwan, C. and Hart, E.},
  title = {{On AIRS and Clonal Selection for Machine Learning}},
  journal = {Artificial Immune Systems},
  year = {2009},
  volume = {1},
  pages = {67--79},
  file = {Mcewan09.pdf:Artificial_Immune_System/Mcewan09.pdf:PDF},
  publisher = {Springer}
}

@BOOK{Mcgehee37,
  title = {{The reliability of the identification of the human voice}},
  publisher = {Baltimore},
  year = {1937},
  author = {McGehee, F.},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{McKenna96,
  author = {Stephen Mckenna and Shaogang Gong and J.J. Collins},
  title = {Face Tracking and Pose Representation},
  booktitle = {British Machine Vision Conference},
  year = {1996},
  address = {Edimburgh (UK)},
  file = {McKenna96.pdf:Video/Face_tracking/McKenna96.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@ARTICLE{McKenna98,
  author = {Stephen J. McKenna and Shaogang Gong and Yogesh Raja},
  title = {Modelling Facial Colour and Identity with Gaussian Mixtures},
  journal = {Pattern Recognition},
  year = {1998},
  volume = {31},
  pages = {1883-1892},
  number = {12},
  file = {McKenna98.pdf:Video/Face_detection/McKenna98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.29}
}

@INPROCEEDINGS{Mclachlan00,
  author = {McLachlan, G.J. and Peel, D.},
  title = {{On computational aspects of clustering via mixtures of normal and
	t-components}},
  booktitle = {American Statistical Association (Bayesian Statistical Science Section)},
  year = {2000},
  file = {Mclachlan00.pdf:Outils/StudentT/Mclachlan00.pdf:PDF},
  owner = {antho},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{McLaren09,
  author = {Mitchell McLaren and brendan J. Baker and Robbie Vogt and Shrida
	Sridhara},
  title = {{Improved SVM speaker verification through data-driven background
	dataset selection.}},
  booktitle = icassp,
  year = {2009},
  pages = {1--4},
  file = {McLaren09.pdf:Speaker_reco/SVM/McLaren09.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.07}
}

@INPROCEEDINGS{McLaren11_a,
  author = {Mitchell McLaren and David A. Van Leeuwen},
  title = {{Source-normalised and weighted LDA for robust speaker recognition
	using I-Vectors}},
  booktitle = icassp,
  year = {2011},
  pages = {5456--5459},
  file = {McLaren11_a.pdf:Speaker_reco/FA/I-Vector/McLaren11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@INPROCEEDINGS{McLaren11_b,
  author = {Mitchell McLaren and David A. Van Leeuwen},
  title = {{Improved speaker recognition when using I-vectors from multiple
	speech sources}},
  booktitle = icassp,
  year = {2011},
  pages = {5460--5463},
  file = {McLaren11_b.pdf:Speaker_reco/FA/I-Vector/McLaren11_b.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@ARTICLE{Mclaren09,
  author = {McLaren, M. and Vogt, R. and Baker, B. and Sridharan, S.},
  title = {{Data-Driven Impostor Selection for T-Norm Score Normalisation and
	the Background Dataset in SVM-Based Speaker Verification}},
  journal = {Advances in Biometrics},
  year = {2009},
  volume = {1},
  pages = {474--483},
  publisher = {Springer}
}

@INPROCEEDINGS{Meigner08,
  author = {Sylvain Meigner and Teva Merlin and Christophe L{\'e}vy and Anthony
	Larcher and Eric Charton and Jean-Francois Bonastre and Laurent Besacier
	and J{\'e}r{\^o}me Farinas and Bertrand Ravera},
  title = {{Mistral: Plate-forme open source d'authentification biom{\'e}trique}},
  booktitle = jep,
  year = {2008},
  owner = {antho},
  timestamp = {2009.05.08}
}

@INPROCEEDINGS{Mengusoglu03,
  author = {Erhan Mengusoglu},
  title = {{Confidence measure based model adaptation for speaker verification}},
  booktitle = {International Conference on Communications, Internet and Information
	Technology},
  year = {2003},
  organization = {Citeseer},
  file = {Mengusoglu03.pdf:Speaker_reco/Adaptation/Mengusoglu03.pdf:PDF}
}

@INPROCEEDINGS{Merlin99,
  author = {Teva Merlin and Jean-Francois Bonastre and Corinne Fredouille},
  title = {Non Directly Acoustic Process for Costless Speaker Recognition and
	Indexation},
  booktitle = {{International Workshop on Intelligent Communication Technologies
	and Applications, with emphasis on Mobile Communications}},
  year = {1999},
  address = {Neuch{\^a}tel (Switzerland)},
  file = {Merlin99.pdf:Speaker_reco/Anchor_models/Merlin99.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.17}
}

@INPROCEEDINGS{Messer99,
  author = {Messer, K. and Matas, J. and Kittler, J. and Luettin, J. and Maitre,
	G.},
  title = {{XM2VTSDB: The Extended M2VTS Database}},
  booktitle = avbpa,
  year = {1999},
  volume = {626},
  file = {Messer99.pdf:Base_de_donnees/Messer99.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Micheloni09,
  author = {Christian Micheloni and Sergio Canazza and Gian Luca Foresti},
  title = {{Audio-video biometric recognition for non-collaborative access granting}},
  journal = {Journal of Visual Languages and Computing},
  year = {2009},
  volume = {20},
  pages = {353--367},
  number = {6},
  file = {Micheloni09.pdf:Audio-Video/Micheloni09.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.06}
}

@INPROCEEDINGS{Mikolov10,
  author = {Tomas Mikolov and Oldrich Plchot and Ondrej Glembek and Pavel Matejka},
  title = {{PCA-based Feature Extraction for Phonotactic Language Recognition}},
  booktitle = odyssey,
  year = {2010},
  file = {Mikolov10.pdf:Language_reco/Mikolov10.pdf:PDF}
}

@INPROCEEDINGS{Minematsu03,
  author = {Nobuaki Minematsu and Keita Yamauchi and Keikichi Hirose},
  title = {Automatic Estimation of Perceptual Age Using Speaker Modeling Techniques},
  booktitle = eurospeech,
  year = {2003},
  organization = {ISCA},
  file = {Minematsu03.pdf:Divers/Minematsu03.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Ming06,
  author = {Ji Ming and Timothy J. Hazen and James R. Glass},
  title = {{Speaker verification over handheld devices with realistic noisy
	speech data}},
  booktitle = icassp,
  year = {2006},
  pages = {637--640},
  file = {Ming06.pdf:Speaker_reco/Text_dependent/Ming06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.26}
}

@ARTICLE{Ming07,
  author = {Ji Ming and Timothy J. Hazen and James R. Glass and Douglas A. Reynolds},
  title = {{Robust Speaker Recognition in Unknown Noisy Conditions}},
  journal = taslp,
  year = {2007},
  volume = {15},
  pages = {1711--1723},
  number = {5},
  file = {Ming07.pdf:Speaker_reco/Text_dependent/Ming07.pdf:PDF}
}

@INPROCEEDINGS{Ming06_b,
  author = {Ji Ming and timothy J. Hazen and James R. Glass},
  title = {{A comparative study of methods for handheld speaker verification
	in realistic noisy conditions}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--8},
  file = {Ming06_b.pdf:Speaker_reco/Text_dependent/Ming06_b.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.26}
}

@INPROCEEDINGS{Mirghafori04,
  author = {Nikki Mirghafori and Matthieu Hebert},
  title = {Paramatrization of the score threshold for a text-dependent adaptive
	speaker verification system},
  booktitle = icassp,
  year = {2004},
  pages = {361--363},
  doi = {10.1109/ICASSP.2004.1325997},
  file = {Mirghafori04.pdf:Speaker_reco/Unsupervised/Mirghafori04.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.19}
}

@INPROCEEDINGS{Miyajima00,
  author = {Chiyomi Miyajima and Keiichi Tokuda and Tadasbi Kitamura},
  title = {{Audio-visual speech recognition using minimum classification error
	training}},
  booktitle = {{Neural Networks for Signal Processing X}},
  year = {2000},
  volume = {1},
  pages = {3-12 vol.1},
  doi = {10.1109/NNSP.2000.889354},
  file = {Miyajima00.pdf:Audio-Video/Miyajima00.pdf:PDF},
  keywords = {audio-visual systems, errors, gradient methods, hidden Markov models,
	learning (artificial intelligence), minimisation, signal classification,
	speech recognitionaudiovisual speech recognition system, error reduction,
	generalized probabilistic descent method, globally-tied stream weights,
	hidden Markov model, likelihood combination, maximum likelihood criterion,
	minimum classification error training, model-dependent stream weight
	estimation, optimization, speaker-independent isolated word recognition,
	system performance}
}

@ARTICLE{Moghaddam97,
  author = {Baback Moghaddam and Alex Pentland},
  title = {Probabilistic visual learning for object representation},
  journal = pami,
  year = {1997},
  volume = {19},
  pages = {696-710},
  abstract = {We present an unsupervised technique for visual learning, which is
	based on density estimation in high-dimensional spaces using an eigenspace
	decomposition. Two types of density estimates are derived for modeling
	the training data: a multivariate Gaussian (for unimodal distributions)
	and a mixture-of-Gaussians model (for multimodal distributions).
	Those probability densities are then used to formulate a maximum-likelihood
	estimation framework for visual search and target detection for automatic
	object recognition and coding. Our learning technique is applied
	to the probabilistic visual modeling, detection, recognition, and
	coding of human faces and nonrigid objects, such as hands},
  doi = {10.1109/34.598227},
  file = {Moghaddam97.pdf:Video/Moghaddam97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.04}
}

@INBOOK{Mohri09,
  chapter = {Weighted Automata Algorithms},
  pages = {213-254},
  title = {{Handbook of Weighted Automata. Monographs in Theoretical Computer
	Science}},
  publisher = {Springer},
  year = {2009},
  author = {Mehryar Mohri},
  file = {Mohri09.pdf:FST/Mohri09.pdf:PDF},
  owner = {antho},
  timestamp = {2012.04.03}
}

@ARTICLE{Mohri08,
  author = {Mehryar Mohri and Fernando C. N. Pereira and Michael Riley},
  title = {{Speech recognition with weighted finite-state transducers}},
  journal = {Handbook on Speech Processing and Speech Communication},
  year = {2008},
  volume = {E},
  pages = {1--31},
  file = {Mohri08.pdf:FST/Mohri08.pdf:PDF},
  owner = {antho},
  timestamp = {2012.04.03}
}

@ARTICLE{Monrose00,
  author = {Fabian Monrose and Aviel D. Rubin},
  title = {Keystroke dynamics as a biometric for authentication},
  journal = {Future Gener Comput Syst},
  year = {2000},
  volume = {16},
  pages = {351--359},
  number = {4},
  file = {Monrose00.pdf:Divers/Monrose00.pdf:PDF}
}

@INPROCEEDINGS{Montacie87,
  author = {Claude Montacie and Gérard Chollet},
  title = {Systèmes de référence pour l'évaluation d'applications et la caractérisation
	de bases de données en reconnaissance automatique de la parole},
  booktitle = jep,
  year = {1987},
  owner = {antho},
  timestamp = {2009.02.25}
}

@BOOK{Montanari10,
  title = {{Graphical Models Concepts in Compressed Sensing}},
  publisher = {Yonina Eldar and Gitta Kutyniok},
  year = {2010},
  author = {Andrea Montanari},
  file = {Montanari10.pdf:eBooks/Montanari10.pdf:PDF},
  journal = {Arxiv preprint arXiv:1011.4328}
}

@ARTICLE{Morein03,
  author = {Morein-Zamir, S. and Soto-Faraco, S. and Kingstone, A.},
  title = {{Auditory capture of vision: examining temporal ventriloquism}},
  journal = {Cognitive Brain Research},
  year = {2003},
  volume = {17},
  pages = {154--163},
  number = {1},
  file = {Morein03.pdf:Ventriloquie/Morein03.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Morgan04,
  author = {Nelson Morgan and Barry Y. Chen and Qifeng Zhu and Andreas Stolcke},
  title = {Trapping conversational speech: extending {TRAP/TANDEM} approaches
	to conventional telephone speech recognition},
  booktitle = icassp,
  year = {2004},
  owner = {antho},
  timestamp = {2009.02.25}
}

@INPROCEEDINGS{Morishima02,
  author = {Shigeo Morishima and Shin Ogata and Kazumasa Murai and Satoshi Nakamura},
  title = {{Audio-visual speech translation with automatic lip synchronization
	and face tracking based on 3-D head model}},
  booktitle = icassp,
  year = {2002},
  volume = {2},
  file = {Morishima02.pdf:Video/Segmentation/Viseme/Morishima02.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Mulyono08,
  author = {Mulyono, D. and Jinn, H.S.},
  title = {{A study of finger vein biometric for personal identification}},
  booktitle = {Biometrics and Security Technologies, 2008. ISBAST 2008. International
	Symposium on},
  year = {2008},
  pages = {1--8}
}

@ARTICLE{Muthusamy94,
  author = {Yeshwant K. Muthusamy and Etienne Barnard and Ronald A. Cole},
  title = {{Automatic language identification: A review/tutorial}},
  journal = {IEEE Signal Processing Magazine},
  year = {1994},
  volume = {11},
  pages = {33--41},
  number = {4},
  file = {Muthusamy94.pdf:Language_reco/Muthusamy94.pdf:PDF},
  publisher = {Citeseer}
}

@ARTICLE{Myers80,
  author = {Cory Myers and Lawrence R. Rabiner and Aaron E. Rosenberg},
  title = {Performance Tradeoffs in Dynamic Time Warping Algorithms for Isolated
	Word Recognition},
  journal = tassp,
  year = {1980},
  volume = {ASSP-28},
  pages = {623-635},
  number = {6},
  month = {December},
  abstract = {The technique of dynamic programming for the time registration of
	a reference and a test pattern has found widespread use in the area
	of isolated word recognition. Recently, a number of variations on
	the basic time warping algorithm have been proposed by Sakoe and
	Chiba, and Rabiner, Rosenberg, and Levinson. These algorithms all
	assume that the test input is the time pattern of a feature vector
	from an isolated word whose endpoints are known (at least approximately).
	The major differences in the methods are the global path constraints
	(i.e., the region of possible warping paths), the local continuity
	constraints on the path, and the distance weighting and normalization
	used to give the overall minimum distance. The purpose of this investigation
	is to study the effects of such variations on the performance of
	different dynamic time warping algorithms for a realistic speech
	database. The performance measures that were used include: speed
	of operation, memory requirements, and recognition accuracy. The
	results show that both axis orientation and relative length of the
	reference and the test patterns are important factors in recognition
	accuracy. Our results suggest a new approach to dynamic time warping
	for isolated words in which both the reference and test patterns
	are linearly warped to a fixed length, and then a simplified dynamic
	time warping algorithm is used to handle the nonlinear component
	of the time alignment. Results with this new algorithm show performance
	comparable to or better than that of all other dynamic time warping
	algorithms that were studied.},
  file = {Myers80.pdf:Speech_reco/Word_reco/Myers80.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Nakagawa04,
  author = {Seiichi Nakagawa and Zhang Wei and Mitsuo Takahashi},
  title = {{Text-independent speaker recognition by combining speaker-specific
	GMM with speaker adapted syllable-based HMM}},
  booktitle = icassp,
  year = {2004},
  volume = {5},
  address = {Montreal (Canada)},
  month = {May},
  abstract = {We presented a new text-independent speaker recognition method by
	combining speaker-specific Gaussian Mixture Model(GMM) with syllable-based
	HMM adapted by MLLR or MAP (EuroSpeech 2003[16]). The robustness
	of this speaker recognition method for speaking style's change was
	evaluated in this paper. The speaker identification experiment using
	NTT database which consists of sentences data uttered at three speed
	modes (normal, fast and slow) by 35 Japanese speakers(22 males and
	13 females) on five sessions over ten months was conducted. Each
	speaker uttered only 5 training utterances (about 20 seconds in total).
	We obtained the accuracy of 98.8% for text-independent speaker identification
	for three speaking style modes (normal, fast, slow) by using a short
	test utterance (about 4 seconds). This result was superior to conventional
	methods for the same database. We show that the attractive result
	was brought from the compensational effect between speaker specific
	GMM and speaker adapted syllable based HMM.},
  file = {Nakagawa04.pdf:Speaker_reco/Text_dependent/Nakagawa04.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.07.30}
}

@INPROCEEDINGS{Navarrete01,
  author = {Pablo Navarrete and Javier Ruiz-del-Solar},
  title = {{Eigenspace-based Recognition of Faces: Comparisons and a new Approach}},
  booktitle = {Image Analysis and Processing},
  year = {2001},
  pages = {42--47},
  organization = {IEEE},
  file = {Navarrete01.pdf:Image/EigenSpace/Navarrete01.pdf:PDF}
}

@CONFERENCE{Navratil06,
  author = {Jiri Navratil},
  title = {{Recent advances in phonotactic language recognition using binary-decision
	trees}},
  booktitle = interspeech,
  year = {2006},
  organization = {Citeseer},
  file = {Navratil06.pdf:Language_reco/Phonotactic/Navratil06.pdf:PDF}
}

@ARTICLE{Navratil02,
  author = {Jiri Navratil},
  title = {{Spoken language recognition-a step toward multilinguality in speech
	processing}},
  journal = tasp,
  year = {2002},
  volume = {9},
  pages = {678--685},
  number = {6},
  file = {Navratil02.pdf:Language_reco/Navratil02.pdf:PDF},
  issn = {1063-6676},
  publisher = {IEEE}
}

@INPROCEEDINGS{Navratil00,
  author = {Jiri Navratil and Upendra V. Chaudhari and Stephane H. Maes},
  title = {A Speech Biometrics System with Multigrained Speaker Modeling},
  booktitle = {Conference for Natural Speech Processing},
  year = {2000},
  owner = {antho},
  timestamp = {2007.09.24}
}

@INPROCEEDINGS{Navratil03,
  author = {Jiri Navratil and Qin Jin and Walter D. Andrews and Joseph P. Campbell},
  title = {{Phonetic speaker recognition using maximum-likelihood binary-decision
	tree models}},
  booktitle = icassp,
  year = {2003},
  volume = {4},
  pages = {796-799},
  abstract = {Recent work in phonetic speaker recognition has shown that modeling
	phone sequences using n-grams is a viable and effective approach
	to speaker recognition, primarily aiming at capturing speaker-dependent
	pronunciation and also word usage. The paper describes a method involving
	binary-tree-structured statistical models for extending the phonetic
	context beyond that of standard n-grams (particularly bigrams) by
	exploiting statistical dependencies within a longer sequence window
	without exponentially increasing the model complexity, as is the
	case with n-grams. Two ways of dealing with data sparsity are also
	studied; namely, model adaptation and a recursive bottom-up smoothing
	of symbol distributions. Results obtained under a variety of experimental
	conditions using the NIST 2001 Speaker Recognition Extended Data
	Task indicate consistent improvements in equal-error rate performance
	as compared to standard bigram models. The described approach confirms
	the relevance of long phonetic context in phonetic speaker recognition
	and represents an intermediate stage between short phone context
	and word-level modeling without the need for any lexical knowledge,
	which suggests its language independence.},
  file = {Navratil03.pdf:Language_reco/Navratil03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.06.21}
}

@INPROCEEDINGS{Nealand05,
  author = {James H. Nealand and Jason W. Pelecanos and Ran D. Zilca and Ganesh
	N. Ramaswamy},
  title = {A study of the relative importance of temporal characteristics in
	text-dependent and text-constrained speaker verification},
  booktitle = icassp,
  year = {2005},
  pages = {653--656},
  file = {Nealand05.pdf:Speaker_reco/Text_dependent/Nealand05.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.18}
}

@BOOK{Nefian03,
  title = {A Bayesian Approach to Audio-Visual Speaker Identification},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  author = {Ara V. Nefian and Lu Hong Liang and Tieyan Fu and Xiao Xing Liu},
  volume = {2688-1},
  pages = {761--769},
  doi = {10.1007/3-540-44887-X},
  journal = {Lectures Notes in Computer Science},
  owner = {antho},
  timestamp = {2008.10.24}
}

@INPROCEEDINGS{Ney99,
  author = {Hermann Ney},
  title = {{Speech translation: Coupling of recognition and translation}},
  booktitle = icassp,
  year = {1999},
  pages = {517--520},
  organization = {IEEE},
  file = {Ney99.pdf:Machine_Translation/Ney99.pdf:PDF}
}

@INPROCEEDINGS{Ng10,
  author = {Raymond W. M. Ng and Tan Lee and Cheung-Chi Leung and Bin Ma and
	Haizhou Li},
  title = {{Analysis and selection of prosodic features for language identification}},
  booktitle = {International Conference on Asian Language Processing},
  year = {2010},
  pages = {123--128},
  organization = {IEEE},
  file = {Ng10.pdf:Language_reco/Ng10.pdf:PDF}
}

@INPROCEEDINGS{Ng10_b,
  author = {Raymond W. M. Ng and Tan Lee and Cheung-Chi Leung and Bin Ma and
	Haizhou Li},
  title = {{Prosodic attribute model for spoken language identification}},
  booktitle = icassp,
  year = {2010},
  pages = {5022--5025},
  organization = {IEEE},
  file = {Ng10_b.pdf:Language_reco/Ng10_b.pdf:PDF},
  issn = {1520-6149}
}

@INPROCEEDINGS{Nishida01,
  author = {Nishida, M. and Ariki, Y.},
  title = {{Speaker recognition by separating phonetic space and speaker space}},
  booktitle = eurospeech,
  year = {2001},
  pages = {1381--1384},
  organization = {ISCA},
  file = {Nishida01.pdf:Speaker_reco/Text_dependent/Nishida01.pdf:PDF}
}

@INPROCEEDINGS{Nishida00,
  author = {Masafumi Nishida and Ariki, Y.},
  title = {{Speaker verification by integrating dynamic and static features
	using subspace method}},
  booktitle = interspeech,
  year = {2000},
  file = {Nishida00.pdf:Speaker_reco/Text_dependent/Nishida00.pdf:PDF}
}

@INPROCEEDINGS{Noda98,
  author = {Hideki Noda and Katsuya Harada and Eiji Kawaguchi and Hidefumi Sawai},
  title = {A Context-Dependent Approach for Speaker Verification Using Sequential
	Decision},
  booktitle = icslp,
  year = {1998},
  address = {Sydney},
  month = {November},
  abstract = {This paper is concerned about speaker verification (SV) using the
	sequential probability ratio test (SPRT). In the SPRT input samples
	are usually assumed to be i.i.d. samples from a probability density
	function because an on-line probability computation is required.
	Feature vectors used in speech processing obviously do not satisfy
	the assumption and therefore the correlation between successive feature
	vectors has not been considered in conventional SV using the SPRT.
	The correlation can be modeled by the hidden Markov model (HMM) but
	unfortunately the HMM can not be directly applied to the SPRT because
	of statistical dependence of input samples. This paper proposes a
	method of HMM probability computation using the mean field approximation
	to resolve this problem, where the probability of whole input samples
	is nominally represented as the product of probability of each sample
	as if input samples were independent each other.},
  owner = {larcher},
  timestamp = {2007.02.08}
}

@INPROCEEDINGS{Nosratighods07,
  author = {Mohaddeseh Nosratighods and Eliathamby Ambikairajah and Julien Epps
	and Michael Carey},
  title = {{P-value segment selection technique for speaker verification}},
  booktitle = icassp,
  year = {2007},
  volume = {4},
  pages = {IV--269},
  organization = {IEEE},
  file = {Nosratighods07.pdf:Speaker_reco/Data_selection/Nosratighods07.pdf:PDF}
}

@ARTICLE{Nosratighods10,
  author = {Mohaddeseh Nosratighods and Eliathamby Ambikairajah and Julien Epps
	and Michael John Carey},
  title = {{A segment selection technique for speaker verification}},
  journal = {Speech Communication},
  year = {2010},
  volume = {52},
  pages = {753--761},
  number = {9},
  file = {Nosratighods10.pdf:Speaker_reco/Short_Utterance/Nosratighods10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.06}
}

@ARTICLE{Oglesby95,
  author = {John Oglesby},
  title = {{What's in a number? Moving beyond the equal error rate}},
  journal = {Speech Communication},
  year = {1995},
  volume = {17},
  pages = {193--208},
  number = {1-2},
  file = {Oglesby95.pdf:Outils/DET curve and ROC/Oglesby95.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Oglesby90,
  author = {John Oglesby and John S.D. Mason},
  title = {Optimisation of neural models for speaker identification},
  booktitle = icassp,
  year = {1990},
  pages = {261--264},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Okamoto09,
  author = {Takeshi Okamoto and Takayuki Watanabe and Yoshiteru Ishida},
  title = {{Towards an immunity-based system for detecting masqueraders}},
  journal = {International Journal of Knowledge-based and Intelligent Engineering
	Systems},
  year = {2009},
  volume = {13},
  pages = {103--110},
  number = {3},
  file = {Okamoto09.pdf:Artificial_Immune_System/Okamoto09.pdf:PDF},
  publisher = {IOS Press}
}

@INPROCEEDINGS{Orr00,
  author = {Robert J. Orr and Gregory D. Abowd},
  title = {{The smart floor: a mechanism for natural user identification and
	tracking}},
  booktitle = {Conference on Human Factors in Computing Systems},
  year = {2000},
  pages = {275--276},
  address = {New York (USA)},
  organization = {ACM},
  file = {Orr00.pdf:Divers/Footstep/Orr00.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Ortegagarcia03,
  author = {Ortega-Garcia, J. and Fierrez-Aguilar, J. and Simon, D. and Gonzalez,
	J. and Faundez-Zanuy, M. and Espinosa, V. and Satue, A. and Hernaez,
	I. and Igarza, J.J. and Vivaracho, C. and others},
  title = {{MCYT baseline corpus: a bimodal biometric database}},
  journal = {IEEE Proceedings on Vision, Image and Signal Processing},
  year = {2003},
  volume = {150},
  pages = {395--401},
  number = {6},
  booktitle = {Vision, Image and Signal Processing, IEE Proceedings-}
}

@INPROCEEDINGS{Osuna97,
  author = {Edgar Osuna and Robert Freund and Federico Girosi},
  title = {Training support vector machines: an application to face detection},
  booktitle = cvpr,
  year = {1997},
  pages = {130-136},
  address = {San Juan (Puerto Rico)},
  month = {June},
  abstract = {We investigate the application of Support Vector Machines (SVMs) in
	computer vision. SVM is a learning technique developed by V. Vapnik
	and his team (AT&T Bell Labs., 1985) that can be seen as a new method
	for training polynomial, neural network, or Radial Basis Functions
	classifiers. The decision surfaces are found by solving a linearly
	constrained quadratic programming problem. This optimization problem
	is challenging because the quadratic form is completely dense and
	the memory requirements grow with the square of the number of data
	points. We present a decomposition algorithm that guarantees global
	optimality, and can be used to train SVM's over very large data sets.
	The main idea behind the decomposition is the iterative solution
	of sub-problems and the evaluation of optimality conditions which
	are used both to generate improved iterative values, and also establish
	the stopping criteria for the algorithm. We present experimental
	results of our implementation of SVM, and demonstrate the feasibility
	of our approach on a face detection problem that involves a data
	set of 50,000 data points},
  doi = {10.1109/CVPR.1997.609310},
  file = {Osuna97.pdf:Video/Face_detection/Osuna97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.29}
}

@ARTICLE{Pan85,
  author = {Kuk-Chin Pan and Frank Kao Ping Soong Soong and Lawrence Rabiner},
  title = {A Vector Quantization based Preprocessor for speaker independent
	isolated word recognition},
  journal = tassp,
  year = {1985},
  volume = {33},
  pages = {546-560},
  number = {3},
  month = {June},
  abstract = {In this paper, we propose a speaker-independent isolated ward recognition
	system whose performance is comparable to that of a conventional
	isolated word recognizer, but whose computation is greatly reduced.
	The structure of the proposed recognizer consists of a word-based
	vector quantization (VQ) preprocessor, followed by a conventional
	DTW postprocessor. The purpose of the preprocessor is essentially
	to eliminate from further consideration all words in the vocabulary
	which are unlikely recognition candidates. In some cases, the preprocessor
	will be able to eliminate all word candidates except one; for such
	cases, there is no further processing required for word recognition.
	In all other cases (i.e., when more than one word candidate is passed
	on), a dynamic time warping (DTW) processor is used to re-solve finer
	acoustical distinctions among the remaining word candidates. The
	performance of this type of recognizer (i.e., using a word-based
	preprocessor and a standard DTW comparison to make finer distinctions)
	is affected by a number of factors involved with the details of exactly
	how the system is implemented-e.g., the distortion measure used in
	the preprocessor and in the DTW comparison, the size of the VQ codebook
	for each vocabulary word, the decision thresholds of the preprocessor,
	etc. Several of these factors were studied experimentally using testing
	databases consisting of isolated digits and words from a vocabulary
	of 129 airline terms. The results show that the proposed preprocessor
	has the capability of reducing computation for recognition by up
	to an order of magnitude, while maintaining the same performance
	as that obtained using a DTW comparison without the pre-processor.
	A somewhat smaller reduction in memory over the straight DTW implementation
	is also obtained in the proposed approach.},
  file = {Pan85.pdf:Speaker_reco/VQ/Pan85.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.23}
}

@INPROCEEDINGS{Park02,
  author = {Alex Park and Timothy Hazen},
  title = {{ASR Dependent Techniques for Speaker Identification}},
  booktitle = interspeech,
  year = {2002},
  pages = {1337--1340},
  address = {Denver, USA},
  file = {Park02.pdf:Speaker_reco/Text_dependent/Park02.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.18}
}

@INPROCEEDINGS{Park04,
  author = {Alex Park and Timothy J. Hazen},
  title = {{A comparison of normalization and training approaches for ASR-dependent
	speaker identification}},
  booktitle = interspeech,
  year = {2004},
  organization = {Citeseer},
  file = {Park04.pdf:Speaker_reco/Text_dependent/Park04.pdf:PDF}
}

@ARTICLE{Park09,
  author = {Hyunsin Park and Tetsuya Takiguchi and Yasuo Ariki},
  title = {{Integrated phoneme subspace method for speech feature extraction}},
  journal = {{EURASIP Journal on Audio, Speech, and Music Processing}},
  year = {2009},
  volume = {2009},
  pages = {1--9},
  file = {Park09.pdf:Speech_reco/Park09.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.06}
}

@INPROCEEDINGS{Park08,
  author = {Hyunsin Park and Tetsuya Takiguchi and Yasuo Ariki},
  title = {{Integration of Phoneme-Subspaces Using ICA for Speech Feature Extraction
	and Recognition}},
  booktitle = {{Hands-Free Speech Communication and Microphone Arrays}},
  year = {2008},
  pages = {148--151},
  file = {Park08.pdf:Parametrisation/Park08.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.07}
}

@ARTICLE{Parker05,
  author = {D.R. Parker and S.C. Gustafson andT.D. Ross},
  title = {Bayesian Confidence Intervals for ROC Curves},
  journal = {Electronics Letters},
  year = {2005},
  volume = {41},
  pages = {279-280},
  file = {Parker05.pdf:Outils/interval_confiance/Parker05.pdf:PDF},
  owner = {antho},
  timestamp = {2009.09.30}
}

@ARTICLE{Parmar07,
  author = {Darshit Parmar and Teresa Wu and Jennifer Blackhurst},
  title = {{MMR: An algorithm for clustering categorical data using Rough Set
	Theory}},
  journal = {Data \& Knowledge Engineering},
  year = {2007},
  volume = {63},
  pages = {877--891},
  number = {3},
  file = {Parmar07.pdf:Speaker_reco/Adaptation/MMR/Parmar07.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Parris98,
  author = {Eluned S. Parris and Michael J. Carey},
  title = {{Multilateral techniques for speaker recognition}},
  booktitle = icslp,
  year = {1998}
}

@INPROCEEDINGS{Parthasarathy96,
  author = {Srinivasan Parthasarathy and Aaron E. Rosenberg},
  title = {{General phrase speaker verification using sub-word background models
	and likelihood-ratio scoring}},
  booktitle = interspeech,
  year = {1996},
  volume = {4},
  pages = {2403--2406},
  organization = {IEEE},
  file = {Parthasarathy96.pdf:Speaker_reco/Text_dependent/Parthasarathy96.pdf:PDF}
}

@INPROCEEDINGS{Patterson03,
  author = {Patterson, EK and Gowdy, JN},
  title = {An audio-visual approach to simultaneous-speaker speech recognition},
  booktitle = icassp,
  year = {2003},
  volume = {5},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Patterson02,
  author = {Patterson, E. and Gurbuz, S. and Tufekci, Z. and Gowdy, J.},
  title = {{CUAVE: A new audio-visual database for multimodal human-computer
	interface research}},
  booktitle = icassp,
  year = {2002},
  volume = {2},
  organization = {Citeseer},
  file = {Patterson02.pdf:Base_de_donnees/Patterson02.pdf:PDF}
}

@ARTICLE{Peel00,
  author = {Peel, D. and McLachlan, GJ},
  title = {{Robust mixture modelling using the t distribution}},
  journal = {Statistics and Computing},
  year = {2000},
  volume = {10},
  pages = {339--348},
  number = {4},
  file = {Peel00.pdf:Outils/StudentT/Peel00.pdf:PDF},
  issn = {0960-3174},
  publisher = {Springer}
}

@INPROCEEDINGS{Pelecanos01,
  author = {Jason Pelecanos and Sridha Sridharan},
  title = {{Feature warping for robust speaker verification}},
  booktitle = odyssey,
  year = {2001},
  file = {Pelecanos01.pdf:Speaker_reco/FA/Pelecanos01.pdf:PDF}
}

@INPROCEEDINGS{Penagarikano10_b,
  author = {Mikel Penagarikano and Amparo Varona and Mireia Diez and Luis Javier
	Rodriguez-Fuentes and German Bordel},
  title = {{A speaker recognition system based on sufficient-statistic-space
	channel-compensation and dto-scoring}},
  booktitle = {FALA "VI Jornadas en Tecnología del Habla" and II Iberian SLTech
	Workshop},
  year = {2010},
  file = {Penagarikano10_b.pdf:Speaker_reco/FA/Penagarikano10_b.pdf:PDF},
  owner = {antho},
  timestamp = {2011.01.19}
}

@INPROCEEDINGS{Penagarikano10,
  author = {Mikel Penagarikano and Amparo Varona and Luis Javier Rodriguez-Fuentes
	and German Bordel},
  title = {{Using cross-decoder phone coocurrences in phonotactic language recognition}},
  booktitle = icassp,
  year = {2010},
  pages = {5034--5037},
  organization = {IEEE},
  file = {Penagarikano10.pdf:Language_reco/Penagarikano10.pdf:PDF},
  issn = {1520-6149}
}

@ARTICLE{Perlibakas04,
  author = {Vytautas Perlibakas},
  title = {{Distance measures for PCA-based face recognition}},
  journal = {Pattern Recognition Letters},
  year = {2004},
  volume = {25},
  pages = {711--724},
  number = {6},
  file = {Perlibakas04.pdf:Image/EigenSpace/Perlibakas04.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Perronnin02,
  author = {Florent Perronnin and Jean-Luc Dugelay},
  title = {Introduction \`{a} la Biom\'{e}trie : Authentification des individus
	par traitement audio-vid\'{e}o},
  journal = {Traitement du Signal},
  year = {2002},
  volume = {19},
  pages = {253-265},
  number = {4},
  abstract = {La biometrie, qui consiste a identifier un individu a partir de ses
	caracteristiques physiques ou comportementales, connait depuis quelques
	annees un renouveau spectaculaire dans la communaute du traitement
	du signal. Elle a aussi recu une attention accrue de la part des
	medias depuis les tragiques evenements du 11 septembre 2001. Dans
	cet article nous introduisons tout d' abord la notion de biometrie.
	Nous decrivons l' architecture d' un systeme biometrique ainsi que
	les metriques utilisees pour evaluer leur performance. Nous donnons
	un bref apercu des technologies biometriques les plus courantes et
	des moyens de les fusionner pour obtenir des systemes multimodaux.
	Nous presentons enfin les applications possibles de la biometrie.},
  owner = {larcher},
  timestamp = {2006.06.20}
}

@ARTICLE{Perronnin05,
  author = {Florent Perronnin and Jean-Luc Dugelay and Kenneth Rose},
  title = {A probabilistic model of face mapping with local transformations
	and its application to person recognition},
  journal = pami,
  year = {2005},
  volume = {27},
  pages = {1157-1171},
  number = {7},
  abstract = {This paper proposes a new measure of "distance" between faces. This
	measure involves the estimation of the set of possible transformations
	between face images of the same person. The global transformation,
	which is assumed to be too complex for direct modeling, is approximated
	by a patchwork of local transformations, under a constraint imposing
	consistency between neighboring local transformations. The proposed
	system of local transformations and neighboring constraints is embedded
	within the probabilistic framework of a two-dimensional hidden Markov
	model. More specifically, we model two types of intraclass variabilities
	involving variations in facial expressions and illumination, respectively.
	The performance of the resulting method is assessed on a large data
	set consisting of four face databases. In particular, it is shown
	to outperform a leading approach to face recognition, namely, the
	Bayesian intra/extrapersonal classifier.},
  doi = {10.1109/TPAMI.2005.130},
  file = {Perronnin05.pdf:Video/Perronnin05.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.28}
}

@INPROCEEDINGS{Peskin03,
  author = {Barbara Peskin and Jiri Navratil and Joy Abramson and Douglas Jones
	and David Klusacek and Douglas A. Reynolds and Bing Xiang},
  title = {Using Prosodic and Conversational Features for High-Performance Speaker
	Recognition Report from JHU WS'02},
  booktitle = icassp,
  year = {2003},
  volume = {4},
  pages = {792-795},
  address = {Hong Kong},
  abstract = {While there has been a long tradition of research seeking to use prosodic
	features, especially pitch, in speaker recognition systems, results
	have generally been disappointing when such features are used in
	isolation and only modest improvements have been seen when used in
	conjunction with traditional cepstral GMM systems. In contrast, we
	report here on work from the JHU 2002 Summer Workshop exploring a
	range of prosodic features, using as testbed the 2001 NIST Extended
	Data task. We examined a variety of modeling techniques, such as
	n-gram models of turn-level prosodic features and simple vectors
	of summary statistics per conversation side scored by k/sup th/ nearest-neighbor
	classifiers. We found that purely prosodic models were able to achieve
	equal error rates of under 10%, and yielded significant gains when
	combined with more traditional systems. We also report on exploratory
	work on "conversational" features, capturing properties of the interaction
	across conversation sides, such as turn-taking patterns.},
  file = {Peskin03.pdf:Speaker_reco/Divers/Peskin03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.23}
}

@INPROCEEDINGS{Petracca06,
  author = {Petracca, M. and Servetti, A. and Martin, J.C.},
  title = {{Performance analysis of compressed-domain automatic speaker recognition
	as a function of speech coding technique and bit rate}},
  booktitle = {{Conference on Multimedia and Expo}},
  year = {2006},
  pages = {1393--1396},
  organization = {IEEE},
  file = {Petracca06.pdf:Speaker_reco/Compression/Petracca06.pdf:PDF}
}

@INPROCEEDINGS{Phillips05,
  author = {Phillips, PJ and Flynn, PJ and Scruggs, T. and Bowyer, KW and Chang,
	J. and Hoffman, K. and Marques, J. and Min, J. and Worek, W.},
  title = {{Overview of the face recognition grand challenge}},
  booktitle = cvpr,
  year = {2005},
  volume = {1},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Phillips06,
  author = {Phillips, P.J. and Flynn, P.J. and Scruggs, T. and Bowyer, K. and
	Worek, W. and National Institute of Standards and Technology (US},
  title = {{Preliminary Face Recognition Grand Challange Results}},
  booktitle = {International Conference on Automatic Face and Gesture Recognition
	(FGR)},
  year = {2006},
  publisher = {US Dept. of Commerce, National Institute of Standards and Technology},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Phillips00,
  author = {P. Jonathon Phillips and Alvin Martin and C.l. Wilson and Mark Przybocki},
  title = {An Introduction to Evaluating Biometric Systems},
  journal = {Computer},
  year = {2000},
  volume = {33},
  pages = {56-63},
  number = {2},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/2.820040},
  issn = {0018-9162},
  publisher = {IEEE Computer Society}
}

@ARTICLE{Pigeon00,
  author = {Stephane Pigeon and Pascal Druyts and Patrick Verlinde},
  title = {{Applying logistic regression to the fusion of the NIST'99 1-speaker
	submissions}},
  journal = {Digital Signal Processing},
  year = {2000},
  volume = {10},
  pages = {237--248},
  number = {1-3},
  file = {Pigeon00.pdf:Speaker_reco/Score_Fusion/Pigeon00.pdf:PDF},
  issn = {1051-2004},
  publisher = {Elsevier}
}

@ARTICLE{Pigeon97,
  author = {Stephane Pigeon and Luc Vandendorpe},
  title = {{The M2VTS multimodal face database (release 1.00)}},
  journal = lncs,
  year = {1997},
  volume = {1206/1997},
  pages = {403--409},
  booktitle = {Audio-and Video-Based Biometric Person Authentication},
  organization = {Springer}
}

@ARTICLE{Poh08,
  author = {Norman Poh and Joseph Kittler},
  title = {{Incorporating Variation of Model-specific Score Distribution in
	Speaker Verification Systems}},
  journal = taslp,
  year = {2008},
  volume = {16},
  pages = {594--606},
  number = {3},
  file = {Poh08.pdf:Speaker_reco/Score_Fusion/Poh08.pdf:PDF},
  owner = {antho},
  timestamp = {2010.12.01}
}

@INPROCEEDINGS{Poh09,
  author = {Norman Poh and Amin Merati and joseph Kittler},
  title = {{Adaptive client-impostor centric score normalization: A case study
	in fingerprint verification}},
  booktitle = {International Conference on Biometrics: Theory, Applications, and
	Systems},
  year = {2009},
  pages = {1--7},
  organization = {IEEE},
  file = {Poh09.pdf:Speaker_reco/Normalisation/Poh09.pdf:PDF}
}

@ARTICLE{Potamianos01,
  author = {Gerasimos Potamianos and Chalapathy Neti and Giridharan Iyengar and
	Andrew W. Senior and Ashish Verma},
  title = {A Cascade Visual Front End for Speaker Independent Automatic Speechreading},
  journal = {International Journal of Speech Technology},
  year = {2001},
  volume = {4},
  pages = {193--208},
  number = {3},
  file = {Potamianos01.pdf:Audio-Video/Potamianos01.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Potamianos03,
  author = {Gerasimos PotamianosS and Chalapathy Neti and Guillaume Gravier and
	Ashutosh Garg},
  title = {Recent Advances in the Automatic Recognition of Audiovisual Speech},
  journal = ieee,
  year = {2003},
  volume = {91},
  pages = {1306-1326},
  number = {9},
  abstract = {Visual speech information from the speaker's mouth region has been
	successfully shown to improve noise robustness of automatic speech
	recognizers, thus promising to extend their usability in the human
	computer interface. In this paper, we review the main components
	of audiovisual automatic speech recognition (ASR) and present novel
	contributions in two main areas: first, the visual front-end design,
	based on a cascade of linear image transforms of an appropriate video
	region of interest, and subsequently, audiovisual speech integration.
	On the latter topic, we discuss new work on feature and decision
	fusion combination, the modeling of audiovisual speech asynchrony,
	and incorporating modality reliability estimates to the bimodal recognition
	process. We also briefly touch upon the issue of audiovisual adaptation.
	We apply our algorithms to three multisubject bimodal databases,
	ranging from small- to large-vocabulary recognition tasks, recorded
	in both visually controlled and challenging environments. Our experiments
	demonstrate that the visual modality improves ASR over all conditions
	and data considered, though less so for visually challenging environments
	and large vocabulary tasks.},
  doi = {10.1109/JPROC.2003.817150},
  file = {Potamianos03.pdf:Audio-Video/Potamianos03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@INPROCEEDINGS{Pouchoulin07,
  author = {Pouchoulin, G. and Fredouille, C. and Bonastre, J.-F. and Ghio, A.
	and Revis, J.},
  title = {{Characterization of the pathological voices (dysphonia) in the frequency
	space}},
  booktitle = {Proceedings of International Congress of Phonetic Sciences (ICPhS)},
  year = {2007},
  volume = {16},
  pages = {6--10}
}

@INPROCEEDINGS{Povey10,
  author = {Daniel Povey and Lukas Burget and Mohit Agarwal and Pinar Akiazy
	and Kai Feng and Arnab Ghoshal and Ondrej Glembeck and Nagendra Kumar
	Goel and Martin Karafiat and Ariya Rastrow and Richard C. Rose and
	Petr Schwarz and Samuel Thomas},
  title = {{Subspace Gaussian mixture models for speech recognition}},
  booktitle = icassp,
  year = {2010},
  file = {Povey10.pdf:Speech_reco/iVectors/Povey10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.10.18}
}

@PHDTHESIS{Preti08,
  author = {Alexandre Preti},
  title = {Surveillance de réseaux professionnels de communication par la reconnaissance
	du locuteur},
  school = {Université d'Avignon et des Pays de Vaucluse},
  year = {2008},
  owner = {antho},
  timestamp = {2009.06.05}
}

@ARTICLE{Preti07_b,
  author = {Alexandre Preti and Jean-Francois Bonastre and Francois Capman},
  title = {{A continuous unsupervised adaptation method for speaker verification}},
  journal = {Innovations in e-learning, instruction technology, assessment, and
	engineering education},
  year = {2007},
  volume = {1},
  pages = {461},
  editor = {Springer},
  file = {Preti07_b.pdf:Speaker_reco/Unsupervised/Preti07_b.pdf:PDF},
  isbn = {1402062613},
  publisher = {Springer Verlag}
}

@INPROCEEDINGS{Preti07,
  author = {Alexandre Preti and Jean-Francois Bonastre and Driss Matrouf and
	Francois Capman and Bertrand Ravera},
  title = {{Confidence measure based unsupervised target model adaptation for
	speaker verification}},
  booktitle = interspeech,
  year = {2007},
  pages = {754--757},
  file = {Preti07.pdf:Speaker_reco/Unsupervised/Preti07.pdf:PDF}
}

@INPROCEEDINGS{Pretti06,
  author = {Alexandre Preti and Nicolas Scheffer and Jean-Francois Bonastre},
  title = {{Discriminant approaches for GMM-based speaker detection systems}},
  booktitle = mmua,
  year = {2006},
  file = {Pretti06.pdf:Speaker_reco/Adaptation/MMIE/Pretti06.pdf:PDF}
}

@BOOK{Prince12,
  title = {{Computer Vision: Models Learning and Inference}},
  publisher = {{Cambridge University Press}},
  year = {2012},
  author = {Simon J.D. Prince},
  note = {In press},
  file = {Prince12.pdf:Outils/Prince12.pdf:PDF}
}

@INPROCEEDINGS{Prince07,
  author = {Simon J.D. Prince and James H. Elder},
  title = {{Probabilistic linear discriminant analysis for inferences about
	identity}},
  booktitle = {International Conference on Computer Vision},
  year = {2007},
  pages = {1--8},
  organization = {IEEE},
  file = {Prince07.pdf:Image/Prince07.pdf:PDF},
  issn = {1550-5499}
}

@ARTICLE{Prince08,
  author = {Simon J.D. Prince and James Warrell and Jonathan Elder and Fatima
	Felisberti},
  title = {{Tied factor analysis for face recognition across large pose differences}},
  journal = pami,
  year = {2008},
  volume = {30},
  pages = {970--984},
  number = {6},
  file = {Prince08.pdf:Outils/PLDA/Prince08.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Przybocki07,
  author = {Mark A. Przybocki and Alvin F. Martin and Audrey N. Le},
  title = {{NIST} Speaker Recognition Evaluations Utilizing the Mixer Corpora
	- 2004, 2005, 2006},
  journal = {IEEE Transactions on Audio, Speech and Language Processing},
  year = {2007},
  volume = {15},
  pages = {1951--1959},
  number = {7},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Przybocki04,
  author = {Przybocki, M. and Martin, A.F.},
  title = {{NIST speaker recognition evaluation chronicles}},
  booktitle = odyssey,
  year = {2004},
  organization = {ISCA},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Pye00,
  author = {Pye, D.},
  title = {{Content-based methods for the management of digital music}},
  booktitle = icassp,
  year = {2000},
  volume = {4},
  organization = {IEEE; 1999},
  file = {Pye00.pdf:Divers/Music_Recognition/Pye00.pdf:PDF}
}

@INPROCEEDINGS{Pylkkonen04,
  author = {Janne Pylkkönen and Mikko Kurimo},
  title = {Duration Modeling Techniques for Continuous Speech Recognition},
  booktitle = icslp,
  year = {2004},
  pages = {385-388},
  address = {Jeju Island (Korea)},
  month = {October},
  abstract = {Phone durations play a significant part in the comprehension of speech.
	The duration information is still mostly disregarded in automatic
	speech recognizers due to the use of hidden Markov models (HMMs)
	which are deficient in modeling phone durations properly. Previous
	results have shown that using different approaches for explicit duration
	modeling have improved the isolated word recognition in English.
	However, a unified comparison between the methods has not been reported
	In this paper three techniques for explicit duration modeling are
	compared and evaluated in a large vocabulary continuous speech recognition
	task. The target language was Finnish, in which phone durations are
	especially important for proper understanding. The results show that
	the choice of the duration modeling technique depends on the speed
	requirements of the recognizer. The best technique required a slightly
	longer running time than without an explicit duration model, but
	achieved an 8% relative improvement to the letter error rate.},
  file = {Pylkkonen04.pdf:Speech_reco/Continuous/Pylkkonen04.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.04.02}
}

@INPROCEEDINGS{Quatieri00,
  author = {Quatieri, TF and Dunn, RB and Reynolds, DA and Campbell, JP and Singer,
	E.},
  title = {{Speaker recognition using G. 729 speech codec parameters}},
  booktitle = icassp,
  year = {2000},
  volume = {2},
  pages = {II1089--II1092},
  organization = {IEEE},
  file = {Quatieri00.pdf:Speaker_reco/Compression/Quatieri00.pdf:PDF},
  isbn = {0780362934}
}

@INPROCEEDINGS{Quenot92,
  author = {Georges M. Quenot},
  title = {{The orthogonal algorithm for optical flow detection using dynamic
	programming}},
  booktitle = icassp,
  year = {1992},
  volume = {3},
  file = {Quenot92.pdf:Video/Quenot92.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Quene08,
  author = {Hugo Quen{\'e}},
  title = {Multilevel modeling of between-speaker and within-speaker variation
	in spontaneous speech tempo},
  journal = jasa,
  year = {2008},
  volume = {123},
  pages = {1104},
  file = {Quene08.pdf:Divers/Quene08.pdf:PDF}
}

@INPROCEEDINGS{Quing06,
  author = {Xi-Ke Quing and Ke Chen},
  title = {On use of GMM for Multilingual speaker verification : An empirical
	study},
  booktitle = icslp,
  year = {2006},
  address = {Westin},
  month = {September},
  owner = {larcher},
  timestamp = {2007.02.08},
  url = {http://speech.cis.pku.edu.cn}
}

@ARTICLE{Rabiner89,
  author = {Lawrence R. Rabiner},
  title = {{A Tutorial on Hidden Markov Models and Selected Applications in
	Speech Recognition}},
  journal = ieee,
  year = {1989},
  volume = {77},
  pages = {257-286},
  number = {2},
  month = {February},
  abstract = {This tutorial provides an overview of the basic theory of hidden Markov
	models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and
	gives practical details on methods of implementation of the theory
	along with a description of selected applications of the theory to
	distinct problems in speech recognition. Results from a number of
	original sources are combined to provide a single source of acquiring
	the background required to pursue further this area of research.
	The author first reviews the theory of discrete Markov chains and
	shows how the concept of hidden states, where the observation is
	a probabilistic function of the state, can be used effectively. The
	theory is illustrated with two simple examples, namely coin-tossing,
	and the classic balls-in-urns system. Three fundamental problems
	of HMMs are noted and several practical techniques for solving these
	problems are given. The various types of HMMs that have been studied,
	including ergodic as well as left-right models, are described},
  doi = {10.1109/5.18626},
  file = {Rabiner89.pdf:Speech_reco/Rabiner89.pdf:PDF},
  organization = {Proceedings of the IEEE},
  owner = {larcher},
  timestamp = {2006.03.28}
}

@ARTICLE{Rabiner78,
  author = {Lawrence R. Rabiner and Aaron E Rosenberg and Stephen E. Levinson},
  title = {{Considerations in dynamic time warping algorithms for discrete word
	recognition}},
  journal = tassp,
  year = {1978},
  volume = {26},
  pages = {575-582},
  number = {6},
  month = {December},
  abstract = {The technique of dynamic time warping for time registration of a reference
	and test utterance has found widespread use in the areas of speaker
	verification and discrete word recognition. As originally proposed,
	the algorithm placed strong constraints on the possible set of dynamic
	paths-namely it was assumed that the initial and final frames of
	both the test and reference utterances were in exact time synchrony.
	Because of inherent practical difficulties with satisfying the assumptions
	under which the above constraints are valid, we have considered some
	modifications to the dynamic time warping algorithm. In particular,
	an algorithm in which an uncertainty exists in the registration both
	for initial and final frames was studied. Another modification constrains
	the dynamic path to follow (within a given range) the path which
	is locally optimum at each frame. This modification tends to work
	well when the location of the final frame of the test utterance is
	significantly in error due to breath noise, etc. To test the different
	time warping algorithms a set of ten isolated words spoken by 100
	speakers was used. Probability density functions of the distances
	from each of the 100 versions of a word to a reference version of
	the word were estimated for each of three dynamic warping algorithms.
	From these data, it is shown that, based on a set of assumptions
	about the distributions of the distances, the warping algorithm that
	minimizes the overall probability of making a word error is the modified
	time warping algorithm with unconstrained endpoints. A discussion
	of this key result along with some ideas on where the other modifications
	would be most useful is included.},
  citeseerurl = {http://citeseer.ist.psu.edu/context/433909/0},
  file = {Rabiner78.pdf:Speech_reco/Word_reco/Rabiner78.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@ARTICLE{Radeau74,
  author = {Radeau, M. and Bertelson, P.},
  title = {{The after-effects of ventriloquism.}},
  journal = {QJ Exp Psychol},
  year = {1974},
  volume = {26},
  pages = {63--71},
  number = {1},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Raj01,
  author = {Bhiksha Raj and Joshua Migdal and Rita Singh},
  title = {{Distributed speech recognition with codec parameters}},
  booktitle = {Automatic Speech Recognition and Understanding, 2001. ASRU'01. IEEE
	Workshop on},
  year = {2001},
  pages = {127--130},
  organization = {IEEE},
  file = {Raj01.pdf:Speaker_reco/Compression/Raj01.pdf:PDF},
  isbn = {078037343X}
}

@INPROCEEDINGS{Raj06,
  author = {Bhiksha Raj and Madhsudana V. S. Shashanka and Paris Smaragdis},
  title = {{Latent Dirichlet decomposition for single channel speaker separation}},
  booktitle = icassp,
  year = {2006},
  pages = {821--824},
  file = {Raj06.pdf:LDA/Raj06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.10.26}
}

@INPROCEEDINGS{Rajagopalan98,
  author = {A. N. Rajagopalan and K. S. Kumar and J. Karlekar and R. Manivasakan
	M.M. Patil and U.B. Desai and P.G. Poonacha S. Chaudhuri},
  title = {Finding Faces in Photographs},
  booktitle = cv,
  year = {1998},
  pages = {640-645},
  month = {January},
  abstract = {Two new schemes are presented for finding human faces in a photograph.
	The first scheme approximates the unknown distributions of the face
	and the face-like manifolds wing higher order statistics (HOS). An
	HOS-based data clustering algorithm is also proposed. In the second
	scheme, the face to non-face and non-face to face transitions are
	learnt using a hidden Markov model (HMM). The HMM parameters are
	estimated corresponding to a given photograph and the faces are located
	by examining the optimal state sequence of the HMM. Experimental
	results are presented on the performance of both the schemes},
  doi = {10.1109/ICCV.1998.710785},
  file = {Rajagopalan98.pdf:Video/Face_detection/Rajagopalan98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.29}
}

@ARTICLE{Ramakrishnan98,
  author = {Sangeeta Ramakrishnan and Kenneth Rose and Allen Gersho},
  title = {Constrained-Storage Vector Quantization with a Universal Codebook},
  journal = tip,
  year = {1998},
  volume = {7},
  pages = {785-793},
  number = {6},
  abstract = {Many image compression techniques require the quantization of multiple
	vector sources with significantly different distributions. With vector
	quantization (VQ), these sources are optimally quantized using separate
	codebooks, which may collectively require an enormous memory space.
	Since storage is limited in most applications, a convenient way to
	gracefully trade between performance and storage is needed. Earlier
	work addressed this problem by clustering the multiple sources into
	a small number of source groups, where each group shares a codebook.
	We propose a new solution based on a size-limited universal codebook
	that can be viewed as the union of overlapping source codebooks.
	This framework allows each source codebook to consist of any desired
	subset of the universal code vectors and provides greater design
	flexibility which improves the storage-constrained performance. A
	key feature of this approach is that no two sources need be encoded
	at the same rate. An additional advantage of the proposed method
	is its close relation to universal, adaptive, finite-state and classified
	quantization. Necessary conditions for optimality of the universal
	codebook and the extracted source codebooks are derived. An iterative
	design algorithm is introduced to obtain a solution satisfying these
	conditions. Possible applications of the proposed technique are enumerated,
	and its effectiveness is illustrated for coding of images using finite-state
	vector quantization, multistage vector quantization, and tree-structured
	vector quantization},
  doi = {10.1109/83.679412},
  file = {Ramakrishnan98.pdf:Speaker_reco/VQ/Ramakrishnan98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.23}
}

@INPROCEEDINGS{Ramos06,
  author = {Daniel Ramos-Castro and Joaquin Gonzalez-Rodriguez and Javier Ortega-Garcia},
  title = {{Likelihood ratio calibration in a transparent and testable forensic
	speaker recognition framework}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--8},
  organization = {IEEE},
  file = {Ramos06.pdf:Calibration/Ramos06.pdf:PDF}
}

@INPROCEEDINGS{Reynolds03,
  author = {Douglas A. Reynolds},
  title = {{Channel robust speaker verification via feature mapping}},
  booktitle = icassp,
  year = {2003},
  volume = {2},
  file = {Reynolds03.pdf:Speaker_reco/FA/Reynolds03.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Reynolds97,
  author = {Douglas A. Reynolds},
  title = {Comparison of Background Normalization Methods for Text-Independent
	Speaker Verification},
  booktitle = eurospeech,
  year = {1997},
  volume = {2},
  pages = {963-966},
  address = {Rhodes, Greece},
  month = {September},
  abstract = {This paper compares two approaches to background model representation
	for a text-independent speaker verification task using Gaussian mixture
	models. We compare speaker-dependent background speaker sets to the
	use of a universal, speaker-independent background model (UBM). For
	the UBM, we describe how Bayesian adaptation can be used to derive
	claimant speaker models, providing a structure leading to significant
	computational savings during recognition. Experiments are conducted
	on the 1996 NIST Speaker Recognition Evaluation corpus and it is
	clearly shown that a system using a UBM and Bayesian adaptation of
	claimant models produces superior performance compared to speaker-dependent
	background sets or the UBM with independent claimant models. In addition,
	the creation and use of a telephone handset-type detector and a procedure
	called hnorm is also described which shows further, large improvements
	in verification performance, especially under the difficult mismatched
	handset conditions. This is believed to be the first use of applying
	a hand-set- type detector and explicit handset- type normalization
	for the speaker verification task.},
  owner = {larcher},
  timestamp = {2007.09.05}
}

@INPROCEEDINGS{Reynolds96,
  author = {Douglas A. Reynolds},
  title = {{The effects of handset variability on speaker recognitionperformance:
	experiments on the Switchboard corpus}},
  booktitle = icassp,
  year = {1996},
  volume = {1},
  file = {Reynolds96.pdf:Speaker_reco/Normalisation/Reynolds96.pdf:PDF}
}

@ARTICLE{Reynolds95_2,
  author = {Douglas A. Reynolds},
  title = {{Speaker identification and verification using Gaussian mixture speaker
	models}},
  journal = {Speech Communication},
  year = {1995},
  volume = {17},
  pages = {91--108},
  number = {1-2},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@ARTICLE{Reynolds94,
  author = {Douglas A. Reynolds},
  title = {Experimental evaluation of features for robust speaker identification},
  journal = {Speech and Audio Processing, IEEE Transactions on},
  year = {1994},
  volume = {2},
  pages = {639--643},
  number = {4},
  owner = {antho},
  timestamp = {2009.10.05}
}

@PHDTHESIS{Reynolds92,
  author = {Douglas A. Reynolds},
  title = {{A Gaussian mixture modeling approach to text-independent speaker
	identification}},
  school = {Georgia Institute of Technology},
  year = {1992},
  owner = {antho},
  timestamp = {2011.11.17}
}

@ARTICLE{Reynolds00,
  author = {Douglas A. Reynolds and Thomas F. Quatieri and Robert B. Dunn},
  title = {{Speaker Verification Using Adapted Gaussian Mixture Models}},
  journal = dsp,
  year = {2000},
  volume = {10},
  pages = {19-41},
  abstract = {In this paper we describe the major elements of MIT Lincoln Laboratory's
	Gaussian mixture model (GMM)-based speaker verification system used
	successfully in several NIST Speaker Recognition Evaluations (SREs).
	The system is built around the likelihood ratio test for verification,
	using simple but effective GMMs for likelihood functions, a universal
	background model (UBM) for alternative speaker representation, and
	a form of Bayesian adaptation to derive speaker models from the UBM.
	The development and use of a handset detector and score normalization
	to greatly improve verification performance is also described and
	discussed. Finally, representative performance benchmarks and system
	behavior experiments on NIST SRE corpora are presented.},
  booktitle = {Digital Signal Processing},
  doi = {10.1006/dspr.1999.0361},
  file = {Reynolds00.pdf:Speaker_reco/GMM-UBM/Reynolds00.pdf:PDF},
  keywords = {speaker recognition; Gaussian mixture models; likelihood ratio detector;
	universal background model; handset normalization; NIST evaluation},
  owner = {larcher},
  timestamp = {2009.10.05}
}

@ARTICLE{Reynolds95,
  author = {Douglas A. Reynolds and Richard C. Rose},
  title = {{Robust Text-Independent Speaker Identification Using Gaussian Mixture
	Speaker Models}},
  journal = tassp,
  year = {1995},
  volume = {3},
  pages = {72-83},
  number = {1},
  month = {January},
  abstract = {This paper introduces and motivates the use of Gaussian mixture models
	(GMM) for robust text-independent speaker identification. The individual
	Gaussian components of a GMM are shown to represent some general
	speaker-dependent spectral shapes that are effective for modeling
	speaker identity. The focus of this work is on applications which
	require high identification rates using short utterance from unconstrained
	conversational speech and robustness to degradations produced by
	transmission over a telephone channel. A complete experimental evaluation
	of the Gaussian mixture speaker model is conducted on a 49 speaker,
	conversational telephone speech database. The experiments examine
	algorithmic issues (initialization, variance limiting, model order
	selection), spectral variability robustness techniques, large population
	performance and comparisons to other speaker modeling techniques
	(uni-modal Gaussian, VQ codebook, tied Gaussian mixture, and radial
	basis functions). The Gaussian mixture speaker model attains 96.8%
	identification accuracy using 5 second clean speech utterance and
	80.8% accuracy using 15 second telephone speech utterances with a
	49 speaker population and is shown to outperform the other speaker
	modeling techniques on an identical 16 speaker telephone speech task.},
  doi = {10.1109/89.365379},
  file = {Reynolds95.pdf:Speaker_reco/GMM-UBM/Reynolds95.pdf:PDF},
  owner = {larcher},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Richardson08,
  author = {Fred S. Richardson and William M. Campbell},
  title = {{Language recognition with discriminative keyword selection}},
  booktitle = icassp,
  year = {2008},
  pages = {4145--4148},
  organization = {IEEE},
  file = {Richardson08.pdf:Language_reco/Richardson08.pdf:PDF},
  issn = {1520-6149}
}

@INPROCEEDINGS{Richiardi08,
  author = {Jonas Richiardi and Andrzej Drygajlo},
  title = {{Evaluation of speech quality measures for the purpose of speaker
	verification}},
  booktitle = odyssey,
  year = {2008},
  volume = {8},
  number = {32},
  pages = {170},
  file = {Richiardi08.pdf:Outils/Qualité/Richiardi08.pdf:PDF}
}

@ARTICLE{Richiardi06_b,
  author = {Jonas Richiardi and Andrzej Drygajlo and Plamen Prodanov},
  title = {{Confidence and reliability measures in speaker verification}},
  journal = {Journal of the Franklin Institute},
  year = {2006},
  volume = {343},
  pages = {574--595},
  number = {6},
  file = {Richiardi06_b.pdf:Speaker_reco/Useful_information/Richiardi06_b.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Richiardi07,
  author = {Jonas Richiardi and Krzysztof Kryszczuk and Andrzej Drygajlo},
  title = {{Quality measures in unimodal and multimodal biometric verification}},
  booktitle = {Proc. 15th European Conference on Signal Processing EUSIPCO},
  year = {2007},
  file = {Richiardi07.pdf:Outils/Qualité/Richiardi07.pdf:PDF}
}

@INPROCEEDINGS{Richiardi06,
  author = {Jonas Richiardi and Plamen Prodanov and Andrzej Drygajlo},
  title = {{Speaker verification with confidence and reliability measures}},
  booktitle = icassp,
  year = {2006},
  volume = {1},
  pages = {I--I},
  organization = {IEEE},
  file = {Richiardi06.pdf:quality_speaker-reco/Richiardi06.pdf:PDF}
}

@TECHREPORT{Riedmiller94,
  author = {Martin Riedmiller and Heinrich Braun},
  title = {{Rprop-description and implementation details}},
  institution = {Institut fur Logik Komplexitat und Deduktionssysteme},
  year = {1994},
  file = {Riedmiller94.pdf:Outils/RPROP/Riedmiller94.pdf:PDF},
  owner = {antho},
  timestamp = {2011.01.13}
}

@INPROCEEDINGS{Riedmiller92,
  author = {Martin Riedmiller and Heinrich Braun},
  title = {{RPROP-A fast adaptive learning algorithm}},
  booktitle = iscis,
  year = {1992},
  organization = {Citeseer},
  file = {Riedmiller92.pdf:Outils/RPROP/Riedmiller92.pdf:PDF}
}

@PHDTHESIS{Robertribes95,
  author = {Jordi Robert-Ribes},
  title = {{Mod{\`e}les d'int{\'e}gration audiovisuelle de signaux linguistiques}},
  school = {Institut National Polytechnique de Grenoble (INPG)},
  year = {1995},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Rodriguez07,
  author = {Rodriguez, R.V. and Evans, N.W.D. and Lewis, R.P. and Fauve, B. and
	Mason, J.S.D.},
  title = {{An experimental study on the feasibility of footsteps as a biometric}},
  booktitle = eusipco,
  year = {2007},
  file = {Rodriguez07.pdf:Divers/Footstep/Rodriguez07.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Rodriguez08,
  author = {Ruben V. Rodr{\'\i}guez and Richard P. Lewis and John S.D. Mason
	and Nicholas W.D. Evans},
  title = {{Footstep recognition for a samrt home environment}},
  journal = {International Journal of Smart Home},
  year = {2008},
  volume = {2},
  pages = {95--110},
  number = {2},
  file = {Rodriguez08.pdf:Divers/Footstep/Rodriguez08.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Rogozan98,
  author = {Rogozan, A. and Del{\'e}glise, P.},
  title = {{Adaptive fusion of acoustic and visual sources for automatic speech
	recognition}},
  journal = {Speech Communication},
  year = {1998},
  volume = {26},
  pages = {149--161},
  number = {1-2},
  file = {Rogozan98.pdf:Ventriloquie/Rogozan98.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Rosenberg92,
  author = {Aaron E. Rosenberg and Joel DeLong and Chin-Hui Lee and Biing-Hwang
	Juang and Frank K. Soong},
  title = {{The use of cohort normalized scores for speaker verification}},
  booktitle = icslp,
  year = {1992},
  pages = {599--602},
  owner = {antho},
  timestamp = {2008.11.27}
}

@INPROCEEDINGS{Rosenberg91,
  author = {A. E. Rosenberg and C.H. Lee and S. Gokcen},
  title = {{Connected word talker verification using whole word Hidden Markov
	Models}},
  booktitle = icassp,
  year = {1991},
  pages = {381--384},
  file = {Rosenberg91.pdf:Speaker_reco/Text_dependent/Rosenberg91.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Rosenberg90,
  author = {Aaron E. Rosenberg and Chin Hui Lee and Frank Kao Ping Soong},
  title = {{Sub-Word Unit Talker verification Using Hidden Markov Models}},
  booktitle = icassp,
  year = {1990},
  address = {Albuquerque (USA)},
  abstract = {A talker verification system based on characterizing talker utterances
	as sequences of subword units represented by hidden Markov models
	(HMMs) was implemented and tested. Two types of subword units were
	studied: phonelike units (PLUs) and acoustic segment units (ASUs).
	PLUs are based on phonetic transcriptions of spoken utterances and
	ASUs are extracted directly from the acoustic signal without use
	of any linguistic knowledge. The ASU representation has the advantage
	of not requiring transcriptions of training utterances. Verification
	performance was evaluated on a 100-talker database of 20000 isolated
	digit utterances. The experiments show only small differences in
	performance between PLU- and ASU-based representations. Overall,
	the verification equal-error rate is approximately 7 to 8% for one-digit
	test utterances (approximately 0.5 s in duration) and 1% or less
	for seven-digit test utterances (approximately 3.5 s in duration).
	In addition, a technique for updating models, using data from current
	test utterances, was devised and implemented. Using this adaptation
	technique, the error rate falls to 6% for one-digit utterances and
	less than 0.5% for seven-digit utterances. The experiment confirms
	that excellent verification performance can be obtained using HMMs
	of subword units},
  doi = {10.1109/ICASSP.1990.115621},
  file = {Rosenberg90.pdf:Speaker_reco/Text_dependent/Rosenberg90.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.18}
}

@INPROCEEDINGS{Rosenberg96,
  author = {Aaron E. Rosenberg and Srinivasan Parthasarathy},
  title = {{Speaker background models for connected digit password speaker verification}},
  booktitle = icassp,
  year = {1996},
  volume = {1},
  pages = {81--84},
  organization = {IEEE},
  file = {Rosenberg96.pdf:Speaker_reco/Text_dependent/Rosenberg96.pdf:PDF}
}

@ARTICLE{Rosenberg00,
  author = {Aaron E. Rosenberg and Olivier Siohan and Parthasarathy, S.},
  title = {{Small group speaker identification with common password phrases}},
  journal = {{Speech communication}},
  year = {2000},
  volume = {31},
  pages = {131--140},
  number = {2-3},
  file = {Rosenberg00.pdf:Speaker_reco/Text_dependent/Rosenberg00.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Ross01,
  author = {Arun Ross and Anil Jain and Jian-Zhong Qian},
  title = {{Information Fusion in Biometrics}},
  booktitle = avbpa,
  year = {2001},
  pages = {354-359},
  address = {Halmstad (Sweden)},
  month = {june},
  abstract = {User verification systems that use a single biometric indica- 
	
	tor often have to contend with noisy sensor data, restricted degrees
	of
	
	freedom and unacceptable error rates. Attempting to improve the per-
	
	formance of individual matchers in such situations may not prove to
	be
	
	effective because of these inherent problems. Multimodal biometric
	sys-
	
	tems seek to alleviate some of these drawbacks by providing multiple
	
	evidences of the same identity. These systems also help achieve an
	in-
	
	crease in performance that may not be possible by using a single biomet-
	
	ric indicator. This paper addresses the problem of information fusion
	in
	
	verification systems. Experimental results on combining three biometric
	
	modalities (face, fingerprint and hand geometry) are also presented.},
  file = {Ross01.pdf:Audio-Video/Ross01.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.24}
}

@INPROCEEDINGS{Ross04,
  author = {Arun Ross and Anil K. Jain},
  title = {{Multimodal biometrics : an overview}},
  booktitle = eusipco,
  year = {2004},
  address = {Vienna (Austria)},
  abstract = {Unimodal biometric systems have to contend with a vari-
	
	ety of problems such as noisy data, intra-class variations, re-
	
	stricted degrees of freedom, non-universality, spoof attacks,
	
	and unacceptable error rates. Some of these limitations can
	
	be addressed by deploying multimodal biometric systems that
	
	integrate the evidence presented by multiple sources of in-
	
	formation. This paper discusses the various scenarios that
	
	are possible in multimodal biometric systems, the levels of
	
	fusion that are plausible and the integration strategies that
	
	can be adopted to consolidate information. We also present
	
	several examples of multimodal systems that have been de-
	
	scribed in the literature.},
  file = {Ross04.pdf:Audio-Video/Ross04.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.24}
}

@ARTICLE{Rouas05,
  author = {Jean-Luc Rouas and Jérôme Farinas and François Pellegrino and Régine
	André-Obrecht},
  title = {{Rhythmic unit extraction and modelling for automatic language identification
	}},
  journal = {Speech Communication},
  year = {2005},
  volume = {47},
  pages = {436--456},
  number = {4},
  note = {?OLDEditeur(Speech Communication, Elsevier)},
  address = {http://www.elsevier.com/},
  file = {Rouas05.pdf:Language_reco/Rouas05.pdf:PDF},
  keywords = {SAMOVA ART.ps IAL},
  language = {anglais},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05},
  url = {http://www.sciencedirect.com/science/article/B6V1C-4G94G8D-1/2/858e586329f1f2fe156c76a54d67ed32}
}

@INPROCEEDINGS{Rouvier09,
  author = {Mickael Rouvier and Driss Matrouf and Georges Linares},
  title = {{Factor Analysis for Audio-based Video Genre Classification}},
  booktitle = interspeech,
  year = {2009},
  abstract = {Statistic classifiers operate on features that generally include both
	usefull and useless information. These two types of information are
	difficult to separate in the feature domain. Recently, a new paradigm
	based on a Latent Factor Analysis proposed a model decomposition
	into usefull and useless components. This method was successfully
	applied to speaker and language recognition tasks. In this paper,
	we study the use of Latent Factor Analysis for video genre classification
	by using only the audio channel. We propose a classification method
	based on short-term cepstral features and GMM or SVM classifiers,
	that are combined to Factor Analysis. Experiments are conducted on
	a corpus composed of 5 types of video (musics, commercials, cartoons,
	movies and news). The relative classification error reduction obtained
	by using the best factor analysis configuration with respect to baseline
	system (GMM-UBM) is about 56%, corresponding to a correct identification
	rate of about 90%},
  owner = {antho},
  timestamp = {2009.06.25}
}

@ARTICLE{Rowley98,
  author = {Henry A. Rowley and Shumeet Baluja and Takeo Kanade},
  title = {{Neural network-based face detection}},
  journal = pami,
  year = {1998},
  volume = {20},
  pages = {23-38},
  number = {1},
  abstract = {We present a neural network-based upright frontal face detection system.
	A retinally connected neural network examines small windows of an
	image and decides whether each window contains a face. The system
	arbitrates between multiple networks to improve performance over
	a single network. We present a straightforward procedure for aligning
	positive face examples for training. To collect negative examples,
	we use a bootstrap algorithm, which adds false detections into the
	training set as training progresses. This eliminates the difficult
	task of manually selecting nonface training examples, which must
	be chosen to span the entire space of nonface images. Simple heuristics,
	such as using the fact that faces rarely overlap in images, can further
	improve the accuracy. Comparisons with several other state-of-the-art
	face detection systems are presented, showing that our system has
	comparable performance in terms of detection and false-positive rates},
  doi = {10.1109/34.655647},
  file = {Rowley98.pdf:Video/Face_detection/Rowley98.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@INCOLLECTION{Rusko07,
  author = {Milan Rusko and Radovan Garabik},
  title = {{Corpus of Spoken Slovak Language}},
  booktitle = {Citeseer},
  publisher = {Citeseer},
  year = {2007},
  file = {Rusko07.pdf:Base_de_donnees/Rusko07.pdf:PDF}
}

@ARTICLE{Rusko04,
  author = {Rusko, M. and Trnka, M. and Dar{\v{z}}{\'a}g{\'\i}n, S. and Cer{\v{n}}ak,
	M.},
  title = {{Slovak speech database for experiments and application building
	in unit-selection speech synthesis}},
  journal = {Text, Speech and Dialogue},
  year = {2004},
  volume = {1},
  pages = {457--464},
  booktitle = {Text, Speech and Dialogue},
  file = {Rusko04.pdf:Base_de_donnees/Rusko04.pdf:PDF},
  organization = {Springer}
}

@INPROCEEDINGS{Saeed06,
  author = {Usman Saeed and Federico Matta and Jean-Luc Dugelay},
  title = {{Person recognition based on head and mouth dynamics}},
  booktitle = mmsp,
  year = {2006},
  address = {Victoria (Canada)},
  month = {October},
  owner = {larcher},
  timestamp = {2006.07.05}
}

@INPROCEEDINGS{Saeta04,
  author = {Javier R. Saeta and Javier Hernando},
  title = {{Model Quality Evaluation during Enrolment for Speaker Verification}},
  booktitle = interspeech,
  year = {2004},
  file = {Saeta04.pdf:quality_speaker-reco/Saeta04.pdf:PDF}
}

@ARTICLE{Sakoe78,
  author = {Hiroaki Sakoe and Seibi Chiba},
  title = {{Dynamic Programming Algorithm Optimization for Spoken Word Recognition}},
  journal = tassp,
  year = {1978},
  volume = {26},
  pages = {43-49},
  number = {1},
  month = {February},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@BOOK{Sanderson08_b,
  title = {{Biometric Person Recognition: Face, Speech and Fusion.}},
  publisher = {VDM-Verlag},
  year = {2008},
  author = {Conrad Sanderson},
  owner = {antho},
  timestamp = {2009.04.29}
}

@ARTICLE{Sanderson07_b,
  author = {Conrad Sanderson and Abbas Bigdeli and Ting Shan and Shaokang Chen
	and Erik Berglund and Brian C. Lovell},
  title = {{Intelligent CCTV for Mass Transport Security: Challenges and Opportunities
	for Video and Face Processing}},
  journal = {ELCVIA},
  year = {2007},
  volume = {6},
  pages = {30--41},
  number = {0},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Sanderson08,
  author = {Conrad Sanderson and Danny Gibbins and Stephen Searle},
  title = {{On statistical approaches to target silhouette classification in
	difficult conditions}},
  journal = dsp,
  year = {2008},
  volume = {18},
  pages = {375--390},
  number = {3},
  file = {Sanderson08.pdf:Image/Sanderson08.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Sanderson06,
  author = {Conrad Sanderson and Simon Guenter},
  title = {{Short Text Authorship Attribution via Sequence Kernels, Markov Chains
	and Author Unmasking: An Investigation}},
  booktitle = {International Conference on Empirical Methods in Natural Language
	Processing (EMNLP)},
  year = {2006},
  address = {Sydney, Australia},
  owner = {antho},
  timestamp = {2008.10.24}
}

@ARTICLE{Sanderson04,
  author = {Conrad Sanderson and Kuldip K. Paliwal},
  title = {{Identity verification using speech and face information}},
  journal = dsp,
  year = {2004},
  volume = {14},
  pages = {449--480},
  number = {5},
  file = {Sanderson04.pdf:Image/Sanderson04.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Sanderson05,
  author = {Conrad Sanderson and Marc Saban and Yongsheng Gao},
  title = {{On local features for GMM based face verification}},
  booktitle = {International Conference on Information Technology and Applications},
  year = {2005},
  pages = {638--643},
  file = {Sanderson05.pdf:Image/Parametres_locaux/Sanderson05.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Sanderson07,
  author = {Conrad Sanderson and Ting Shang and Brian C. Lovell},
  title = {{Towards Pose-Invariant 2D Face Classification for Surveillance}},
  journal = {Lectures Notes in Computer Science},
  year = {2007},
  volume = {4778},
  pages = {276},
  owner = {antho},
  publisher = {Springer},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Kumar10,
  author = {Santosh Kumar, CP and Haizhou Li and Rong Tong and Pavel Matejka
	and Lukas Burget and Jan Cernocky},
  title = {{Tuning phone decoders for language identification}},
  booktitle = icassp,
  year = {2010},
  pages = {5010--5013},
  organization = {IEEE},
  file = {Kumar10.pdf:Language_reco/Kumar10.pdf:PDF},
  issn = {1520-6149}
}

@INPROCEEDINGS{Saon04,
  author = {Saon, G. and Dharanipragada, S. and Povey, D. and Center, I.B.M.T.J.W.R.
	and Yorktown Heights, NY},
  title = {{Feature space gaussianization}},
  booktitle = icassp,
  year = {2004},
  volume = {1},
  file = {Saon04.pdf:Speaker_reco/Gaussianization/Saon04.pdf:PDF}
}

@ARTICLE{Saslove80,
  author = {Saslove, H. and Yarmey, AD},
  title = {{Long-term auditory memory: speaker identification.}},
  journal = {The Journal of applied psychology},
  year = {1980},
  volume = {65},
  pages = {111},
  number = {1},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Satoh00,
  author = {Shin'ichi Satoh},
  title = {{Comparative evaluation of face sequence matching for content-based
	video access}},
  booktitle = {IEEE International Conference on Automatic Face and Gesture Recognition},
  year = {2000},
  pages = {163--168},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Savic90,
  author = {Michael Savic and Sunil K. Gupta},
  title = {{Variable parameter speaker verification system based on hiddenMarkov
	modeling}},
  booktitle = icassp,
  year = {1990},
  pages = {281--284},
  file = {Savic90.pdf:Speaker_reco/Text_dependent/Savic90.pdf:PDF}
}

@PHDTHESIS{Scheffer06,
  author = {Nicolas Scheffer},
  title = {{Structuration de l'espace acoustique par le mod\`eles g\'en\'erique
	pour la v\'erification du locuteurs}},
  school = {Universit\'e d'Avignon et des Pays de Vaucluse},
  year = {2006},
  owner = {antho},
  timestamp = {2008.11.12}
}

@INPROCEEDINGS{Scheffer06_b,
  author = {Nicolas Scheffer and Jean-Francois Bonastre},
  title = {UBM-GMM Driven discriminative approach for speaker verification},
  booktitle = odyssey,
  year = {2006},
  file = {Scheffer06_b.pdf:Speaker_reco/GMM-UBM/Scheffer06_b.pdf:PDF},
  owner = {antho},
  timestamp = {2010.04.30}
}

@INPROCEEDINGS{Scheffer05,
  author = {Nicoals Scheffer and Jean-Fran{\c c}ois Bonastre},
  title = {{Speaker Detection Using Acoustic Event Sequences}},
  booktitle = eurospeech,
  year = {2005},
  address = {Lisboa (Portugal)},
  file = {Scheffer05.pdf:Speaker_reco/GMM-UBM/Scheffer05.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.06.21}
}

@INPROCEEDINGS{Scheffer11,
  author = {Nicolas Scheffer and Yun Lei and Luciana Ferrer},
  title = {{Factor analysis back ends for MLLR transforms in speaker recognition}},
  booktitle = interspeech,
  year = {2011},
  pages = {257--260},
  file = {Scheffer11.pdf:Speaker_reco/FA/Scheffer11.pdf:PDF}
}

@INPROCEEDINGS{Scheffer09,
  author = {Nicolas Scheffer and Robbie Vogt and Sachin Kajarekar and Jason Pelecanos},
  title = {{Combination strategies for a factor analysis phone-conditioned speaker
	verification system}},
  booktitle = {Proceedings of the 2009 IEEE International Conference on Acoustics,
	Speech and Signal Processing-Volume 00},
  year = {2009},
  pages = {4053--4056},
  organization = {IEEE Computer Society},
  file = {Scheffer09.pdf:Speaker_reco/FA/Scheffer09.pdf:PDF}
}

@INPROCEEDINGS{Schwartz84,
  author = {Schwartz, R. and Chow, Y. and Roucos, S. and Krasner, M. and Makhoul,
	J. and Beranek, B. and Inc, N. and Cambridge, MA},
  title = {{Improved hidden Markov modeling of phonemes for continuous speech
	recognition}},
  booktitle = icassp,
  year = {1984},
  volume = {9},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Schwarz06,
  author = {Schwarz, P. and Matejka, P. and Cernocky, J.},
  title = {{Hierarchical structures of neural networks for phoneme recognition}},
  booktitle = icassp,
  year = {2006},
  volume = {1},
  file = {Schwarz06.pdf:Parametrisation/Schwarz06.pdf:PDF}
}

@INPROCEEDINGS{Schwerdt00,
  author = {Karl Schwerdt and James L. Crowley},
  title = {{Robust face tracking using color}},
  booktitle = {IEEE International Conference on Automatic Face and Gesture Recognition},
  year = {2000},
  pages = {90-95},
  month = {March},
  abstract = {We discuss a new robust tracking technique applied to histograms of
	intensity-normalized color. This technique supports a video codec
	based on orthonormal basis coding. Orthonormal basis coding can be
	very efficient when the images to be coded have been normalized in
	size and position. However an imprecise tracking procedure can have
	a negative impact on the efficiency and the quality of reconstruction
	of this technique, since it may increase the size of the required
	basis space. The face tracking procedure described in this paper
	has certain advantages, such as greater stability, higher precision,
	and less jitter, over conventional tracking techniques using color
	histograms. In addition to those advantages, the features of the
	tracked object such as mean and variance are mathematically describable},
  doi = {10.1109/AFGR.2000.840617},
  owner = {larcher},
  timestamp = {2006.05.09}
}

@INPROCEEDINGS{Senoussaoui11,
  author = {Mohammed Senoussaoui and Patrick Kenny and Niko Brummer and Edward
	de Villiers and Pierre Dumouchel},
  title = {{Mixture of PLDA models in I-vector space for gender independent
	speaker recognition}},
  booktitle = interspeech,
  year = {2011},
  file = {Senoussaoui11.pdf:Speaker_reco/PLDA/Senoussaoui11.pdf:PDF},
  journal = {Proceed. of INTERSPEECH 2011}
}

@INPROCEEDINGS{Senoussaoui10,
  author = {Mohammed Senoussaoui and Patrick Kenny and Najim Dehak and Pierre
	Dumouchel},
  title = {{An i-vector extractor suitable for speaker recognition with both
	microphone and telephone speech}},
  booktitle = odyssey,
  year = {2010},
  file = {Senoussaoui10.pdf:Speaker_reco/FA/I-Vector/Senoussaoui10.pdf:PDF}
}

@INPROCEEDINGS{Senoussaoui11_a,
  author = {Mohammed Senoussaoui and Patrick Kenny and Pierre Dumouchel and Fabio
	Castaldo},
  title = {{Well-calibrated heavy tailed bayesian speaker verification for microphone
	speech}},
  booktitle = icassp,
  year = {2011},
  pages = {4824--4827},
  file = {Senoussaoui11_a.pdf:Speaker_reco/FA/I-Vector/Senoussaoui11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@ARTICLE{Seo01,
  author = {Changwoo Seo and Ki Yong Lee and Joohun Lee},
  title = {{GMM based on local PCA for speaker identification}},
  journal = {Electronics Letters},
  year = {2001},
  volume = {37},
  pages = {1486--1488},
  number = {24},
  file = {Seo01.pdf:Parametrisation/Seo01.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.07}
}

@BOOK{Shafran07,
  title = {{Multi-stream Fusion for Speaker Classification}},
  publisher = {Springer},
  year = {2007},
  author = {Izhak Shafran},
  pages = {298--312},
  file = {Shafran07.pdf:Speaker_reco/Divers/Shafran07.pdf:PDF},
  journal = {Speaker Classification I}
}

@ARTICLE{Shao08,
  author = {Xu Shao and Jon Barker},
  title = {{Stream weight estimation for multistream audio-visual speech recognition
	in a multispeaker environment}},
  journal = {Speech Commun.},
  year = {2008},
  volume = {50},
  pages = {337--353},
  number = {4},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.specom.2007.11.002},
  file = {Shao08.pdf:Audio-Video/Shao08.pdf:PDF},
  issn = {0167-6393},
  publisher = {Elsevier Science Publishers B. V.}
}

@INPROCEEDINGS{Shao05,
  author = {Shao, X. and Maddage, NC and Xu, C. and Kankanhalli, MS},
  title = {{Automatic music summarization based on music structure analysis}},
  booktitle = icassp,
  year = {2005},
  volume = {2},
  file = {Shao05.pdf:Divers/Music_Recognition/Shao05.pdf:PDF}
}

@INPROCEEDINGS{Sharma96,
  author = {Manish Sharma and Richard Mammone},
  title = {{Subword-based text-dependent speaker verification system with user-selectable
	passwords}},
  booktitle = icassp,
  year = {1996},
  address = {Atlanta (USA)},
  abstract = {A subword-based, text-dependent speaker verification system that embodies
	the capability of user-selectable passwords (ideally, with no constraints
	on the choice of vocabulary words or the language) is presented.
	A novel automatic speech segmentation procedure, called the "blind"
	segmentation, is also introduced. This algorithm segments speech
	without any linguistic knowledge and makes the subword modeling of
	the user-selectable password realizable in the proposed system. The
	subword modeling is done using the neural tree networks (NTNs). The
	NTN is a hierarchical classifier that combines the properties of
	decision trees and feed-forward neural networks. The proposed system
	also takes advantage of such concepts as the multiple classifier
	fusion and data resampling to successfully boost the system performance},
  doi = {10.1109/ICASSP.1996.540298},
  file = {Sharma96.pdf:Speaker_reco/Text_dependent/Sharma96.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@INPROCEEDINGS{Shen06,
  author = {Wade Shen and William Campbell and Terry Gleason and Doug Reynolds
	and Elliot Singer},
  title = {{Experiments with lattice-based PPRLM language identification}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--6},
  organization = {IEEE},
  file = {Shen06.pdf:Language_reco/Shen06.pdf:PDF}
}

@INPROCEEDINGS{Shen07,
  author = {Wade Shen and Douglas A. Reynolds},
  title = {{Improving Phonotactic Language Recognition with Acoustic Adaptation}},
  booktitle = interspeech,
  year = {2007},
  pages = {358--361},
  file = {Shen07.pdf:Language_reco/Shen07.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.22}
}

@INPROCEEDINGS{Shi94,
  author = {Jianbo Shi and Carlo Tomasi},
  title = {{Good features to track}},
  booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  year = {1994},
  pages = {593--600},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Shimodaira01,
  author = {Hiroshi Shimodaira and Ken\-ichi Noma and Mitsuru Nakai and Shigeki
	Sagayama},
  title = {{Dynamic Time-Alignment Kernel in Support Vector Machine}},
  booktitle = {Neural Information Processing Systems},
  year = {2001},
  address = {Vancouver},
  month = {December},
  abstract = {A new class of Support Vector Machine (SVM) that is applicable to
	sequential-pattern recognition such as speech recognition is developed
	by incorporating an idea of non-linear time alignment into the kernel
	function. Since the time-alignment operation of sequential pattern
	is embedded in the new kernel function, standard SVM training and
	classification algorithms can be employed without further modifications.
	The proposed SVM (DTAK-SVM) is evaluated in speaker-dependent speech
	recognition experiments of hand-segmented phoneme recognition. Preliminary
	experimental results show comparable recognition performance with
	hidden Markov models (HMMs).},
  owner = {larcher},
  timestamp = {2007.02.08}
}

@ARTICLE{Shlens05,
  author = {Johnaton Shlens},
  title = {A tutorial on principal component analysis},
  journal = {Systems Neurobiology Laboratory, University of California at San
	Diego},
  year = {2005},
  file = {Shlens05.pdf:Outils/PCA/Shlens05.pdf:PDF},
  owner = {antho},
  publisher = {Citeseer},
  timestamp = {2011.09.28}
}

@INPROCEEDINGS{Shriberg08,
  author = {Shriberg, E. and Graciarena, M. and Bratt, H. and Kathol, A. and
	Kajarekar, S. and Jameel, H. and Richey, C. and Goodman, F.},
  title = {{Effects of Vocal Effort and Speaking Style on Text-Independent Speaker
	Verification}},
  booktitle = interspeech,
  year = {2008},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/FA/Shriberg08.pdf:PDF},
  journal = {Proc. of Interspeech, Brisbane, Australia}
}

@INPROCEEDINGS{Shriberg09,
  author = {Elisabeth Shriberg and Sachin Kajarekar and Nicolas Scheffer},
  title = {{Does Session Variability Compensation in Speaker Recognition Model
	Intrinsic Variation Under Mismatched Conditions?}},
  booktitle = interspeech,
  year = {2009},
  file = {Shriberg09.PDF:Speaker_reco/Variability/Shriberg09.PDF:PDF}
}

@INPROCEEDINGS{Shriberg11_a,
  author = {Elizabeth Shriberg and Andreas Stolcke},
  title = {{Language-independent constrained cepstral features for speaker recognition}},
  booktitle = icassp,
  year = {2011},
  pages = {5296--5299},
  file = {Shriberg11_a.pdf:Speaker_reco/Phonetic/Shriberg11_a.pdf:PDF},
  owner = {antho},
  timestamp = {2011.06.08}
}

@INPROCEEDINGS{Shum10,
  author = {Stephen Shum and Najim Dehak and Reda Dehak and James R. Glass},
  title = {{Unsupervised speaker adaptation based on the cosine similarity for
	text-independent speaker verification}},
  booktitle = odyssey,
  year = {2010},
  file = {Shum10.pdf:Speaker_reco/Unsupervised/Shum10.pdf:PDF}
}

@INPROCEEDINGS{Sierra10,
  author = {Gabriel H. Sierra and Jean-Francois Bonastre and Driss Matrouf and
	Jose R. Calvo},
  title = {{Topological representation of speech for speaker recognition}},
  booktitle = interspeech,
  year = {2010},
  pages = {2134--2137},
  file = {Sierra10.PDF:Speaker_reco/Divers/Sierra10.PDF:PDF},
  owner = {antho},
  timestamp = {2010.10.07}
}

@INPROCEEDINGS{Singer03,
  author = {Singer, E. and Torres-Carrasquillo, PA and Gleason, TP and Campbell,
	WM and Reynolds, D.A.},
  title = {{Acoustic, Phonetic, and Discriminative Approaches to Automatic Language
	Identification}},
  booktitle = eurospeech,
  year = {2003},
  pages = {1345--1348},
  organization = {ISCA},
  file = {Singer03.pdf:Language_reco/Singer03.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Siracusa07,
  author = {Michael R. Siracusa and John W. Fisher},
  title = {{Dynamic dependency tests for audio visual speaker association}},
  booktitle = icassp,
  year = {2007},
  address = {Hawa\"i (USA)},
  month = {april},
  abstract = {We formulate the problem of audio-visual speaker association as a
	dynamic dependency test. That is, given an audio stream and multiple
	video streams, we wish to determine their dependancy structure as
	it evolves over time. To this end, we propose the use of a hidden
	factorization Markov model in which the hidden state encodes a finite
	number of possible dependency structures. Each dependency structure
	has an explicit semantic meaning, namely "who is speaking.'' This
	model takes advantage of both structural and parametric changes associated
	with changes in speaker. This is contrasted with standard sliding
	window based dependence analysis. Using this model we obtain state-of-the-art
	performance on an audio-visual association task without benefit of
	training data.},
  owner = {larcher},
  timestamp = {2007.05.14}
}

@ARTICLE{Sivakumaran03,
  author = {Sivakumaran, P. and Aladin Ariyaeeinia and Loomes, MJ},
  title = {{Sub-band based text-dependent speaker verification}},
  journal = {Speech Communication},
  year = {2003},
  volume = {41},
  pages = {485--509},
  number = {2-3},
  file = {Sivakumaran03.pdf:Speaker_reco/Text_dependent/Sivakumaran03.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Slaney00,
  author = {Malcolm Slaney and Michele Covell},
  title = {{FaceSync: A Linear Operator for Measuring Synchronization of Video
	Facial Images and Audio Tracks}},
  booktitle = {Proceedings of Neural Information Processing Society},
  year = {2000},
  volume = {13},
  pages = {814-820},
  file = {Slaney00.pdf:Audio-Video/Slaney00.pdf:PDF},
  owner = {larcher},
  timestamp = {2009.10.05},
  url = {citeseer.ist.psu.edu/article/slaney01facesync.html}
}

@ARTICLE{Sohn99,
  author = {Jongseo Sohn and Nam Soo Kim and Wonyong Sung},
  title = {{A statistical model-based voice activity detection}},
  journal = {Signal Processing Letters, IEEE},
  year = {1999},
  volume = {6},
  pages = {1--3},
  number = {1},
  file = {Sohn99.pdf:VAD/Sohn99.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Solar05,
  author = {Javier Ruiz-del-Solar and Pablo Navarrete},
  title = {{Eigenspace-based face recognition: a comparative study of different
	approaches}},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  year = {2005},
  volume = {35},
  pages = {315--325},
  number = {3},
  file = {Solar05.pdf:Image/EigenSpace/Solar05.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Solomonoff05,
  author = {Solomonoff, A. and Campbell, W.M. and Boardman, I.},
  title = {Advances In Channel Compensation For SVM Speaker Recognition},
  booktitle = icassp,
  year = {2005},
  volume = {1},
  pages = { 629-632},
  month = {18-23,},
  doi = {10.1109/ICASSP.2005.1415192},
  file = {Solomonoff05.pdf:Speaker_reco/SVM/Solomonoff05.pdf:PDF},
  issn = {1520-6149},
  journal = icassp,
  keywords = {compensation, eigenvalues and eigenfunctions, speaker recognition,
	support vector machines SVM expansion space projections, SVM speaker
	recognition, channel compensation, cross-channel degradation, eigenvalue
	problem training, nonspeaker nuisance dimension removal, speaker
	multisession variation, support vector machines}
}

@INPROCEEDINGS{Solomonoff04,
  author = {Alex Solomonoff and Carl Quillen and William M. Campbell},
  title = {{Channel Compensation for SVM speaker recognition}},
  booktitle = odyssey,
  year = {2004},
  file = {Solomonoff04.pdf:Speaker_reco/SVM/Solomonoff04.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.03}
}

@INPROCEEDINGS{Soong85,
  author = {Frank Kao Ping Soong and Aaron Rosenberg and Lawrence Rabiner and
	B. Juang},
  title = {{A Vector Quantization Approach to Speaker Recognition}},
  booktitle = icassp,
  year = {1985},
  volume = {10},
  pages = {387-390},
  address = {Tampa (USA)},
  abstract = {In this study a vector quantization (VQ) codebook was used as an efficient
	means of characterizing the short-time spectral features of a speaker.
	A set of such codebooks were then used to recognize the identity
	of an unknown speaker from his/her unlabelled spoken utterances based
	on a minimum distance (distortion) classification rule. A series
	of speaker recognition experiments was performed using a 100-talker
	(50 male and 50 female) telephone recording database consisting of
	isolated digit utterances. For ten random but different isolated
	digits, over 98% speaker identification accuracy was achieved. The
	effects, on performance, of different system parameters such as codebook
	sizes, the number of test digits, phonetic richness of the text,
	and difference in recording sessions were also studied in detail.},
  file = {Soong85.pdf:Speaker_reco/VQ/Soong85.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.22}
}

@ARTICLE{Soong88,
  author = {Frank Kao Ping Soong and Aaron E. Rosenberg},
  title = {{On the use of instantaneous and transitional spectral information
	in speaker recognition}},
  journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing [see
	also IEEE Transactions on Signal Processing]},
  year = {1988},
  volume = {36},
  pages = {871--879},
  number = {6},
  file = {Soong88.pdf:Parametrisation/Soong88.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Sotiropoulos05,
  author = {Dionyssios N. Sotiropoulos and Aristomenis S. Lampropoulos and George
	A. Tsihrintzis},
  title = {{Artificial Immune System-Based Music Piece Similarity Measures and
	Database Organization}},
  booktitle = {EURASIP Conference on Speech and Image Processing, Multimedia Communications
	and Services},
  year = {2005},
  editor = {EURASIP},
  address = {Smolenice, Slovak Republic},
  file = {Sotiropoulos05.pdf:Artificial_Immune_System/Sotiropoulos05.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.04}
}

@INPROCEEDINGS{Sotiropoulos08,
  author = {Dionyssios N. Sotiropoulos and Aristomenis S. Lampropoulos and George
	A. Tsihrintzis},
  title = {{Artificial Immune System-based music genre classification}},
  booktitle = {International Symposium on Intelligent/Interactive/Multimedia Systems
	and Services (KES-IIMSS-10)},
  year = {2008},
  editor = {Springer},
  volume = {142},
  pages = {191--200},
  file = {Sotiropoulos08.pdf:Artificial_Immune_System/Sotiropoulos08.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.04}
}

@INPROCEEDINGS{Stadelmann10,
  author = {Thilo Stadelmann and Bernd Freisleben},
  title = {{Dimension-Decoupled Gaussian Mixture Model for Short Utterance Speaker
	Recognition}},
  booktitle = icpr,
  year = {2010},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/Short_Utterance/Stadelmann10.pdf:PDF},
  journal = {Proceedings of ICRP}
}

@MISC{NIST10,
  author = {National Institute of Standards and Technology},
  title = {Speaker Recognition Evaluation Plan},
  howpublished = {\url{http://www.itl.nist.gov/iad/mig/tests/sre/2010/NIST SRE10 evalplan.r6.pdf}},
  year = {2010},
  owner = {antho},
  timestamp = {2011.11.17}
}

@INPROCEEDINGS{Starpert01,
  author = {Robert P. Starpert and John S. Mason},
  title = {{A segmental mixture model for speaker recognition}},
  booktitle = eurospeech,
  year = {2001},
  volume = {4},
  pages = {2509-2512},
  address = {Aalborg (Denmark)},
  abstract = {standard Gaussian mixture modelling does not posses time sequence
	information (TSI) other than which might be embedded
	
	in the acoustic features. Dynamic time warping relates directly to
	TSI, time-warping two sequences of features into alignment.
	
	Here, a hybrid system embedding DTW into a GMM is presented. Improved
	automatic speaker verification performance is 
	
	demonstrated. Testing 1000 speakers in a fully text independent, world-model-adapted
	mode shows an equal error 
	
	improvement over standard GMM from 4.1% to 3.8%.},
  owner = {larcher},
  timestamp = {2006.04.11},
  url = {http://galilee.swan.ac.uk/}
}

@INPROCEEDINGS{Steffens98,
  author = {Steffens, J. and Elagin, E. and Neven, H.},
  title = {{PersonSpotter - Fast and Robust System for Human Detection, Tracking
	and Recognition}},
  booktitle = {International Conference on Automatic Face and Gesture Recognition},
  year = {1998},
  pages = {516--521},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Stibor08,
  author = {Thomas Stibor},
  title = {{Discriminating self from non-self with finite mixtures of multivariate
	bernoulli distributions}},
  booktitle = {Conference on Genetic and evolutionary computation},
  year = {2008},
  pages = {127--134},
  organization = {ACM},
  file = {Stibor08.pdf:Artificial_Immune_System/Stibor08.pdf:PDF}
}

@INPROCEEDINGS{Stolcke02,
  author = {Andreas Stolcke},
  title = {{SRILM-an extensible language modeling toolkit}},
  booktitle = interspeech,
  year = {2002},
  volume = {3},
  pages = {901--904},
  organization = {Citeseer},
  file = {Stolcke02.pdf:Language_reco/Stolcke02.pdf:PDF}
}

@INPROCEEDINGS{Stolcke10,
  author = {Andreas Stolcke and Murat Ackbacak and Luciana Ferrer and Sachin
	Kajarekar and Colleen Richey and Nicolas Scheffer and Elizabeth Shriberg},
  title = {{Improving language recognition with multilingual phone recognition
	and speaker adaptation transforms}},
  booktitle = odyssey,
  year = {2010},
  file = {Stolcke10.pdf:Language_reco/Stolcke10.pdf:PDF},
  owner = {antho},
  timestamp = {2011.01.12}
}

@INPROCEEDINGS{Stolcke05,
  author = {Andreas Stolcke and Luciana Ferrer and Sachin Kajarekar and Elizabeth
	Shriberg and Anand Venkataraman},
  title = {{MLLR Transforms as Features in Speaker Recognition}},
  booktitle = eurospeech,
  year = {2005},
  pages = {2425-2428},
  address = {Lisboa (Portugale)},
  abstract = {We explore the use of adaptation transforms employed in speech recognition
	systems as features for speaker recognition. This approach is attractive
	because, unlike standard frame-based cepstral speaker recognition
	models, it normalizes for the choice of spoken words in text-independent
	speaker verification. Affine transforms are computed for the Gaussian
	means of the acoustic models used in a recognizer, using maximum
	likelihood linear regression (MLLR). The high-dimensional vectors
	formed by the transform coefficients are then modeled as speaker
	features using support vector machines (SVMs). The resulting speaker
	verification system is competitive, and in some cases significantly
	more accurate, than state-of-the-art cepstral gaussian mixture and
	SVM systems. Further improvements are obtained by combining baseline
	and MLLR-based systems.},
  file = {Stolcke05.pdf:Speaker_reco/Adaptation/MLLR/Stolcke05.pdf:PDF},
  keywords = {acoustic signal processing correlation methods feature extraction
	hidden Markov models image processing natural languages noise speech
	processing speech recognition HMM acoustic information processing
	acoustic parameters modeling articulatory information processing
	asynchronous parameters automatic speech recognition clear environment
	cocktail party environment correlated models direct identification
	heterogenous parameters labial features labial parameters modeling
	linguistic decoder lip reading master HMM noise conditions noisy
	environment segmental preprocessing method slave HMM speech recognition
	score spelled French letters visual parameters},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@ARTICLE{Stolcke93,
  author = {Stolcke, Andreas and Omohundro, Stephen},
  title = {{Hidden Markov model induction by Bayesian model merging}},
  journal = {Advances in Neural Information Processing Systems},
  year = {1993},
  volume = {5},
  pages = {11--18},
  owner = {larcher},
  publisher = {Morgan Kaufmann, San Mateo, CA},
  timestamp = {2007.07.30}
}

@PHDTHESIS{Stoll11,
  author = {Lara Lynn Stoll},
  title = {{Finding Difficult Speakers in Automatic Speaker Recognition}},
  school = {University of California, Berkeley},
  year = {2011},
  file = {Stoll11.pdf:Theses/Stoll11.pdf:PDF},
  owner = {antho},
  timestamp = {2012.02.21}
}

@INPROCEEDINGS{Sturim05,
  author = {Sturim, DE and Reynolds, DA},
  title = {{Speaker adaptive cohort selection for Tnorm in text-independent
	speaker verification}},
  booktitle = icassp,
  year = {2005},
  volume = {1},
  pages = {741--744},
  file = {Sturim05.pdf:Speaker_reco/Normalisation/Sturim05.pdf:PDF}
}

@INPROCEEDINGS{Sturim01,
  author = {D.E. Sturim and Douglas A. Reynolds and E. Singer and Joseph P. Campbell},
  title = {{Speaker indexing in large audio databases using anchor models}},
  booktitle = icassp,
  year = {2001},
  pages = {429-432},
  address = {Salt Lake City (USA)},
  month = {November},
  abstract = {Introduces the technique of anchor modeling in the applications of
	speaker detection and speaker indexing. The anchor modeling algorithm
	is refined by pruning the number of models needed. The system is
	applied to the speaker detection problem where its performance is
	shown to fall short of the state-of-the-art Gaussian mixture model
	with universal background model (GMM-UBM) system. However, it is
	further shown that its computational efficiency lends itself to speaker
	indexing for searching large audio databases for desired speakers.
	Here, excessive computation may prohibit the use of the GMM-UBM recognition
	system. Finally, the paper presents a method for cascading anchor
	model and GMM-UBM detectors for speaker indexing. This approach benefits
	from the efficiency of anchor modeling and high accuracy of GMM-UBM
	recognition},
  doi = {10.1109/ICASSP.2001.940859},
  file = {Sturim01.pdf:Speaker_reco/Anchor_models/Sturim01.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.05}
}

@INPROCEEDINGS{Sturim02,
  author = {Sturim, D. and Reynolds, D. and Dunn, R. and Quatieri, T.},
  title = {{Speaker verification using text-constrained Gaussian mixture models}},
  booktitle = icassp,
  year = {2002},
  volume = {1},
  pages = {677--680},
  organization = {IEEE; 1999},
  file = {Sturim02.pdf:Speaker_reco/Text_dependent/Sturim02.pdf:PDF}
}

@INPROCEEDINGS{Campbell06_b,
  author = {William M. Campbell Douglas E. Sturim and Pedro A. Torres-Carrasquillo
	and Douglas A. Reynolds},
  title = {{A Comparison of Subspace Feature-Domain Methods for Language Recognition}},
  booktitle = interspeech,
  year = {2008},
  pages = {309--312},
  owner = {antho},
  timestamp = {2010.11.22}
}

@INPROCEEDINGS{Subramanya07,
  author = {Amarnag Subramanya and Zhengyou Zhang and Aroun C. Surendran and
	Patrick Nguyen and Mukund Narasimhan and Alex Acero},
  title = {{A generative-discriminative framework using ensemble methods for
	text-dependent speaker verification}},
  booktitle = icassp,
  year = {2007},
  volume = {4},
  file = {Subramanya07.pdf:Speaker_reco/Text_dependent/Subramanya07.pdf:PDF}
}

@ARTICLE{Sumby54,
  author = {Sumby, WH and Irwin Pollack},
  title = {{Visual contribution to speech intelligibility in noise}},
  journal = jasa,
  year = {1954},
  volume = {26},
  pages = {212},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Sun10,
  author = {Hanwu Sun and Bin Ma and Swe Zin Kalayar Khine and Haizhou Li},
  title = {{Speaker Diarization system for RT07 and RT09 meeting room audio}},
  booktitle = icassp,
  year = {2010},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_Diarization/Sun10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.05.12}
}

@INPROCEEDINGS{Sundermann03,
  author = {David Sundermann and Hermann Ney and Harald Hoge},
  title = {{VTLN-based cross-language voice conversion}},
  booktitle = {IEEE Workshop on Automatic Speech Recognition and Understanding,
	ASRU},
  year = {2003},
  pages = {676-681},
  address = {St Thomas (USA)},
  abstract = {In speech recognition, vocal tract length normalization (VTLN) is
	a well-studied technique for speaker normalization. As cross-language
	voice conversion aims at the transformation of a source speaker's
	voice into that of a target speaker using a different language, we
	want to investigate whether VTLN is an appropriate method to adapt
	the voice characteristics. After applying several conventional VTLN
	warping functions, we extend the conventional piece-wise linear function
	to several segments, allowing a more detailed warping of the source
	spectrum. Experiments on cross-language voice conversion are performed
	on three corpora of two languages and both speaker genders.},
  doi = {10.1109/ASRU.2003.1318521},
  file = {Sundermann03.pdf:Speaker_reco/Normalisation/VTLN/Sundermann03.pdf:PDF},
  keywords = {language translation piecewise linear techniques speech recognition
	speech synthesis VTLN warping functions VTLN-based cross-language
	voice conversion piece-wise linear warping speaker normalization
	speech recognition vocal tract length normalization voice characteristics},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Sung94,
  author = {Kah-Kay Sung and Tomaso Poggio},
  title = {{Example-based learning for view-based human face detection}},
  booktitle = {Proceedings International ARPA Image Understanding Workshop},
  year = {1994},
  address = {Monterey (Canada)},
  file = {Sung94.pdf:Video/Face_detection/Sung94.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@INPROCEEDINGS{Sonmez97,
  author = {S{\"o}nmez, M.K. and Heck, L. and Weintraub, M. and Shriberg, E.},
  title = {{A lognormal tied mixture model of pitch for prosody based speaker
	recognition}},
  booktitle = eurospeech,
  year = {1997},
  organization = {ISCA},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Saenz06,
  author = {S{\'a}enz-Lech{\'o}n, N. and Godino-Llorente, J.I. and Osma-Ruiz,
	V. and G{\'o}mez-Vilda, P.},
  title = {{Methodological issues in the development of automatic systems for
	voice pathology detection}},
  journal = {Biomedical Signal Processing and Control},
  year = {2006},
  volume = {1},
  pages = {120--128},
  number = {2},
  file = {Saenz06.pdf:Divers/Pathologies/Saenz06.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@ARTICLE{Tan06,
  author = {Tan, X. and Chen, S. and Zhou, Z.H. and Zhang, F.},
  title = {{Face recognition from a single image per person: A survey}},
  journal = {Pattern Recognition},
  year = {2006},
  volume = {39},
  pages = {1725--1745},
  number = {9},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@ARTICLE{Tarakanov10,
  author = {Alexander O. Tarakanov},
  title = {{Immunocomputing for Speaker Recognition}},
  journal = {Advances in Machine Learning},
  year = {2010},
  volume = {2},
  pages = {515--529},
  file = {Tarakanov10.pdf:Artificial_Immune_System/Tarakanov10.pdf:PDF},
  publisher = {Springer}
}

@MISC{digital-etsi,
  author = {{Technical Specification Digital, European Telecommunications Standards
	Institute (ETSI)}},
  title = {{Speech Processing, Transmission and Quality aspects (STQ); Distributed
	speech recognition; Extended advanced front-end feature extraction
	algorithm; Compression algorithms; Back-end speech reconstruction
	algorithm. [ES 202 212 v1.1.2 (2005-11)]}},
  year = {2005},
  owner = {antho},
  timestamp = {2009.10.05},
  url = {citeseer.ist.psu.edu/418491.html}
}

@ARTICLE{Tekalp00,
  author = {Tekalp, A.M. and Ostermann, J.},
  title = {{Face and 2-D mesh animation in MPEG-4}},
  journal = {Signal Processing: Image Communication},
  year = {2000},
  volume = {15},
  pages = {387--421},
  number = {4-5},
  file = {Tekalp00.pdf:Ventriloquie/Tekalp00.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Teoh04,
  author = {Andrew Teoh and Salina A. Samad and Aini Hussain},
  title = {{Nearest Neighbourhood Classifiers in Biometric Fusion}},
  journal = {International Journal of the computer, ther internet and management
	2},
  year = {2004},
  volume = {12},
  pages = {Teoh04},
  number = {1},
  month = {April},
  abstract = {This paper presents fusion decision
	
	technique comparisons based on nearest-
	
	neighborhood (NN) classifiers family for a
	
	bimodal biometric verification system that
	
	makes use of face images and speech
	
	utterances. The system is essentially
	
	constructed by a face expert, a speech expert
	
	and a fusion decision module. Each
	
	individual expert has been optimized to
	
	operate in automatic mode and designed for
	
	security access application. Fusion decision
	
	schemes considered are ordinary, modified
	
	k-NN and evidence theoretic k-NN classifier
	
	based on Dampster-Safer theory. The aim is
	
	to obtain the optimum fusion module from
	
	amongst these three techniques best suited to
	
	the target application.},
  file = {Teoh04.pdf:Audio-Video/Teoh04.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.24}
}

@INPROCEEDINGS{Teunen00,
  author = {Remco Teunen and Ben Shahshahani and Larry Heck},
  title = {{A model-based transformational approach to robust speaker recognition}},
  booktitle = icslp,
  year = {2000},
  organization = {ISCA},
  file = {Teunen00.pdf:Speaker_reco/FA/Teunen00.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Thiruvaran08,
  author = {Thiruvaran, T. and Ambikairajah, E. and Epps, J.},
  title = {{Extraction of FM components from speech signals using all-pole model}},
  journal = {Electronics Letters},
  year = {2008},
  volume = {44},
  pages = {449}
}

@ARTICLE{Timmis01,
  author = {Jon Timmis and Mark Neal},
  title = {{A resource limited artificial immune system for data analysis}},
  journal = {Knowledge-Based Systems},
  year = {2001},
  volume = {14},
  pages = {121--130},
  number = {3-4},
  file = {Timmis01.pdf:Artificial_Immune_System/Timmis01.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Tipping99,
  author = {Michael E. Tipping and Christopher M. Bishop},
  title = {{Probabilistic principal component analysis}},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year = {1999},
  volume = {61},
  pages = {611--622},
  number = {3},
  file = {Tipping99.pdf:Outils/Tipping99.pdf:PDF},
  publisher = {Wiley Online Library}
}

@ARTICLE{Tipping99_b,
  author = {Michael E. Tipping and Christopher M. Bishop},
  title = {{Mixtures of probabilistic principal component analyzers}},
  journal = {Neural computation},
  year = {1999},
  volume = {11},
  pages = {443--482},
  number = {2},
  file = {Tipping99_b.pdf:Outils/Tipping99_b.pdf:PDF},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Tjahyadi04,
  author = {Ronny Tjahyadi and Wanquan Liu and Svetha Venkatesh},
  title = {{Application of the DCT energy histogram for face recognition}},
  booktitle = {Proceedings of the 2nd International Conference on Information Technology
	for Application (ICITA 2004)},
  year = {2004},
  pages = {305--310},
  file = {Tjahyadi04.pdf:Image/Tjahyadi04.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Toledano08_b,
  author = {Doroteo T. Toledano and Cristina Esteve-Elizalde and Joaquin Gonzalez-Rodriguez
	and Ruben Fernandez Pozo and Luis Hernandez Gomez},
  title = {{Phoneme and Sub-Phoneme T-Normalization for Text-Dependent Speaker
	Recognition}},
  booktitle = odyssey,
  year = {2008},
  address = {Stellenbosch, South Africa},
  month = {January},
  file = {Toledano08_b.pdf:Speaker_reco/Text_dependent/Toledano08_b.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.18}
}

@INPROCEEDINGS{Toledano08,
  author = {Doroteo T. Toledano and Hernandez-Lopez, D. and Esteve-Elizalde,
	C. and Fierrez, J. and Ortega-Garcia, J. and Ramos, D. and Gonzalez-Rodriguez,
	J.},
  title = {{BioSec Multimodal Biometric Database in Text-Dependent Speaker Recognition}},
  booktitle = {LREC},
  year = {2008},
  file = {Toledano08.pdf:Base_de_donnees/Toledano08.pdf:PDF},
  journal = {Proc. LREC, Mayo}
}

@INPROCEEDINGS{Toledo11,
  author = {Orith Toledo-Ronen and Hagai Aronowitz and Ron Hoory and Jason Pelecanos
	and David Nahamoo},
  title = {{Towards Goat Detection in Text-Dependent Speaker Verification}},
  booktitle = interspeech,
  year = {2011},
  file = {Toledo11.PDF:Speaker_reco/Text_dependent/Toledo11.PDF:PDF}
}

@CONFERENCE{Tong06,
  author = {Rong Tong and Ma Bin and Donglai Zhu and Haizhou Li and Eng Siong
	Chng},
  title = {{Integrating acoustic, prosodic and phonotactic features for spoken
	language identification}},
  booktitle = {Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings.
	2006 IEEE International Conference on},
  year = {2006},
  volume = {1},
  organization = {IEEE},
  file = {Tong06.pdf:Language_reco/Tong06.pdf:PDF},
  isbn = {142440469X},
  issn = {1520-6149}
}

@INPROCEEDINGS{Tong10,
  author = {Rong Tong and Bin Ma and Haizhou Li and Eng Siong Chng},
  title = {{Selecting Phonotactic Features for Language Recognition}},
  booktitle = interspeech,
  year = {2010},
  file = {Tong10.PDF:Language_reco/Tong10.PDF:PDF}
}

@ARTICLE{Torres02,
  author = {Luis Torres and Josep Vil{\`a}},
  title = {{Automatic face recognition for video indexing applications}},
  journal = {Pattern Recognition},
  year = {2002},
  volume = {35},
  pages = {615--625},
  number = {3},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Torres10,
  author = {Pedro A. Torres-Carrasquillo and Elliot Singer and Terry Gleason
	and Alan McCree and Douglas A. Reynolds and Fred Richardson, and
	Douglas Sturim},
  title = {{The MITLL NIST LRE 2009 language recognition system}},
  booktitle = icassp,
  year = {2010},
  pages = {4994--4997},
  organization = {IEEE},
  file = {Torres10.pdf:Language_reco/Torres10.pdf:PDF},
  issn = {1520-6149}
}

@ARTICLE{Tremain82,
  author = {Tremain, T.E.},
  title = {{The government standard linear predictive coding algorithm: LPC-10}},
  journal = {Speech Technology},
  year = {1982},
  volume = {1},
  pages = {40--49},
  number = {2},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INCOLLECTION{Triggs00,
  author = {Bill Triggs and Philip McLauchlan and Richard Hartley and Andrew
	Fitzgibbon},
  title = {{Bundle Adjustment A Modern Synthesis}},
  booktitle = {Vision Algotithms : Theory and Practice},
  publisher = {Springer Verlag},
  year = {2000},
  editor = {Bill Triggs and Zisserman and Szeliski},
  series = {LNCS},
  pages = {298-375},
  citeseerurl = {citeseer.ist.psu.edu/triggs00bundle.html},
  file = {Triggs00.pdf:Image/Synthese/Triggs00.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.18}
}

@INPROCEEDINGS{Tsao10,
  author = {Yu Tsao and Hanwu Sun and Haizhou Li and Chin-Hui Lee},
  title = {{An Acoustic segment model approach to incorporating temporal information
	into speaker modeling for text-independent speaker recognition}},
  booktitle = icassp,
  year = {2010},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/Divers/Tsao10.pdf:PDF},
  owner = {antho},
  timestamp = {2010.05.12}
}

@INPROCEEDINGS{Tsuge06,
  author = {Satoru Tsuge and Masami Shishibori and Kenji Kita and Fuji Ren and
	Shingo Kuroiwa},
  title = {Study of intra-speaker's speech variability over long and short time
	periods for speech recognition},
  booktitle = icassp,
  year = {2006},
  pages = {397--400},
  file = {Tsuge06.pdf:Base_de_donnees/Tsuge06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.07}
}

@INPROCEEDINGS{Tucker94,
  author = {R.C.F. Tucker and M. J. Carey and E.S. Parris},
  title = {{Automatic language identification using sub-word models}},
  booktitle = icassp,
  year = {1994},
  volume = {1},
  organization = {IEEE},
  file = {Tucker94.pdf:Language_reco/Tucker94.pdf:PDF},
  isbn = {0780317750}
}

@INPROCEEDINGS{Tulyakov08,
  author = {Serge Tulyakov and Jiang Li and Venu Govindaraju},
  title = {{Enrolled Template Specific Decisions and Combinations in Verification
	Systems}},
  booktitle = {IEEE International Conference on Biometrics: Theory, Applications
	and Systems},
  year = {2008},
  pages = {1--7},
  organization = {IEEE},
  file = {Tulyakov08.pdf:Speaker_reco/Score_Fusion/Tulyakov08.pdf:PDF}
}

@ARTICLE{Turk911,
  author = {Matthew A. Turk and Alex P. Pentland},
  title = {{Eigenfaces for Face Detection/Recognition}},
  journal = {Journal of Cognitive Neuroscience},
  year = {1991},
  volume = {3},
  pages = {71-86},
  file = {Turk911.pdf:Video/Turk911.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.03}
}

@INPROCEEDINGS{Turk912,
  author = {Matthew A. Turk and Alex P. Pentland},
  title = {{Face recognition using eigenfaces}},
  booktitle = cvpr,
  year = {1991},
  pages = {586-591},
  address = {Hawa\"i (USA)},
  month = {June},
  abstract = {An approach to the detection and identification of human faces is
	presented, and a working, near-real-time face recognition system
	which tracks a subject's head and then recognizes the person by comparing
	characteristics of the face to those of known individuals is described.
	This approach treats face recognition as a two-dimensional recognition
	problem, taking advantage of the fact that faces are normally upright
	and thus may be described by a small set of 2-D characteristic views.
	Face images are projected onto a feature space (`face space') that
	best encodes the variation among known face images. The face space
	is defined by the `eigenfaces', which are the eigenvectors of the
	set of faces; they do not necessarily correspond to isolated features
	such as eyes, ears, and noses. The framework provides the ability
	to learn to recognize new faces in an unsupervised manner},
  doi = {10.1109/CVPR.1991.139758},
  file = {Turk912.pdf:Video/Turk912.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.03}
}

@ARTICLE{Turner11,
  author = {Claude Turner and Anthony Joseph and Murat Aksu and Heather Langdond},
  title = {{The Wavelet and Fourier Transforms in Feature Extraction for Text-Dependent,
	Filterbank-Based Speaker Recognition}},
  journal = {Procedia Computer Science},
  year = {2011},
  volume = {6},
  pages = {124--129},
  file = {Turner11.pdf:Speaker_reco/Text_dependent/Turner11.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Ramasubramanian06,
  author = {Ramasubramanian V. and Das A. and Kumar V.P},
  title = {{Text-Dependent Speaker-Recognition Using One-Pass Dynamic Programming
	Algorithm}},
  booktitle = icassp,
  year = {2006},
  file = {Ramasubramanian06.pdf:Speaker_reco/Text_dependent/Ramasubramanian06.pdf:PDF}
}

@INPROCEEDINGS{Vair06,
  author = {Claudio Vair and Daniele Colibro and Fabio Castaldo and Emanuele
	Dalmasso and Pietro Laface},
  title = {{Channel factors compensation in model and feature domain for speaker
	recognition}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--6},
  file = {Vair06.pdf:Speaker_reco/FA/Vair06.pdf:PDF}
}

@ARTICLE{Valtchev97,
  author = {Valtcho Valtchev and Julian Odell and Phil C. Woodland and Steve
	J.Young},
  title = {{MMIE training of large vocabulary recognition systems}},
  journal = {Speech Communication},
  year = {1997},
  volume = {22},
  pages = {303--314},
  number = {4},
  abstract = {This paper describes a framework for optimising the structure and
	parameters of a continuous density HMM-based large vocabulary recognition
	system using the maximum Mutual Information Estimation (MMIE° criterion.
	To reduce the computational complexity of the MMIE training algorithm,
	confusable segments of speech are identified and stored as word lattices
	of alternative utterance hypotheses. An iterative mixture splitting
	procedure is also amployed to adjust the number of mixture components
	in each state during training such that the optimal balance between
	the number of parameters and the available training data is achieved.
	Experiments are presented on various test sets from the wall Street
	Journal database using up to 66 hours of acoustic training data.
	These demonstrate that the use of lattices makes MMIE training practicable
	for very complex recognition systems and large training sets. Furthermore,
	the experimental restults show that MMIE optimisation of system structure
	and parameters can yield useful increases in recognition accuracy.},
  file = {Valtchev97.pdf:Speaker_reco/Adaptation/MMIE/Valtchev97.pdf:PDF},
  owner = {larcher},
  publisher = {Elsevier Science Publishers BV Amsterdam, The Netherlands, The Netherlands},
  timestamp = {2007.04.19}
}

@BOOK{Vapnik98,
  title = {{Statistical learning theory}},
  publisher = {John Wiley \& Sons},
  year = {1998},
  author = {Vapnik, V.N.},
  owner = {antho},
  timestamp = {2009.10.05}
}

@BOOK{Vapnik99,
  title = {{The nature of Statistical Learning Theory}},
  publisher = {Springer-Verlag},
  year = {1999},
  editor = {Springer-Verlag},
  author = {Vladimir N. Vapnik},
  series = {Statistics for Engineering and information Science},
  owner = {larcher},
  timestamp = {2006.06.20}
}

@INPROCEEDINGS{Vaquero11,
  author = {Carlos Vaquero and Alfonso Ortega and Eduardo Lleida},
  title = {{Intra-session variability compensation and a hypothesis generation
	and selection strategy for speaker segmentation}},
  booktitle = icassp,
  year = {2011},
  pages = {4532--4535},
  file = {Vaquero11.pdf:Speaker_Diarization/Vaquero11.pdf:PDF},
  owner = {antho},
  timestamp = {2011.10.10}
}

@INPROCEEDINGS{Vaquero11_b,
  author = {Carlos Vaquero and Alfonso Ortega and Eduardo Lleida},
  title = {{Partitioning of Two-Speaker Conversation Datasets}},
  booktitle = interspeech,
  year = {2011},
  pages = {385--388},
  file = {Vaquero11_b.PDF:Speaker_Diarization/Vaquero11_b.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.10}
}

@INPROCEEDINGS{Vaquero10,
  author = {Carlos Vaquero and Alfonso Ortega and Jesus Villalba and Antonio
	Miguel and Eduardo Lleida},
  title = {{Confidence Measures for Speaker Segmentation and their Relation
	to Speaker Verification}},
  booktitle = interspeech,
  pages = {2310--2313},
  file = {Vaquero10.PDF:Speaker_Diarization/Vaquero10.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.10}
}

@INPROCEEDINGS{Vaquero09,
  author = {Vaquero, C. and Scheffer, N. and Karajekar, S.},
  title = {{Impact of Prior Channel Information for Speaker Identification}},
  booktitle = {Proceedings of the Third International Conference on Advances in
	Biometrics},
  year = {2009},
  pages = {453},
  organization = {Springer},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/FA/Vaquero09.pdf:PDF}
}

@INPROCEEDINGS{Venayagamoorthy00,
  author = {Venayagamoorthy, G.K. and Sundepersadh, N.},
  title = {{Comparison of text-dependent speaker identification methods for
	short distance telephone lines using artificial neural networks}},
  booktitle = {ijcnn},
  year = {2000},
  pages = {5253},
  organization = {Published by the IEEE Computer Society},
  issn = {1098-7576}
}

@INPROCEEDINGS{Verdet10,
  author = {Florian Verdet and Driss Matrouf and Jean-Francois Bonastre and Jean
	Hennebert},
  title = {{Coping with Two Different Transmission Channels in Language Recognition}},
  booktitle = odyssey,
  year = {2010},
  pages = {1--8},
  file = {Verdet10.pdf:Language_reco/Verdet10.pdf:PDF}
}

@INPROCEEDINGS{Verdet09,
  author = {Florian Verdet and Driss Matrouf and Jean-Francois Bonastre and Jean
	Hennebert},
  title = {{Factor Analysis and SVM for Language Recognition}},
  booktitle = interspeech,
  year = {2009},
  abstract = {Statistic classifiers operate on features that generally include both,
	useful and useless information. These two types of information are
	difficult to separate in feature domain. Recently, a new paradigm
	based on Factor Analysis (FA) proposed a model decomposition into
	useful and useless components. This method has successfully been
	applied to speaker recognition tasks.
	
	In this paper, we study the use of FA for language recognition. We
	propose a classification method based on SDC features and Gaussian
	Mixture Models (GMM). We present well performing systems using Factor
	Analysis and FA-based Support Vector Machine (SVM) classifiers.
	
	Experiments are conducted using NIST LRE 2005's primary condition.
	The relative equal error rate reduction obtained by the best factor
	analysis configuration with respect to baseline GMM-UBM system is
	over 60 %, corresponding to an EER of 6.59 %.},
  file = {Verdet09.pdf:Language_reco/Verdet09.pdf:PDF},
  owner = {antho},
  timestamp = {2009.06.25}
}

@INPROCEEDINGS{Verlinde99,
  author = {Verlinde, P. and Cholet, G.},
  title = {{Comparing decision fusion paradigms using k-NN based classifiers,
	decision trees and logistic regression in a multi-modal identity
	verification application}},
  booktitle = avbpa,
  year = {1999},
  pages = {188--193},
  organization = {Citeseer},
  file = {Verlinde99.pdf:Divers/Fusion/Verlinde99.pdf:PDF}
}

@ARTICLE{Verlinde00,
  author = {Verlinde, P. and Chollet, G. and Acheroy, M.},
  title = {{Multi-modal identity verification using expert fusion}},
  journal = {Information Fusion},
  year = {2000},
  volume = {1},
  pages = {17--33},
  number = {1},
  file = {Verlinde00.pdf:Divers/Fusion/Verlinde00.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Verma03,
  author = {Ashish Verma and Nitendra Rajput and Subramaniam, LV},
  title = {{Using viseme based acoustic models for speech driven lip synthesis}},
  booktitle = {International Conference on Multimedia and Expo},
  year = {2003},
  volume = {3},
  file = {Verma03.pdf:Video/Segmentation/Viseme/Verma03.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Villalba11,
  author = {Jesus Villalba and Niko Brummer},
  title = {{Towards Fully Bayesian Speaker Recognition: Integrating Out the
	Between-Speaker Covariance}},
  booktitle = interspeech,
  year = {2011},
  file = {Villalba11.pdf:Speaker_reco/FA/I-Vector/Villalba11.pdf:PDF},
  owner = {antho},
  timestamp = {2011.11.21}
}

@INPROCEEDINGS{Villalba10,
  author = {Jesus Villalba and Carlos Vaquero and Eduardo Lleida and Alfonso
	Ortega and Antonio Miguel},
  title = {{I3A NIST SRE2010 System Description}},
  booktitle = {{NIST Speaker Recognition Evaluation Workshop}},
  year = {2010},
  file = {Villalba10.pdf:Speaker_reco/NIST/Villalba10.pdf:PDF}
}

@ARTICLE{Viterbi67,
  author = {Andrew J. Viterbi},
  title = {{Error bounds for convolutional codes and an asymptotically optimum
	decoding algorithm}},
  journal = tit,
  year = {1967},
  volume = {13},
  pages = {260-269},
  number = {2},
  month = {april},
  abstract = {The probability of error in decoding an optimal convolutional code
	transmitted over a memoryless channel is bounded from above and below
	as a function of the constraint length of the code. For all but pathological
	channels the bounds are asymptotically (exponentially) tight for
	rates aboveR_{0}, the computational cutoff rate of sequential decoding.
	As a function of constraint length the performance of optimal convolutional
	codes is shown to be superior to that of block codes of the same
	length, the relative improvement increasing with rate. The upper
	bound is obtained for a specific probabilistic nonsequential decoding
	algorithm which is shown to be asymptotically optimum for rates aboveR_{0}and
	whose performance bears certain similarities to that of sequential
	decoding algorithms.},
  owner = {larcher},
  timestamp = {2007.04.11},
  url = {http://ieeexplore.ieee.org/search/freesrchabstract.jsp?arnumber=1054010&isnumber=22634&punumber=18&k2dockey=1054010@ieeejrns&query=error+bounds+for+convolutional+codes+and+an+asymptotically+optimum+decoding+algorithm+%3Cin%3E+metadata&pos=0&fromcon}
}

@INPROCEEDINGS{Vogel03,
  author = {Stephan Vogel and Ying Zhang and Fei Huang and Alicia Tribble and
	Ashish Venugopal and Bing Zhao and Alex Waibel},
  title = {{The CMU statistical machine translation system}},
  booktitle = {Machine Translation Summit},
  year = {2003},
  volume = {9},
  pages = {54},
  organization = {Citeseer},
  file = {Vogel03.pdf:Machine_Translation/Vogel03.pdf:PDF}
}

@INPROCEEDINGS{Vogt05,
  author = {Vogt, R. and Baker, B. and Sridharan, S.},
  title = {{Modelling session variability in text-independent speaker verification}},
  booktitle = eurospeech,
  year = {2005},
  organization = {ISCA},
  file = {Vogt05.pdf:Speaker_reco/FA/Vogt05.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Vogt09,
  author = {Robert Vogt and Sridha Sridharan},
  title = {{Minimising speaker verification utterance length through confidence
	based early verification decisions}},
  booktitle = {Proceedings of the Third International Conference on Advances in
	Biometrics},
  year = {2009},
  pages = {463--472},
  organization = {Springer},
  file = {Vogt09.pdf:Speaker_reco/Short_Utterance/Vogt09.pdf:PDF}
}

@ARTICLE{Vogt2008_c,
  author = {Robert Vogt and Sridha Sridharan},
  title = {{Explicit modelling of session variability for speaker verification}},
  journal = {Computer Speech \& Language},
  year = {2008},
  volume = {22},
  pages = {17--38},
  number = {1},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Vogt08,
  author = {Robert J. Vogt and Christopher J. Lustri and Sridha Sridharan},
  title = {{Factor analysis modelling for speaker verification with short utterances}},
  booktitle = odyssey,
  year = {2008},
  publisher = {IEEE},
  file = {Vogt08.pdf:Speaker_reco/Short_Utterance/Vogt08.pdf:PDF}
}

@INPROCEEDINGS{Vogt09_b,
  author = {Robert J. Vogt and Jason Pelecanos and Nicolas Scheffer and Sachin
	Kajarekar and Sridha Sridharan},
  title = {{Within-session variability modelling for factor analysis speaker
	verification}},
  booktitle = interspeech,
  year = {2009},
  address = {Brighton (UK)},
  file = {Vogt09_b.pdf:Speaker_reco/Short_Utterance/Vogt09_b.pdf:PDF}
}

@INPROCEEDINGS{Vogt08_b,
  author = {Robert J. Vogt and Sridha Sridharan and Michael W. Mason},
  title = {{Making confident speaker verification decisions with minimal speech}},
  booktitle = interspeech,
  year = {2008},
  publisher = {International Speech Communication Association (ISCA)},
  file = {:/Volumes/Donnees/LIA/biblio/Speaker_reco/Short_Utterance/Vogt08_b.pdf:PDF}
}

@ARTICLE{Vroomen04,
  author = {Vroomen, J. and de Gelder, B.},
  title = {{Temporal ventriloquism: sound modulates the flash-lag effect}},
  journal = {Journal of Experimental Psychology},
  year = {2004},
  volume = {30},
  pages = {513--518},
  number = {3},
  file = {Vroomen04.pdf:Ventriloquie/Vroomen04.pdf:PDF}
}

@INPROCEEDINGS{Vuuren96,
  author = {Sarel Van Vuuren},
  title = {{Comparison of text-independent speaker recognition methods on telephone
	speech with acoustic mismatch}},
  booktitle = interspeech,
  year = {1996},
  volume = {96},
  pages = {1788--1791},
  organization = {Citeseer},
  file = {Vuuren96.pdf:Speaker_reco/Divers/Vuuren96.pdf:PDF}
}

@INPROCEEDINGS{Wagner06,
  author = {Wagner, M. and Summerfield, C. and Dunstone, T. and Summerfield,
	R. and Moss, J.},
  title = {{An evaluation of "commercial off-the-shelf" speaker verification
	systems}},
  booktitle = odyssey,
  year = {2006},
  pages = {1--8},
  file = {Wagner06.pdf:Speaker_reco/Divers/Wagner06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.08}
}

@INPROCEEDINGS{Wan00,
  author = {Vincent Wan and William M. Campbell},
  title = {{Support Vector Machines for Speaker Verification and Identification}},
  booktitle = {IEEE Signal Processing Society Workshop Neural Networks for Signal
	Processing},
  year = {2000},
  volume = {2},
  pages = {775-784},
  address = {Sydney (Australia)},
  abstract = {The performance of the support vector machine (SVM) on a speaker verification
	task is assessed. Since speaker verification requires binary decisions,
	support vector machines seem to be a promising candidate to perform
	the task. A new technique for normalising the polynomial kernel is
	developed and used to achieve performance comparable to other classifiers
	on the YOHO database. We also present results on a speaker identification
	task},
  citeseerurl = {http://citeseer.ist.psu.edu/wan00support.html},
  doi = {10.1109/NNSP.2000.890157},
  file = {Wan00.pdf:Speaker_reco/SVM/Wan00.pdf:PDF},
  journal = {IEEE Proceeding},
  keywords = {database management systems learning automata performance evaluation
	speaker recognition YOHO database binary decisions performance evaluation
	polynomial kernel normalisation speaker identification speaker verification
	support vector machine},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@INPROCEEDINGS{Wan05,
  author = {Vincent Wan and James Carmichael},
  title = {{Polynomial Dynamic Time Warping Kernel Support Vector Machines for
	Dysarthric Speech Recognition with Sparse Training Data}},
  booktitle = interspeech,
  year = {2005},
  address = {Lisboa},
  month = {September},
  abstract = {This paper describes a new formulation of a polynomial sequence kernel
	based on dynamic time warping (DTW) for support vector machine (SVM)
	classification of isolated words given very sparse training data.
	The words are uttered by dysarthric speakers who suffer from debilitating
	neurological conditions that make the collection of speech samples
	a time-consuming and low-yield process. Data for building dysarthric
	speech recognition engines are therefore limited. Simulations show
	that the SVM based approach is significantly better than standard
	DTW and hidden Markov model (HMM) approaches when given sparse training
	data. In conditions where the models were constructed from three
	examples of each word, the SVM approach recorded a 45\% lower error
	rate (relative) than the DTW approach and a 35\% lower error rate
	than the HMM approach.},
  owner = {larcher},
  timestamp = {2007.02.08}
}

@INPROCEEDINGS{Wang12,
  author = {Haipeng Wang and Cheung-Chi Leung and Tan Lee and Bin Ma and Haizhou
	Li},
  title = {{An acoustic segment modeling approach to query-by-example spoken
	term detection}},
  booktitle = icassp,
  year = {2012},
  file = {Wang12.pdf:Spoken_Document_Retrieval/Wang12.pdf:PDF},
  owner = {antho},
  timestamp = {2011.11.15}
}

@ARTICLE{Wang07,
  author = {Longbiao Wang and Norihide Kitaoka and Seiichi Nakagawa},
  title = {{Robust distant speaker recognition based on position-dependent CMN
	by combining speaker-specific GMM with speaker-adapted HMM}},
  journal = {Speech Communication},
  year = {2007},
  volume = {49},
  pages = {501--513},
  number = {6},
  file = {Wang07.pdf:Speaker_reco/Text_dependent/Wang07.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Wang04,
  author = {Wang, L. and Kitaoka, N. and Nakagawa, S.},
  title = {{Robust distant speech recognition based on position dependent CMN}},
  booktitle = icslp,
  year = {2004},
  pages = {2409--2052},
  file = {Wang04.pdf:Systemes_embarques/Wang04.pdf:PDF}
}

@INPROCEEDINGS{Wang07_b,
  author = {Lei Wang and Haizhou Li and Eng Siong Chng},
  title = {{A vector-based approach to broadcast audio database indexing and
	retrieval}},
  booktitle = {IEEE International Conference on Multimedia and Expo},
  year = {2007},
  pages = {512--515},
  organization = {IEEE},
  file = {Wang07_b.pdf:Spoken_Document_Retrieval/Wang07_b.pdf:PDF}
}

@INPROCEEDINGS{Wang08_b,
  author = {XiaoRui Wang and ShiJin Wang and JiaEn Liang and Bo Xu},
  title = {{Improved phonotactic language identification using random forest
	language models}},
  booktitle = icassp,
  year = {2008},
  pages = {4237--4240},
  organization = {IEEE},
  issn = {1520-6149}
}

@INPROCEEDINGS{Wang08,
  author = {Yu Wang and Zhiyong Wu and Lianhong Cai and Helen M. Meng},
  title = {{Modeling the Synchrony between Audio and Visual Modalities for Speaker
	Identification}},
  booktitle = {Phonetic Conference of China and the International Symposium on Phonetic
	Frontiers},
  year = {2008},
  address = {Beijing, China},
  owner = {antho},
  timestamp = {2008.10.24}
}

@ARTICLE{Wang08_c,
  author = {Ye-Yi Wang and Dong Yu and Yun-Cheng Ju and and Alex Acero},
  title = {{An introduction to voice search}},
  journal = {IEEE Signal Processing Magazine},
  year = {2008},
  volume = {25},
  pages = {28--38},
  number = {3},
  file = {Wang08_c.pdf:Spoken_Document_Retrieval/Wang08_c.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Wark01,
  author = {Timothy Wark and Sridha Sridharan},
  title = {{Adaptive Fusion of Speech and Lip Information for Robust Speaker
	Identification}},
  journal = dsp,
  year = {2001},
  volume = {11},
  pages = {169--186},
  number = {3},
  file = {Wark01.pdf:Audio-Video/Wark01.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@ARTICLE{Watkins04,
  author = {Andrew Watkins and Jon Timmis and Lois Boggess},
  title = {{Artificial Immune Recognition System (AIRS): An Immune-Inspired
	Supervised Learning Algorithm}},
  journal = {Genetic Programming and Evolvable Machines},
  year = {2004},
  volume = {5},
  pages = {291--317},
  month = {September},
  file = {:E\:\\Biblio\\Artificial_Immune_System\\Watkins04.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.02}
}

@ARTICLE{Wei02,
  author = {Jie Wei},
  title = {{Image segmentation based on situational DCT descriptors}},
  journal = {Pattern Recogn. Lett.},
  year = {2002},
  volume = {23},
  pages = {295--302},
  number = {1-3},
  abstract = {It is of utmost importance in multimedia processing to achieve still
	image segmentation, i.e., to partition images into regions of coherent
	color and texture. In this paper we propose a novel image segmentation
	method using a special visual descriptor. For each pixel p, the discrete
	cosine transform (DCT) of the block centered on p together with its
	location in the image is employed as its content descriptor thus
	resulting in a long vector vp??, referred to as situational DCT descriptors
	(SDDs). A scalar quantization step is then carried out on the DCT
	component of SDDs to reflect the fact that the human vision system
	is not of uniform discriminative sensitivity to details of different
	frequencies. Next the principal component analysis is conducted to
	drastically reduce the dimensionality of SDDs. The adaptive K-means
	algorithm is then performed to arrive at the region assignment for
	each pixel. The final partitioning results are obtained after performing
	the post-processing step. Encouraging empirical performance has been
	demonstrated.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S0167-8655(01)00124-6},
  file = {Wei02.pdf:Video/Segmentation/Wei02.pdf:PDF},
  issn = {0167-8655},
  owner = {antho},
  publisher = {Elsevier Science Inc.},
  timestamp = {2007.10.11}
}

@INPROCEEDINGS{Wei11,
  author = {Wei, X. and Li, C.},
  title = {{The Student's t-Hidden Markov Model with Truncated Stick-Breaking
	Priors}},
  booktitle = {Signal Processing Letters},
  year = {2011},
  number = {99},
  pages = {1--1},
  publisher = {IEEE},
  file = {Wei11.pdf:Outils/StudentT/Wei11.pdf:PDF},
  issn = {1070-9908},
  journal = {Signal Processing Letters, IEEE}
}

@INPROCEEDINGS{Weinstein07,
  author = {Weinstein, E. and Moreno, P.},
  title = {{Music identification with weighted finite-state transducers}},
  booktitle = icassp,
  year = {2007},
  volume = {2},
  file = {Weinstein07.pdf:Divers/Music_Recognition/Weinstein07.pdf:PDF}
}

@INPROCEEDINGS{Welling99,
  author = {L. Welling and S. Kanthak and H. Ney},
  title = {{Improved methods for vocal tract normalization}},
  booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing,
	1999. ICASSP '99. Proceedings},
  year = {1999},
  volume = {2},
  pages = {761-764},
  address = {Phoenix (USA)},
  abstract = {This paper presents improved methods for vocal tract normalization
	(VTN) along with experimental tests on three databases. We propose
	a new method for VTN in training: by using acoustic models with single
	Gaussian densities per state for selecting the normalization scales
	the need for the models to learn the normalization scales of the
	training speakers is avoided. We show that using single Gaussian
	densities for selecting the normalization scales in training results
	in lower error rates than using mixture densities. For VTN in recognition,
	we propose an improvement of the well-known multiple-pass strategy:
	by using an unnormalized acoustic model for the first recognition
	pass instead of a normalized model lower error rates are obtained.
	In recognition tests, this method is compared with a fast variant
	of VTN. The multiple-pass strategy is an efficient method but it
	is suboptimal because the normalization scale and the word sequence
	are determined sequentially. We found that for telephone digit string
	recognition this suboptimality reduces the VTN gain in recognition
	performance by 30% relative. On the German spontaneous scheduling
	task Verbmobil, the WSJ task and the German telephone digit string
	corpus SieTill the proposed methods for VTN reduce the error rates
	significantly},
  doi = {10.1109/ICASSP.1999.759780},
  file = {Welling99.pdf:Speaker_reco/Normalisation/VTLN/Welling99.pdf:PDF},
  keywords = {Markov processes feature extraction image colour analysis image segmentation
	lighting random processes statistical analysis video signal processing
	LIP-MAD algorithm Markov random field modeling RGB color space ROI
	extraction color video sequence face geometrical features hue-intensity
	color space label field lip features automatic extraction lip segmentation
	logarithmic color transform natural lighting conditions red hue prevailing
	region region of interest spatiotemporal neighborhood motion statistical
	approach},
  owner = {larcher},
  timestamp = {2006.03.29}
}

@ARTICLE{Wenlong08,
  author = {Huang Wenlong and Jiao Licheng},
  title = {{Unsupervised Texture Segmentation Based on Artificial Immune Gaussian
	Mixture Models Network}},
  journal = {Chinese Journal of Electronics},
  year = {2008},
  volume = {17},
  pages = {301--304},
  number = {2},
  file = {Wenlong08.pdf:Artificial_Immune_System/Wenlong08.pdf:PDF}
}

@INPROCEEDINGS{White06,
  author = {Christopher White and Izhak Shafran and Jean-Luc Gauvain},
  title = {{Discriminative classifiers for language recognition}},
  booktitle = icassp,
  year = {2006},
  volume = {1},
  organization = {IEEE},
  file = {White06.pdf:Language_reco/White06.pdf:PDF},
  isbn = {142440469X},
  issn = {1520-6149}
}

@ARTICLE{Willsky76,
  author = {Willsky, A. and Jones, H.},
  title = {{A generalized likelihood ratio approach to the detection and estimation
	of jumps in linear systems}},
  journal = {IEEE Transactions on Automatic Control},
  year = {1976},
  volume = {21},
  pages = {108--112},
  number = {1},
  file = {Willsky76.pdf:Outils/GLR/Willsky76.pdf:PDF}
}

@ARTICLE{Wiskott97,
  author = {Laurenz Wiskott and Jean-Marc Fellous and Norbert Kr\"{u}ger and
	Christoph von der Malsburg},
  title = {{Face Recognition by Elastic Bunch Graph Matching}},
  journal = pami,
  year = {1997},
  volume = {19},
  pages = {775--779},
  file = {Wiskott97.pdf:Video/Wiskott97.pdf:PDF},
  owner = {antho},
  publisher = {IEEE Computer Society},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Wong01,
  author = {Lit Ping Wong and Martin Russell},
  title = {{Text-dependent speaker verification under noisy conditions using
	parallel model combination}},
  booktitle = icassp,
  year = {2001},
  volume = {1},
  pages = {457--460},
  organization = {Citeseer},
  file = {Wong01.pdf:Speaker_reco/Text_dependent/Wong01.pdf:PDF}
}

@INPROCEEDINGS{Woo06,
  author = {Ram H. Woo and Alex Park and Timothy J. Hazen},
  title = {{The MIT Mobile Device Speaker Verification Corpus: Data Collection
	and Preliminary Experiments}},
  booktitle = odyssey,
  year = {2006},
  file = {Woo06.pdf:Base_de_donnees/Woo06.pdf:PDF},
  owner = {antho},
  timestamp = {2010.07.27}
}

@INPROCEEDINGS{Woo00,
  author = {Siew Chan Woo and Chee Peng Lim and R. Osman},
  title = {{Text-dependent speaker recognition using the fuzzy ARTMAP neural
	network}},
  booktitle = {Proceedings of IEEE Region 10 International Conference on Electrical
	and Electronic Technology, TENCON},
  year = {2000},
  address = {Kuala Lumpur (Malaysia)},
  abstract = {Speaker recognition is the process of automatically recognizing the
	speaker by analyzing individual information contained in the speech
	waves. We discuss the development of an intelligent system for text-dependent
	speaker recognition. The system comprises two main modules, a wavelet-based
	signal-processing module for feature extraction of speech waves,
	and an artificial neural network-based classifier module to identify
	and categorize the speakers. The wavelet is used in de-noising and
	in compressing the speech signals. The wavelet family that we used
	is the Daubechies (1988) wavelets. After extracting the necessary
	features from the speech waves, the features were then fed to a neural-network-based
	classifier to identify the speakers. We have implemented the fuzzy
	ARTMAP (FAM) network in the classifier module to categorize the de-noised
	and compressed signals. The proposed intelligent learning system
	has been applied to a case study of text-dependent speaker recognition
	problem},
  doi = {10.1109/TENCON.2000.893535},
  file = {Woo00.pdf:Speaker_reco/Text_dependent/Woo00.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.21}
}

@MISC{Woodland00,
  author = {Phil Woodland and Dan Povey},
  title = {{Large Scale Discriminative Training for Speech Recognition}},
  year = {2000},
  abstract = {This paper describes, and evaluates on a large scale, the lattice
	based framework for discriminative training of large vocabulary speech
	recognition systems based on Gaussian mixture hidden Markov models
	(HMMs). The paper concentrates on the maximum mutual information
	estimation (MMIE) criterion which has been used to train HMM systems
	for conversational telephone speech transcription using up to 265
	hours of training data. These experiments represent the largest-scale
	application of discriminative training techniques for speech recognition
	of which the authors are aware, and have led to significant reductions
	in word error rate for both triphone and quinphone HMMs compared
	to our best models trained using maximum likelihood estimation. The
	MMIE latticebased implementation used; techniques for ensuring improved
	generalisation; and interactions with maximum likelihood based adaptation
	are all discussed. Furthermore several variations to the MMIE training
	scheme are introduced with the a...},
  file = {Woodland00.pdf:Speaker_reco/Adaptation/MMIE/Woodland00.pdf:PDF},
  owner = {larcher},
  text = {PC Woodland and D Povey. Large Scale Discriminative Training for Speech
	
	 Recognition. In ISCA ITRW Automatic Speech Recognition: Challenges
	for the
	
	 Millenium, pages 7-16, Paris, 2000.},
  timestamp = {2009.10.05},
  url = {citeseer.ist.psu.edu/article/woodland00large.html}
}

@ARTICLE{Wu09,
  author = {Dalei Wu and Ji Li and Haiqing Wu},
  title = {{Alpha-Gaussian mixture modelling for speaker recognition}},
  journal = {Pattern Recognition Letters},
  year = {2009},
  volume = {30},
  pages = {589--594},
  number = {6},
  owner = {antho},
  timestamp = {2010.09.06}
}

@ARTICLE{Xiang03,
  author = {Bing Xiang and Toby Berger},
  title = {{Efficient Text-Independent Speaker Verification with Structural
	Gaussian Mixture Models and Neural Network}},
  journal = tsap,
  year = {2003},
  volume = {11},
  pages = {447--456},
  number = {5},
  doi = {10.1109/TSA.2003.815822},
  file = {Xiang03.pdf:Speaker_reco/Text_dependent/Xiang03.pdf:PDF},
  owner = {antho},
  timestamp = {2010.08.24}
}

@INPROCEEDINGS{Xiang02,
  author = {Xiang, B. and Chaudhari, U.V. and Navratil, J. and Ramaswamy, G.N.
	and Gopinath, R.A.},
  title = {{Short-time Gaussianization for robust speaker verification}},
  booktitle = icassp,
  year = {2002},
  volume = {1},
  organization = {IEEE; 1999},
  file = {Xiang02.pdf:Speaker_reco/Gaussianization/Xiang02.pdf:PDF}
}

@INPROCEEDINGS{Xu02,
  author = {Xu, C. and Zhu, Y. and Tian, Q.},
  title = {{Automatic music summarization based on temporal, spectral and cepstral
	features}},
  booktitle = {IEEE International Conference on Multimedia and Expo},
  year = {2002},
  volume = {1},
  file = {Xu02.pdf:Divers/Music_Recognition/Xu02.pdf:PDF}
}

@INPROCEEDINGS{Xu11,
  author = {Jian Xu and Yu Zhang and Zhi-Jie Yan and Qiang Huo},
  title = {{An i-vector based approach to acoustic sniffing for irrelevant variability
	normalization based acoustic model training and speech recognition}},
  booktitle = interspeech,
  year = {2011},
  pages = {1701--1704},
  file = {Xu11.PDF:Information_Retrieval/Xu11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.13}
}

@ARTICLE{Yager10,
  author = {Neil Yager and Ted Dunstone},
  title = {{The biometric menagerie}},
  journal = pami,
  year = {2010},
  volume = {32},
  pages = {220--230},
  number = {2},
  file = {Yager10.pdf:Divers/Yager10.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Yaman11,
  author = {Sibel Yaman and Jason Pelecanos and Mohamed K. Omar},
  title = {{Boosting Speaker Recognition Performance with Compact Representations}},
  booktitle = interspeech,
  year = {2011},
  pages = {381--384},
  file = {Yaman11.PDF:Speaker_reco/FA/Yaman11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.10}
}

@INPROCEEDINGS{Yambor02,
  author = {Wendy S. Yambor and Bruce A. Draper and J. Ross Beveridge},
  title = {{Analyzing PCA-based face recognition algorithms: Eigenvector selection
	and distance measures}},
  booktitle = {Empirical Evaluation Methods in Computer Vision},
  year = {2002},
  publisher = {Singapore: World Scientific Press},
  file = {Yambor02.pdf:Image/EigenSpace/Yambor02.pdf:PDF},
  journal = {Empirical Evaluation Methods in Computer Vision}
}

@ARTICLE{Yang94,
  author = {Guangzheng Yang and Thomas S. Huang},
  title = {{Human face detection in a complex background}},
  journal = {Pattern Recognition},
  year = {1994},
  volume = {27},
  pages = {53-63},
  number = {1},
  abstract = {The human face is a complex pattern. Finding human faces automatically
	in a scene is a difficult yet significant problem. It is the first
	important step in a fully automatic human face recognition system.
	In this paper a new method to locate human faces in a complex background
	is proposed. This system utilizes a hierarchical knowledge-based
	method and consists of three levels. The higher two levels are based
	on mosaic images at different resolutions. In the lower level, an
	improved edge detection method is proposed. In this research the
	problem of scale is dealt with, so that the system can locate unknown
	human faces spanning a wide range of sizes in a complex black-and-white
	picture. Some experimental results are given.},
  file = {Yang94.pdf:Image/Yang94.pdf:PDF},
  keywords = {Face detection; Knowledge-based pattern recognition; Mosaic image;
	Edge detection},
  owner = {larcher},
  timestamp = {2006.05.29}
}

@INPROCEEDINGS{Yang05,
  author = {Jian Yang and David Zhang and Jing-Yu Yang},
  title = {{Is ICA significantly better than PCA for face recognition?}},
  booktitle = {Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference
	on},
  year = {2005},
  volume = {1},
  pages = {198--203},
  organization = {IEEE},
  file = {Yang05.pdf:Image/EigenSpace/Yang05.pdf:PDF}
}

@INPROCEEDINGS{Yang06,
  author = {Liping Yang and Weiguo Gong},
  title = {{Multi-SNR GMMs-Based Noise-Robust Speaker Verification Using 1/fa
	Noises}},
  booktitle = icpr,
  year = {2006},
  volume = {4},
  pages = {241--244},
  organization = {IEEE},
  file = {Yang06.pdf:Speaker_reco/Divers/Yang06.pdf:PDF}
}

@INPROCEEDINGS{Yang02_isomap,
  author = {Ming Hsuan Yang},
  title = {{Face recognition using extended isomap}},
  booktitle = icip,
  year = {2002},
  volume = {2},
  pages = {117--120},
  file = {Yang02_isomap.pdf:Outils/Isomap/Yang02_isomap.pdf:PDF}
}

@ARTICLE{Yang02,
  author = {Ming-Hsuan Yang and David J. Kriegman and Narendra Ahuja},
  title = {{Detecting Faces in Images : A Survey}},
  journal = pami,
  year = {2002},
  volume = {24},
  pages = {34-58},
  number = {1},
  abstract = {Images containing faces are essential to intelligent vision-based
	human-computer interaction, and research efforts in face processing
	include face recognition, face tracking, pose estimation and expression
	recognition. However, many reported methods assume that the faces
	in an image or an image sequence have been identified and localized.
	To build fully automated systems that analyze the information contained
	in face images, robust and efficient face detection algorithms are
	required. Given a single image, the goal of face detection is to
	identify all image regions which contain a face, regardless of its
	3D position, orientation and lighting conditions. Such a problem
	is challenging because faces are non-rigid and have a high degree
	of variability in size, shape, color and texture. Numerous techniques
	have been developed to detect faces in a single image, and the purpose
	of this paper is to categorize and evaluate these algorithms. We
	also discuss relevant issues such as data collection, evaluation
	metrics and benchmarking. After analyzing these algorithms and identifying
	their limitations, we conclude with several promising directions
	for future research},
  doi = {10.1109/34.982883},
  file = {Yang02.pdf:Video/Face_detection/Yang02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.24}
}

@ARTICLE{Yegnanarayana09,
  author = {B. Yegnanarayana and K. Sri Rama Murty},
  title = {Event-based instantaneous fundamental frequency estimation from speech
	signal},
  journal = taslp,
  year = {2009},
  volume = {17},
  pages = {614--624},
  file = {Yegnanarayana09.pdf:Parametrisation/Yegnanarayana09.pdf:PDF},
  owner = {antho},
  timestamp = {2010.10.18}
}

@INPROCEEDINGS{Yehia97,
  author = {Hani Yehia and Philip Rubin and Eric Vatiokis-Bateson},
  title = {{Quantitative association of orofacial and vocal-tract shapes}},
  booktitle = avsp,
  year = {1997},
  address = {Rhodes (Greece)},
  abstract = {This paper examines the degrees of correlation among vocal tract
	
	and orofacial movements data and the speech acoustics. Multi-
	
	linear techniques are applied to support the claims that orofacial
	
	motion during speech is largely a by-product of producing the 
	
	speech acoustics and further that the spectral enveloe of the speech
	
	acoustics is better estimated by the 3d motion of the face than the
	
	
	mid-sagittal motion of the anterior vocal tract (lips, tongue and
	jaw).},
  file = {Yehia97.pdf:Audio-Video/Yehia97.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.25}
}

@INPROCEEDINGS{Yemez03,
  author = {Y. Yemez and A. Kanak and E. Erzin and A.M. Tekalp},
  title = {{Multimodal speaker identification with audio-video processing}},
  booktitle = icip,
  year = {2003},
  volume = {3},
  pages = {5-8},
  month = {september},
  abstract = {In this paper we present a multimodal audio-visual speaker identification
	system. The objective is to improve the recognition performance over
	conventional unimodal schemes. The proposed system decomposes the
	information existing in a video stream into three components: speech,
	face texture and lip motion. Lip motion between successive frames
	is first computed in terms of optical flow vectors and then encoded
	as a feature vector in a magnitude direction histogram domain. The
	feature vectors obtained along the whole stream are then interpolated
	to match the rate of the speech signal and fused with mel frequency
	cepstral coefficients (MFCC) of the corresponding speech signal.
	The resulting joint feature vectors are used to train and test a
	Hidden Markov Model (HMM) based identification system. Face texture
	images are treated separately in eigenface domain and integrated
	to the system through decision-fusion. Experimental results are also
	included for demonstration of the system performance.},
  doi = {10.1109/ICIP.2003.1247167},
  file = {Yemez03.pdf:Audio-Video/Yemez03.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.05.18}
}

@ARTICLE{Yoma02,
  author = {Nestor Becerra Yoma and Tarciano Facco Pegoraro},
  title = {{Robust speaker verification with state duration modeling}},
  journal = {Speech Communication},
  year = {2002},
  volume = {38},
  pages = {77--88},
  number = {1--2},
  file = {Yoma02.pdf:Speaker_reco/Text_dependent/Yoma02.pdf:PDF},
  owner = {antho},
  timestamp = {2010.09.06}
}

@ARTICLE{You09,
  author = {Chanf Huai You and Kong Aik Lee and Haizhou Li},
  title = {{An SVM kernel with GMM-supervector based on the Bhattacharyya distance
	for speaker recognition}},
  journal = {IEEE Signal processing letters},
  year = {2009},
  volume = {16},
  pages = {49--52},
  number = {1},
  file = {You09.pdf:Speaker_reco/SVM/You09.pdf:PDF}
}

@TECHREPORT{Youansi06,
  author = {Guy Nouaga Youansi},
  title = {{Artificial Immune System}},
  institution = {Communication and Operating Systems Group, Berlin University of Technology},
  year = {2006},
  file = {Youansi06.pdf:Artificial_Immune_System/Youansi06.pdf:PDF},
  journal = {Communication and Operating Systems Group, Berlin University of Technology}
}

@INPROCEEDINGS{Young92,
  author = {Steve J. Young},
  title = {{The general use of tying in phoneme-based HMM speech recognisers}},
  booktitle = icassp,
  year = {1992},
  volume = {1},
  pages = {569--572},
  abstract = {A method of manipulating sets of hidden Markov models (HMMs) by applying
	various kinds of parameter tying operations is described, the aim
	being to synthesize compact and robust context dependent models.
	The method is illustrated via an experiment to build a set of generalized
	triphone models for the TIMIT database in which triphones are constructed
	by joining together left and right dependent biphones. Although simple,
	the method results in good performance and avoids the need to train
	large numbers of triphones. The use of tying to increase model robustness
	is also investigated. Tying the center states within triphones of
	the same phoneme class and tying variances within states is beneficial,
	but larger-scale tying of variances leads to degraded performance},
  file = {Young92.pdf:Speech_reco/Young92.pdf:PDF},
  owner = {larcher},
  timestamp = {2007.09.06}
}

@TECHREPORT{Yow96,
  author = {Kin Chong Yow and Roberto Cipolla},
  title = {{Feature-Based Human Face Detection}},
  institution = {Department of Engineering, University of Cambridge},
  year = {1996},
  citeseerurl = {citeseer.ist.psu.edu/yow96featurebased.html},
  file = {Yow96.pdf:Video/Face_detection/Yow96.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.05.29}
}

@INPROCEEDINGS{Yu95,
  author = {Yu, K. and Mason, J. and Oglesby, J.},
  title = {{Speaker recognition using hidden Markov models, dynamic time warping
	and vector quantisation}},
  booktitle = {Vision, Image and Signal Processing},
  year = {1995},
  volume = {142},
  number = {5},
  pages = {313--318},
  organization = {IET},
  file = {Yu95.pdf:Speaker_reco/Divers/Yu95.pdf:PDF},
  issn = {1350-245X}
}

@INPROCEEDINGS{Zadrozny02,
  author = {Bianca Zadrozny and Charles Elkan},
  title = {{Transforming classifier scores into accurate multiclass probability
	estimates}},
  booktitle = {ACM International Conference on Knowledge Discovery and Data Mining},
  year = {2002},
  pages = {694--699},
  organization = {ACM},
  file = {Zadrozny02.pdf:Calibration/Zadrozny02.pdf:PDF},
  isbn = {158113567X}
}

@PHDTHESIS{Zavaliagkos95,
  author = {Georges Zavaliagkos},
  title = {{Maximum A Posteriori Adaptation Techniques For Speech Recognition}},
  school = {Northeastern University},
  year = {1995},
  owner = {antho},
  timestamp = {2009.04.12}
}

@INPROCEEDINGS{Zelenek10,
  author = {Martin Zelenek and Henrik Schulz and and Javier Hernando},
  title = {{Albayzin 2010 Evaluation Campaign: Speaker Diarization}},
  booktitle = {FALA "VI Jornadas en Tecnologia del Habla" and II Iberian SLTech
	Workshop},
  year = {2010},
  file = {Zelenek10.pdf:Speaker_Diarization/Zelenek10.pdf:PDF},
  owner = {antho},
  timestamp = {2011.02.01}
}

@INPROCEEDINGS{Zeng06,
  author = {Zhihong Zeng and Yun Fu and Glenn I. Roisman and Zhen Wen and Yuxiao
	Hu and Thomas S. Huang},
  title = {{One-class classification for spontaneous facial expression analysis}},
  booktitle = {Automatic Face and Gesture Recognition},
  year = {2006},
  pages = {281--286},
  organization = {IEEE},
  file = {Zeng06.pdf:Image/EigenSpace/Zeng06.pdf:PDF}
}

@INPROCEEDINGS{Zhang05,
  author = {Dell Zhang and Xi Chen and Wee Sun Lee},
  title = {{Text classification with kernels on the multinomial manifold}},
  booktitle = {SIGIR conference on Research and development in information retrieval},
  year = {2005},
  pages = {266--273},
  organization = {ACM},
  file = {Zhang05.pdf:Speaker_reco/SVM/Zhang05.pdf:PDF}
}

@INPROCEEDINGS{Zhang03,
  author = {Zhang, T.},
  title = {{Automatic singer identification}},
  booktitle = {International Conference on Multimedia and Expo (ICME)},
  year = {2003},
  volume = {1},
  file = {Zhang03.pdf:Divers/Music_Recognition/Zhang03.pdf:PDF}
}

@INPROCEEDINGS{Zhang02,
  author = {Xiaozheng Zhang and Russell M. Mersereau and Mark A. Clements},
  title = {{Audio-Visual Speech Recognition by Speechreading}},
  booktitle = icdsp,
  year = {2002},
  volume = {2},
  pages = {1069-1072},
  address = {Island of Santorini (Thera)},
  abstract = {Speechreading increases intelligibility in human speech perception.
	This suggests that conventional acoustic-based speech processing
	can benefit from the addition of visual information. This paper exploits
	speechreading for joint audio-visual speech recognition. We first
	present a color-based feature extraction algorithm that is able to
	extract salient visual speech features reliably from a frontal view
	of the talker in a video sequence. Then, a new fusion strategy using
	a coupled hidden Markov model (CHMM) is proposed to incorporate visual
	modality into the acoustic subsystem. By maintaining temporal coupling
	across the two modalities at the feature level and allowing asynchrony
	in the state at the same time, a CHMM provides a better model for
	capturing temporal correlations between the two streams of information.
	The experimental results demonstrate that the combined audio-visual
	system outperforms the acoustic-only recognizer over a wide range
	of noise levels.},
  doi = {10.1109/ICDSP.2002.1028275},
  file = {Zhang02.pdf:Audio-Video/Zhang02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.12}
}

@INPROCEEDINGS{Zhang11,
  author = {Yu Zhang and Jian Xu and Zhi-Jie Yan and Qiang Huo},
  title = {{An i-vector Based Approach to Training Data Clustering for Improved
	Speech Recognition}},
  booktitle = interspeech,
  year = {2011},
  pages = {789--792},
  file = {Zhang11.PDF:Information_Retrieval/Zhang11.PDF:PDF},
  owner = {antho},
  timestamp = {2011.10.13}
}

@ARTICLE{Zhao03,
  author = {W. Zhao and Rama Chellappa and P.J. Phillips and A. Rosenfeld},
  title = {{Face recognition: A literature survey}},
  journal = {ACM Computing Surveys (CSUR)},
  year = {2003},
  volume = {35},
  pages = {399-458},
  number = {4},
  month = {December},
  abstract = {As one of the most successful applications of image analysis and understanding,
	face recognition has recently received significant attention, especially
	during the past several years. At least two reasons account for this
	trend: the first is the wide range of commercial and law enforcement
	applications, and the second is the availability of feasible technologies
	after 30 years of research. Even though current machine recognition
	systems have reached a certain level of maturity, their success is
	limited by the conditions imposed by many real applications. For
	example, recognition of face images acquired in an outdoor environment
	with changes in illumination and/or pose remains a largely unsolved
	problem. In other words, current systems are still far away from
	the capability of the human perception system.This paper provides
	an up-to-date critical survey of still- and video-based face recognition
	research. There are two underlying motivations for us to write this
	survey paper: the first is to provide an up-to-date review of the
	existing literature, and the second is to offer some insights into
	the studies of machine recognition of faces. To provide a comprehensive
	survey, we not only categorize existing recognition techniques but
	also present detailed descriptions of representative methods within
	each category. In addition, relevant topics such as psychophysical
	studies, system evaluation, and issues of illumination and pose variation
	are covered.},
  doi = {10.1145/954339.954342},
  file = {Zhao03.pdf:Video/Zhao03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.28}
}

@INPROCEEDINGS{Zhen02,
  author = {Yang Zhen and Li Canwei},
  title = {{A New feature extraction based the reliability of speech in speaker
	recognition}},
  booktitle = icsp,
  year = {2002},
  volume = {1},
  pages = {536--539},
  organization = {IEEE},
  file = {Zhen02.pdf:Parametrisation/Zhen02.pdf:PDF}
}

@INPROCEEDINGS{Zheng04,
  author = {Haishu Zheng and Yngchun Yang and Zhaohui Wu},
  title = {{Two-stage decision for short utterance speaker identification in
	mobile telecommunication environment}},
  booktitle = {International Conference on Systems, Man and Cybernetics},
  year = {2004},
  volume = {1},
  pages = {547--551},
  file = {Zheng04.pdf:Speaker_reco/Text_dependent/Zheng04.pdf:PDF}
}

@INPROCEEDINGS{Zheng88,
  author = {Zheng, Y.C. and Yuan, B.Z.},
  title = {{Text-dependent speaker identification using circular hidden Markov
	models}},
  booktitle = icassp,
  year = {1988},
  pages = {580--582},
  doi = {10.1109/ICASSP.1988.196651},
  file = {Zheng88.pdf:Speaker_reco/Text_dependent/Zheng88.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Zhou03,
  author = {Shaohua Zhou and Volker Krueger and Rama Chellappa},
  title = {{Probabilistic recognition of human faces from video}},
  journal = {Computer Vision and Image Understanding},
  year = {2003},
  volume = {91},
  pages = {214--245},
  number = {1-2},
  abstract = {Most present face recognition approaches recognize faces based on
	still images. We present a novel approach to recognize faces in video.
	In that scenario, the face gallery may consist of still images or
	may be derived from a videos. For evidence integration we use classical
	Bayesian propagation over time and compute the posterior distribution
	using sequential importance sampling. The probabilistic approach
	allows us to handle uncertainties in a systematic manner. Experimental
	results using videos collected by NIST/USF and CMU illustrate the
	effectiveness of this approach in both still-to-video and video-to-video
	scenarios with appropriate model choices.},
  file = {Zhou03.pdf:Video/Zhou03.pdf:PDF},
  owner = {antho},
  publisher = {Elsevier},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Zhou02,
  author = {Shaohua Zhou and Volker Krueger and Rama Chellappa},
  title = {{Face recognition from video: A CONDENSATION approach}},
  booktitle = {International Conference on Automatic Face and Gesture Recognition},
  year = {2002},
  address = {Washington (USa)},
  abstract = {The aim of this work is to investigate how to exploit the
	
	temporal information in a video sequence for the task of
	
	face recognition. Inspired by Li and Chellappa's approach
	
	[11], we propose a probabilistic model parameterized by a
	
	tracking state vector and a recognizing identity variable,
	
	simultaneously characterizing the dynamics and identity of
	
	humans. We then invoke a CONDENSATION [8] approach to
	
	provide a numerical solution to the model. Once the joint
	
	posterior distribution of state vector and identity variable is
	
	estimated, we marginalize it over the state vector to yield a
	
	robust estimate of the posterior distribution of identity vari-
	
	able. Due to the propagation of identity and dynamics, a
	
	degeneracy in the posterior distribution of identity variable
	
	is achieved to give improved recognition. This evolving be-
	
	havior is characterized using changes in entropy. The ef-
	
	fectiveness of this approach is illustrated using experimen- 
	
	tal results on low-resolution video data .},
  citeseerurl = {http://citeseer.ist.psu.edu/zhou02face.html},
  file = {Zhou02.pdf:Video/Zhou02.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.28}
}

@INPROCEEDINGS{Zhou08_b,
  author = {Xi Zhou and Jiri Navratil and Jason W. Pelecanos and Ganesh N. Ramaswamy
	and Thomas S Huang},
  title = {{Intersession variability compensation for language detection}},
  booktitle = icassp,
  year = {2008},
  pages = {4157--4160},
  file = {Zhou08_b.pdf:Language_reco/Zhou08_b.pdf:PDF},
  owner = {antho},
  timestamp = {2010.11.24}
}

@ARTICLE{Zhu08,
  author = {Donglai Zhu and Haizhou Li and Bin Ma and Chin-Hui Lee},
  title = {{Optimizing the Performance of Spoken Language Recognition With Discriminative
	Training}},
  journal = {IEEE transactions on audio, speech and language processing},
  year = {2008},
  volume = {16},
  pages = {1642--1653},
  number = {8},
  file = {:/Volumes/Donnees/LIA/biblio/Language_reco/Zhu08.pdf:PDF}
}

@INPROCEEDINGS{Zilea03,
  author = {Ran D. Zilea and Jiri Navratil and Ganesh N. Ramaswamy},
  title = {{Depitch and the role of fundamental frequency in speaker recognition}},
  booktitle = icassp,
  year = {2003},
  address = {Hong Kong},
  month = {april},
  abstract = {Pitch information is known to be partially conveyed in Mel cepstral
	features that are commonly used for speaker recognition. In particular,
	for high pitched female speakers, and whenever average pitch varies
	significantly between enrollment and testing, the fine spectral structure
	introduced by the fundamental frequency was shown to degrade speaker
	recognition performance. This paper introduces a signal processing
	procedure termed depitch that attempts to remove pitch information
	from the speech signal. Recognition experiments carried out on the
	female subset of the NIST 2002 Speaker Recognition Evaluation show
	that by combining scores from a conventional and a depitched system,
	a substantial improvement in equal error rate is obtained for high
	pitched speakers and pitch-mismatched trials. Performing pitch/depitch
	score fusion is also shown to help alleviate the well-known problem
	of "goat" speakers.},
  doi = {10.1109/ICASSP.2003.1202299},
  file = {Zilea03.pdf:Audio-Video/Zilea03.pdf:PDF},
  owner = {larcher},
  timestamp = {2006.04.24}
}

@ARTICLE{Zissman96,
  author = {Marc A. Zissman},
  title = {{Comparison of four approaches to automatic language identification
	of telephone speech}},
  journal = tsap,
  year = {1996},
  volume = {4},
  pages = {31--44},
  number = {1},
  file = {Zissman96.pdf:Language_reco/Zissman96.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@INPROCEEDINGS{Zissman95,
  author = {Marc A. Zissman},
  title = {{Language identification using phoneme recognition and phonotactic
	language modeling}},
  booktitle = icassp,
  year = {1995},
  pages = {3503--3506},
  organization = {IEEE},
  file = {Zissman95.pdf:Language_reco/Zissman95.pdf:PDF}
}

@INPROCEEDINGS{Zissman94,
  author = {Marc A. Zissman and Elliot Singer},
  title = {{Automatic language identification of telephone speech messages using
	phoneme recognition and N-gram modeling}},
  booktitle = icassp,
  year = {1994},
  volume = {1},
  file = {Zissman94.pdf:Language_reco/Zissman94.pdf:PDF},
  owner = {antho},
  timestamp = {2009.10.05}
}

@ARTICLE{Zue90,
  author = {Victor Zue and Stephanie Seneff and James Glass},
  title = {{Speech database development at MIT: Timit and beyond}},
  journal = {Speech Communication},
  year = {1990},
  volume = {9},
  pages = {351--356},
  number = {4},
  file = {Zue90.pdf:Base_de_donnees/Zue90.pdf:PDF},
  owner = {antho},
  timestamp = {2011.01.26}
}

@comment{jabref-meta: selector_author:Automatic;Lea;}

@comment{jabref-meta: selector_journal:2;}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:3D\;0\;Triggs00\;;
1 ExplicitGroup:Artificial Immune System\;0\;Atreas03\;Atreas04\;Coell
o07\;Dasgupta03\;Faraoun06\;Hart02\;Hart08\;Hunt96\;Kumar07\;Lampropou
los10\;Leung07\;Mcewan09\;Okamoto09\;Sotiropoulos05\;Sotiropoulos08\;S
tibor08\;Tarakanov10\;Timmis01\;Watkins04\;Wenlong08\;Youansi06\;;
1 ExplicitGroup:Bimodal\;2\;Chibelushi02\;Dugelay02\;Lucey02\;Potamian
os03\;;
2 ExplicitGroup:Classifiers\;0\;Broun01\;Brunelli95\;;
2 ExplicitGroup:Correlation Audio Video\;0\;Barker99\;Chetty04\;Eveno0
5\;Goecke03\;Goecke05\;Hershey00\;Slaney00\;Yehia97\;;
2 ExplicitGroup:Divers\;0\;Choudhury98\;Lucey03\;Mason02\;Ross04\;Zile
a03\;;
2 ExplicitGroup:Fusion\;0\;Fisher00\;Jourlin97_3\;Lucey04\;Ross01\;Teo
h04\;;
2 ExplicitGroup:Lip Tracking & Audio\;0\;Andre-Obrecht97\;Chetty041\;D
uchnowski95\;Jourlin97_1\;Jourlin97_2\;Zhang02\;;
2 ExplicitGroup:Text dependent\;0\;Acheroy96\;;
1 ExplicitGroup:COIA CANCOR\;0\;Doledec94\;;
1 ExplicitGroup:DTW\;0\;Myers80\;Rabiner78\;;
1 ExplicitGroup:Eigenvoices\;0\;Kuhn98_1\;Kuhn98_2\;;
1 ExplicitGroup:Face Tracking\;0\;McKenna96\;;
1 ExplicitGroup:Fisherfaces\;0\;Belhumeur97\;;
1 ExplicitGroup:GDW\;0\;Bonastre03\;;
1 ExplicitGroup:GMM\;0\;Bimbot04\;Liu99\;Reynolds00\;Reynolds95\;;
1 ExplicitGroup:HMM\;0\;Rabiner89\;Woodland00\;;
1 ExplicitGroup:Lip Reading\;0\;Broun02\;Eveno04\;Goecke00\;Lievin98\;
Luettin96\;;
1 ExplicitGroup:MAP\;0\;Gauvain94\;Matrouf03\;;
1 ExplicitGroup:MLLR\;0\;Gales96\;Leggetter95\;Stolcke05\;;
1 ExplicitGroup:Modèles d'Anchrage\;0\;Mami04\;Merlin99\;Sturim01\;;
1 ExplicitGroup:Normalisation\;0\;Carey91\;;
1 ExplicitGroup:Prosodie\;0\;Peskin03\;;
1 ExplicitGroup:Quantification Vectorielle\;0\;Gray84\;Pan85\;Ramakris
hnan98\;Soong85\;;
1 ExplicitGroup:SAT\;0\;Jin98\;;
1 ExplicitGroup:SMM\;0\;Starpert01\;;
1 ExplicitGroup:Speaker Tracking\;0\;Bonastre00\;Johnson97\;;
1 ExplicitGroup:SVM\;0\;Cornuejols02\;Fine01\;Wan00\;;
1 ExplicitGroup:Systèmes Embarqués\;0\;Levy06\;;
1 ExplicitGroup:Text Dependent\;0\;BenZeghiba06\;Bonastre03\;Burton87\
;Chatzis07\;Che96\;Chen96\;Das10\;Dutta08\;Falavigna95\;Farrell95\;Fin
an96\;Genoud98\;Hansen04\;Hebert03\;Hebert04\;Hebert05\;Huang95\;Ismai
l98\;Larcher_JEP10\;Larcher_SAC10\;Larcher_eusipco08\;Larcher_interspe
ech08\;Larcher_jep08\;Larcher_mmsp08\;Laxman03\;Li03\;Liou95\;Liu06\;L
uan06\;Matsui93\;Mirghafori04\;Nishida01\;Ramasubramanian06\;Rosenberg
90\;Savic90\;Sharma96\;Sivakumaran03\;Sturim02\;Subramanya07\;Wang07\;
Wong01\;Woo00\;Zheng04\;Zheng88\;;
1 ExplicitGroup:Video\;0\;Chellappa95\;Chen01\;Garcia04\;Garcia04_b\;L
ee05\;Li00\;Li01_1\;Li01_2\;Li02\;Liu03\;Luettin97\;Mallauran05\;Mogha
ddam97\;Perronnin05\;Turk911\;Turk912\;Zhao03\;Zhou02\;Zhou03\;;
2 ExplicitGroup:Statique\;0\;;
3 ExplicitGroup:Détection\;0\;Leung95\;Rajagopalan98\;Rowley98\;Sung94
\;;
1 ExplicitGroup:VTLN\;0\;Eide96\;Finke97\;Sundermann03\;Welling99\;;
1 ExplicitGroup:Short Utterance\;0\;Fauve07_b\;Mak06\;Stadelmann10\;Vo
gt08\;Vogt08_b\;Vogt09\;Vogt09_b\;;
1 ExplicitGroup:Publi_Antho\;0\;Audibert_HASR10\;Bonastre08\;Larcher05
\;Larcher_IS10\;Larcher_JEP10\;Larcher_NIST10\;Larcher_SAC10\;Larcher_
eusipco08\;Larcher_interspeech08\;Larcher_jep08\;Larcher_mmsp08\;Larch
er_rapportAV06\;Matrouf_NIST08\;;
1 ExplicitGroup:Audio Compression\;0\;Broun01_b\;Dan08\;Huerta98\;Petr
acca06\;Quatieri00\;Raj01\;;
1 ExplicitGroup:Machine Translation\;0\;Casacuberta04\;Matusov08\;Ney9
9\;;
1 ExplicitGroup:Student T\;0\;Chatzis07\;Chatzis09\;Mclachlan00\;Peel0
0\;;
}

